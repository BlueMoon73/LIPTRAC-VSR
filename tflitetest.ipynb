{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-13T18:25:47.257031Z",
     "start_time": "2024-07-13T18:25:47.244855Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2 "
   ],
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T18:25:47.582944Z",
     "start_time": "2024-07-13T18:25:47.340974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"finalModelCUSTOM.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)\n",
    "\n",
    "# Test model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "# \n",
    "# input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "# interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "# \n",
    "# interpreter.invoke()\n",
    "# \n",
    "# # The function `get_tensor()` returns a copy of the tensor data.\n",
    "# # Use `tensor()` in order to get a pointer to the tensor.\n",
    "# output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "# print(output_data)"
   ],
   "id": "32987a83ab426477",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_conv1_input:0', 'index': 0, 'shape': array([  1, 290,  40, 120,   1]), 'shape_signature': array([ -1, 290,  40, 120,   1]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'StatefulPartitionedCall:0', 'index': 115, 'shape': array([ 1,  1, 29]), 'shape_signature': array([-1, -1, 29]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[  1 290  40 120   1]\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T18:25:47.598286Z",
     "start_time": "2024-07-13T18:25:47.584943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def padTensor(tensor, target_shape, padding_value=0):\n",
    "  \"\"\"Pads a NumPy tensor to the specified target shape with a given padding value.\n",
    "\n",
    "  Args:\n",
    "      tensor: The NumPy tensor to be padded.\n",
    "      target_shape: The desired padded shape (tuple).\n",
    "      padding_value: The value to use for padding (default: 0).\n",
    "\n",
    "  Returns:\n",
    "      The padded NumPy tensor.\n",
    "  \"\"\"\n",
    "\n",
    "  pad_width = [(0, max(target_shape[i] - tensor.shape[i], 0)) for i in range(len(target_shape))]\n",
    "  return np.pad(tensor, pad_width, mode='constant', constant_values=padding_value)"
   ],
   "id": "300d11914729c473",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T18:25:47.705362Z",
     "start_time": "2024-07-13T18:25:47.600287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def faceDetection(img):\n",
    "    # TROUBLESHOOTING\n",
    "    # print(\"max size:\",img.shape, img.shape[0] - 3 * padding, img.shape[1] - 3 * padding)\n",
    "    return faceCascade.detectMultiScale(\n",
    "        img,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "    )\n",
    "\n",
    "def cropForMouth(img):\n",
    "    global lastKnownCrop\n",
    "    rects = faceDetection(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
    "    \n",
    "    # finding the largest face in a given image \n",
    "    largestFace = (0,0,0,0)\n",
    "    for (x, y, w, l) in rects:\n",
    "        if (w * l) > largestFace[2] * largestFace[3]:\n",
    "            largestFace = (x, y,w,l)\n",
    "        \n",
    "    if largestFace == (0,0,0,0):\n",
    "        largestFace =lastKnownCrop\n",
    "    # cropping for face \n",
    "    lastKnownCrop = largestFace\n",
    "    y1 = lastKnownCrop[1] \n",
    "    x1 = lastKnownCrop[0]\n",
    "    y2 = y1 + lastKnownCrop[3] \n",
    "    x2 = x1 + lastKnownCrop[2]\n",
    "    return img[y1 + int(0.65 * lastKnownCrop[3]): y2, x1 + int(0.05 * lastKnownCrop[2]): int(0.95 * x2)]\n",
    "\n",
    "def loadVideo(path): \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    global lastKnownCrop, frameSizeOld, frameSize, newFrameSize, grayFrame\n",
    "    global errorNums\n",
    "    processedFrames = []\n",
    "    isFirstFrame = True\n",
    "    frameShape = None\n",
    "    # for each frame \n",
    "    for n in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))): \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # in case a frame is missing, just continue\n",
    "        if frame is None or frame.shape[0] == 0: \n",
    "            continue\n",
    "        \n",
    "        if isFirstFrame: \n",
    "            frameShape  = frame.shape\n",
    "            isFirstFrame = False\n",
    "        \n",
    "        if frame.shape != frameShape: \n",
    "            continue\n",
    "        # crop only the mouth like we'll do on the RPI \n",
    "        frameSizeOld = frame.shape\n",
    "        frame = cropForMouth(frame)\n",
    "        frameSize = frame.shape\n",
    "        frame = cv2.resize(frame, (120, 40))\n",
    "        newFrameSize = frame.shape\n",
    "        grayFrame = tf.image.rgb_to_grayscale(frame)\n",
    "        processedFrames.append(grayFrame)\n",
    "        # processedFrames = [*processedFrames, grayFrame]\n",
    "    mean = tf.math.reduce_mean(processedFrames, keepdims=True)\n",
    "    cap.release()    \n",
    "\n",
    "   \n",
    "    std = tf.math.reduce_std(tf.cast(processedFrames, tf.float32), keepdims=True)\n",
    "    frames = tf.cast(processedFrames, tf.float32)\n",
    "    normalizedFrames = (tf.cast(frames, tf.float32) - tf.cast(mean, tf.float32)) / tf.cast(std, tf.float32)\n",
    "    return normalizedFrames"
   ],
   "id": "69a31b4eb6beab02",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T18:25:48.442693Z",
     "start_time": "2024-07-13T18:25:47.707754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = \"A:\\Lip Reading\\Potential Datasets\\BBC LRS2\\\\allFiles\\\\5570920046221178499_00015.mp4\"\n",
    "inputVid = loadVideo(path)\n",
    "inputVid.shape"
   ],
   "id": "ae61e08e29187386",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([130, 40, 120, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T18:25:48.458204Z",
     "start_time": "2024-07-13T18:25:48.444694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "paddedVid  = padTensor(inputVid, target_shape = (290, 40, 120, 1))\n",
    "paddedVid.shape"
   ],
   "id": "fb77a76b8dab25d6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290, 40, 120, 1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T18:25:48.474063Z",
     "start_time": "2024-07-13T18:25:48.460205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batchedPaddedVid = paddedVid.reshape((1,) + paddedVid.shape)  # Add a dimension of size 1\n",
    "batchedPaddedVid.shape"
   ],
   "id": "4786260f49599bf7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 290, 40, 120, 1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T18:25:53.141616Z",
     "start_time": "2024-07-13T18:25:48.476062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "input_data = np.array(batchedPaddedVid, dtype=np.float32)\n",
    "interpreter.set_tensor(0, input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)\n",
    "print(output_data.shape)"
   ],
   "id": "5663a69b859a8b56",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[7.23460573e-07 6.93142829e-06 2.65667361e-04 ... 2.46738011e-07\n",
      "   6.97800851e-06 1.11549625e-05]\n",
      "  [7.90351635e-07 4.23869824e-05 1.43869022e-06 ... 8.09406853e-09\n",
      "   5.78710024e-06 1.69129824e-04]\n",
      "  [1.64023356e-06 2.26260186e-03 5.22224695e-07 ... 2.80639085e-08\n",
      "   5.45448256e-06 3.76769225e-04]\n",
      "  ...\n",
      "  [9.60396826e-01 7.50445892e-08 7.06979648e-08 ... 1.45323797e-09\n",
      "   2.31208290e-07 3.95952016e-02]\n",
      "  [5.99314459e-03 1.26904990e-06 1.10831252e-07 ... 1.26646305e-09\n",
      "   4.98851068e-06 9.93992627e-01]\n",
      "  [6.48846269e-01 5.35934578e-06 2.41780367e-06 ... 3.59239216e-08\n",
      "   3.72095710e-05 3.50981325e-01]]]\n",
      "(1, 290, 29)\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T18:25:53.187726Z",
     "start_time": "2024-07-13T18:25:53.143499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab = [x for x in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ \"]\n",
    "charToNum = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
    "numToChar = tf.keras.layers.StringLookup(vocabulary=charToNum.get_vocabulary(), oov_token=\"\", invert=True)"
   ],
   "id": "ca0e4de6065d6a61",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T18:25:53.233657Z",
     "start_time": "2024-07-13T18:25:53.189727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "decoded = tf.keras.backend.ctc_decode(output_data, input_length=[145*2], greedy=True)[0][0].numpy()\n",
    "\n",
    "prediction = tf.strings.reduce_join(numToChar(decoded[0])).numpy().decode('utf-8')\n",
    "prediction"
   ],
   "id": "1bbd67982a941020",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WHICH OF OUR CONTESTANTS TODAY IS GOING TO MAKE A THUMPING GREAT PROFIT'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T18:25:53.249760Z",
     "start_time": "2024-07-13T18:25:53.235657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _remove_repeats(inds):\n",
    "    is_not_repeat = np.insert(np.diff(inds).astype(bool), 0, True)\n",
    "    return inds[is_not_repeat]\n",
    "\n",
    "def _remove_blanks(inds, n_classes):\n",
    "    return inds[inds < (n_classes - 1)]\n",
    "\n",
    "def ctc_decode_np(y_pred, input_length):\n",
    "    # Note:\n",
    "    # Last element in alphabet treated as blank character\n",
    "    # decoded_dense padded with -1\n",
    "\n",
    "    n_samples = y_pred.shape[0]\n",
    "    n_classes = y_pred.shape[-1]\n",
    "    log_prob = np.zeros((n_samples, 1))\n",
    "    decoded_dense = -np.ones_like(y_pred[..., 0])\n",
    "    decoded_length = np.zeros((n_samples,), dtype=np.int32)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        print('-'*60)\n",
    "        # [n_time_steps, alphabet_size]\n",
    "        prob = y_pred[i]\n",
    "\n",
    "        length = input_length[i]\n",
    "\n",
    "        decoded = np.argmax(prob[:length], axis=-1)\n",
    "\n",
    "        # print('decoded:', decoded)\n",
    "\n",
    "        log_prob[i] = -np.sum(np.log(prob[np.arange(length), decoded]))\n",
    "\n",
    "        decoded = _remove_repeats(decoded)\n",
    "\n",
    "        # print('decoded remove_repeats:', decoded)\n",
    "\n",
    "        decoded = _remove_blanks(decoded, n_classes)\n",
    "\n",
    "        # print('decoded remove_blanks:', decoded)\n",
    "\n",
    "        decoded_length[i] = len(decoded)\n",
    "        decoded_dense[i, :len(decoded)] = decoded\n",
    "\n",
    "\n",
    "\n",
    "    return decoded_dense[:, :np.max(decoded_length)], log_prob\n",
    "\n",
    "# [batch_size, ]\n",
    "input_length = np.array([290], dtype=np.int32)\n",
    "# print('input_length.shape', input_length.shape)\n",
    "ctc_decode_np(output_data, input_length=input_length)\n"
   ],
   "id": "f430ed47b1c52ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[23.,  8.,  9.,  3.,  8., 27., 15.,  6., 27., 15., 21., 18., 27.,\n",
       "          3., 15., 14., 20.,  5., 19., 20.,  1., 14., 20., 19., 27., 20.,\n",
       "         15.,  4.,  1., 25., 27.,  9., 19., 27.,  7., 15.,  9., 14.,  7.,\n",
       "         27., 20., 15., 27., 13.,  1., 11.,  5., 27.,  1., 27., 20.,  8.,\n",
       "         21., 13., 16.,  9., 14.,  7., 27.,  7., 18.,  5.,  1., 20., 27.,\n",
       "         16., 18., 15.,  6.,  9., 20.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]], dtype=float32),\n",
       " array([[14.22221565]]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T18:25:53.265727Z",
     "start_time": "2024-07-13T18:25:53.250760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scuffedDecode = ctc_decode_np(output_data, input_length=input_length)\n",
    "\n",
    "prediction = tf.strings.reduce_join(numToChar(scuffedDecode[0])).numpy().decode('utf-8')\n",
    "prediction"
   ],
   "id": "14f5e1e03083b7b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'WHICH OF OUR CONTESTANTS TODAY IS GOING TO MAKE A THUMPING GREAT PROFIT'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T19:24:47.456982Z",
     "start_time": "2024-07-13T19:24:47.443469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "vocab = [x for x in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ \"]\n",
    "charToIdx = {char: i for i, char in enumerate(vocab)}\n",
    "IdxToChar = {i: char for i, char in enumerate(vocab)}\n",
    "def encode_string(text):\n",
    "  \"\"\"Encodes a string into a vector of character indices.\n",
    "\n",
    "  Args:\n",
    "      text: The string to be encoded.\n",
    "\n",
    "  Returns:\n",
    "      A NumPy array of integer indices representing the encoded string.\n",
    "  \"\"\"\n",
    "  encoded_vector = [charToIdx.get(char, charToIdx[\" \"]) for char in text]\n",
    "  return np.array(encoded_vector, dtype=np.int32)\n",
    "\n",
    "def decode_vector(encoded_vector):\n",
    "  \"\"\"Decodes a vector of character indices back to a string.\n",
    "\n",
    "  Args:\n",
    "      encoded_vector: A NumPy array of integer indices representing the encoded string.\n",
    "\n",
    "  Returns:\n",
    "      The decoded string.\n",
    "  \"\"\"\n",
    "  \n",
    "  # print(index_to_char.get(0))\n",
    "\n",
    "  decoded_string = \"\".join([IdxToChar.get(idx-1, \" \") for idx in encoded_vector])\n",
    "  # - 1 because everything is offset by one for some reason\n",
    "  return decoded_string"
   ],
   "id": "5bdd4415fbfcac62",
   "outputs": [],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T19:25:34.536977Z",
     "start_time": "2024-07-13T19:25:34.528466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "d = scuffedDecode[0][0]\n",
    "finalMsg = ''.join(decode_vector(d))\n",
    "    "
   ],
   "id": "aee179174acf4612",
   "outputs": [],
   "execution_count": 143
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2e9e8c39a1a1b1be",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
