{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-13T19:27:02.281920Z",
     "start_time": "2024-07-13T19:26:55.963806Z"
    }
   },
   "source": [
    "# imports \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2 "
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T19:31:31.020105Z",
     "start_time": "2024-07-13T19:31:30.998520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"finalModelCUSTOM.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "inputDetails = interpreter.get_input_details()\n",
    "outputDetails = interpreter.get_output_details()\n",
    "print(inputDetails)\n",
    "print('\\n', outputDetails)\n",
    "\n",
    "inputShape = inputDetails[0]['shape']\n",
    "print(\"\\n input dims\", inputShape)\n"
   ],
   "id": "2c06f646cfba3cec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_conv1_input:0', 'index': 0, 'shape': array([  1, 290,  40, 120,   1]), 'shape_signature': array([ -1, 290,  40, 120,   1]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "\n",
      " [{'name': 'StatefulPartitionedCall:0', 'index': 115, 'shape': array([ 1,  1, 29]), 'shape_signature': array([-1, -1, 29]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "\n",
      " input dims [  1 290  40 120   1]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## VIDEO PROCESSING FUNCS",
   "id": "697f7db0bc4f769d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T19:28:45.543846Z",
     "start_time": "2024-07-13T19:28:45.470016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def faceDetection(img):\n",
    "    # TROUBLESHOOTING\n",
    "    # print(\"max size:\",img.shape, img.shape[0] - 3 * padding, img.shape[1] - 3 * padding)\n",
    "    return faceCascade.detectMultiScale(\n",
    "        img,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "    )\n",
    "\n",
    "def cropForMouth(img):\n",
    "    global lastKnownCrop\n",
    "    rects = faceDetection(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
    "    \n",
    "    # finding the largest face in a given image \n",
    "    largestFace = (0,0,0,0)\n",
    "    for (x, y, w, l) in rects:\n",
    "        if (w * l) > largestFace[2] * largestFace[3]:\n",
    "            largestFace = (x, y,w,l)\n",
    "        \n",
    "    if largestFace == (0,0,0,0):\n",
    "        largestFace =lastKnownCrop\n",
    "    # cropping for face \n",
    "    lastKnownCrop = largestFace\n",
    "    y1 = lastKnownCrop[1] \n",
    "    x1 = lastKnownCrop[0]\n",
    "    y2 = y1 + lastKnownCrop[3] \n",
    "    x2 = x1 + lastKnownCrop[2]\n",
    "    return img[y1 + int(0.65 * lastKnownCrop[3]): y2, x1 + int(0.05 * lastKnownCrop[2]): int(0.95 * x2)]\n",
    "\n",
    "def loadVideo(path): \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    global lastKnownCrop, frameSizeOld, frameSize, newFrameSize, grayFrame\n",
    "    global errorNums\n",
    "    processedFrames = []\n",
    "    isFirstFrame = True\n",
    "    frameShape = None\n",
    "    # for each frame \n",
    "    for n in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))): \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # in case a frame is missing, just continue\n",
    "        if frame is None or frame.shape[0] == 0: \n",
    "            continue\n",
    "        \n",
    "        if isFirstFrame: \n",
    "            frameShape  = frame.shape\n",
    "            isFirstFrame = False\n",
    "        \n",
    "        if frame.shape != frameShape: \n",
    "            continue\n",
    "        # crop only the mouth like we'll do on the RPI \n",
    "        frameSizeOld = frame.shape\n",
    "        frame = cropForMouth(frame)\n",
    "        frameSize = frame.shape\n",
    "        frame = cv2.resize(frame, (120, 40))\n",
    "        newFrameSize = frame.shape\n",
    "        grayFrame = tf.image.rgb_to_grayscale(frame)\n",
    "        processedFrames.append(grayFrame)\n",
    "        # processedFrames = [*processedFrames, grayFrame]\n",
    "    mean = tf.math.reduce_mean(processedFrames, keepdims=True)\n",
    "    cap.release()    \n",
    "\n",
    "   \n",
    "    std = tf.math.reduce_std(tf.cast(processedFrames, tf.float32), keepdims=True)\n",
    "    frames = tf.cast(processedFrames, tf.float32)\n",
    "    normalizedFrames = (tf.cast(frames, tf.float32) - tf.cast(mean, tf.float32)) / tf.cast(std, tf.float32)\n",
    "    return normalizedFrames"
   ],
   "id": "77a9d31f79ccfa56",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T19:30:15.562084Z",
     "start_time": "2024-07-13T19:30:15.555465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def padTensor(tensor, target_shape, padding_value=0):\n",
    "  \"\"\"Pads a NumPy tensor to the specified target shape with a given padding value.\n",
    "\n",
    "  Args:\n",
    "      tensor: The NumPy tensor to be padded.\n",
    "      target_shape: The desired padded shape (tuple).\n",
    "      padding_value: The value to use for padding (default: 0).\n",
    "\n",
    "  Returns:\n",
    "      The padded NumPy tensor.\n",
    "  \"\"\"\n",
    "\n",
    "  pad_width = [(0, max(target_shape[i] - tensor.shape[i], 0)) for i in range(len(target_shape))]\n",
    "  return np.pad(tensor, pad_width, mode='constant', constant_values=padding_value)"
   ],
   "id": "3527fe2a1e7b9998",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## LOADING SAMPLE DATA ",
   "id": "5fc75fef91ba483"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T19:31:15.749671Z",
     "start_time": "2024-07-13T19:31:14.986868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = \"A:\\Lip Reading\\Potential Datasets\\BBC LRS2\\\\allFiles\\\\5570920046221178499_00015.mp4\"\n",
    "inputVid = loadVideo(path)\n",
    "print(\"input video shape:\", inputVid.shape)\n",
    "\n",
    "# padding the tensor to the appropriate dims \n",
    "paddedVid  = padTensor(inputVid, target_shape = (290, 40, 120, 1))\n",
    "print(\"padded video shape:\", paddedVid.shape)\n",
    "\n",
    "# since model was trained in batches, the dataset needs to be reshaped with 1 more dim \n",
    "batchedPaddedVid = paddedVid.reshape((1,) + paddedVid.shape)  # Add a dimension of size 1\n",
    "print(\"batched padded video shape:\", batchedPaddedVid.shape)"
   ],
   "id": "18b7cf3445306fce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input video shape: (130, 40, 120, 1)\n",
      "padded video shape: (290, 40, 120, 1)\n",
      "batched padded video shape: (1, 290, 40, 120, 1)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T19:32:26.821923Z",
     "start_time": "2024-07-13T19:32:22.421921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputData = np.array(batchedPaddedVid, dtype=np.float32) # make data into a np arr\n",
    "interpreter.set_tensor(0, inputData) # set tensor to input  data\n",
    "\n",
    "interpreter.invoke() # \"prediction\" \n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "outputData = interpreter.get_tensor(outputDetails[0]['index'])\n",
    "print(\"output data shape:\", outputData.shape)"
   ],
   "id": "e4f4f2785ab07de1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output data shape: (1, 290, 29)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CTC DECODING",
   "id": "7a865a199c18f80"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T19:43:11.184233Z",
     "start_time": "2024-07-13T19:43:11.174722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab = [x for x in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ \"] # defines the vocab (MUST BE SAME AS IN THE FILE)   \n",
    "\n",
    "# DICTS to replicate charToNum & numToChar from model \n",
    "charToIdx = {char: i for i, char in enumerate(vocab)} \n",
    "IdxToChar = {i: char for i, char in enumerate(vocab)}"
   ],
   "id": "8d0f7b710528974b",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T19:45:41.487223Z",
     "start_time": "2024-07-13T19:45:41.470636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def removeRepeats(inds):\n",
    "    is_not_repeat = np.insert(np.diff(inds).astype(bool), 0, True)\n",
    "    return inds[is_not_repeat]\n",
    "\n",
    "def removeBlanks(inds, numClasses):\n",
    "    return inds[inds < (numClasses - 1)]\n",
    "\n",
    "def ctcDecode(yPred, inputLen):\n",
    "    # Notes:     \n",
    "    # last  element in \"vocab\" treated as blank character\n",
    "    # decodedDense padded with -1\n",
    "\n",
    "    numSamples = yPred.shape[0]\n",
    "    numClasses = yPred.shape[-1]\n",
    "    logProb = np.zeros((numSamples, 1))\n",
    "    decodedDense = -np.ones_like(yPred[..., 0])\n",
    "    decodedLen = np.zeros((numSamples,), dtype=np.int32)\n",
    "\n",
    "    for i in range(numSamples):\n",
    "        prob = yPred[i]\n",
    "\n",
    "        length = inputLen[i]\n",
    "\n",
    "        decoded = np.argmax(prob[:length], axis=-1)\n",
    "\n",
    "        logProb[i] = -np.sum(np.log(prob[np.arange(length), decoded]))\n",
    "\n",
    "        decoded = removeRepeats(decoded)\n",
    "\n",
    "        decoded = removeBlanks(decoded, numClasses)\n",
    "\n",
    "        decodedLen[i] = len(decoded)\n",
    "        decodedDense[i, :len(decoded)] = decoded\n",
    "\n",
    "    return decodedDense[:, :np.max(decodedLen)], logProb\n",
    "\n",
    "def encodeString(text):\n",
    "  encodedVec = [charToIdx.get(char, charToIdx[\" \"]) for char in text]\n",
    "  return np.array(encodedVec, dtype=np.int32)\n",
    "\n",
    "def decodeVector(encodedVector):\n",
    "  # - 1 because everything is offset by one for some reason\n",
    "  decodedString = \"\".join([IdxToChar.get(idx-1, \"\") for idx in encodedVector])\n",
    "  finalMsg = ''.join(decodedString)\n",
    "\n",
    "  return finalMsg\n",
    "\n",
    "inputLen = np.array([290], dtype=np.int32) # max frame ct \n",
    "decoded = ctcDecode(outputData, inputLen=inputLen)\n",
    "print(decodeVector(decoded[0][0]))"
   ],
   "id": "716e33efe3797e6f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHICH OF OUR CONTESTANTS TODAY IS GOING TO MAKE A THUMPING GREAT PROFIT\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CONDENSED FUNCTION   ",
   "id": "aa2138d01bda8e57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T19:46:46.443714Z",
     "start_time": "2024-07-13T19:46:46.427182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def makePrediction(interpreter, vidPath):\n",
    "    \n",
    "    # vid processing \n",
    "    inputVid = loadVideo(vidPath)\n",
    "    paddedVid  = padTensor(inputVid, target_shape = (290, 40, 120, 1))\n",
    "    batchedPaddedVid = paddedVid.reshape((1,) + paddedVid.shape)  # Add a dimension of size 1\n",
    "    \n",
    "    # making a prediction \n",
    "    inputData = np.array(batchedPaddedVid, dtype=np.float32) # make data into a np arr\n",
    "    interpreter.set_tensor(0, inputData)\n",
    "    interpreter.invoke() # \"prediction\" \n",
    "    \n",
    "    # decode the final ctc decoded tensor \n",
    "    outputData = interpreter.get_tensor(outputDetails[0]['index'])\n",
    "    return decodeVector(ctcDecode(outputData, inputLen=inputLen)[0][0])\n"
   ],
   "id": "9f9e2907ffec3047",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T19:46:52.055219Z",
     "start_time": "2024-07-13T19:46:47.250514Z"
    }
   },
   "cell_type": "code",
   "source": "makePrediction(interpreter=interpreter, vidPath=path)",
   "id": "472c2e4c80ee80f5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WHICH OF OUR CONTESTANTS TODAY IS GOING TO MAKE A THUMPING GREAT PROFIT'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e4c7a15accad0b6d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
