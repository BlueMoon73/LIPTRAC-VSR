{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T23:07:11.310298Z",
     "start_time": "2024-07-27T23:07:06.974489Z"
    }
   },
   "source": [
    "# imports \n",
    "import os\n",
    "import time\n",
    "\n",
    "import tensorflow as tf \n",
    "import cv2 \n",
    "import numpy\n",
    "from matplotlib import pyplot as plt\n",
    "from jiwer import wer \n",
    "# making GPU be used, and setting memory limits\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "# gpus = tf.config.list_logical_devices('GPU')\n",
    "print(gpus)\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    print(\"gpu set\")\n",
    "except:\n",
    "    pass\n",
    "    print(\"failed\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "gpu set\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "7c48bcf107f4c31b",
   "metadata": {},
   "source": [
    "## basic functions"
   ]
  },
  {
   "cell_type": "code",
   "id": "787272fefa6ec811",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T23:07:11.856815Z",
     "start_time": "2024-07-27T23:07:11.312339Z"
    }
   },
   "source": [
    "# setting up the functions to convert from chars to num and vice versa\n",
    "vocab = [x for x in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ \"]\n",
    "charToNum = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
    "numToChar = tf.keras.layers.StringLookup(vocabulary=charToNum.get_vocabulary(), oov_token=\"\", invert=True)\n",
    "\n",
    "# facial detection vars \n",
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "lastKnownCrop = (0, 0, 160, 150)\n",
    "\n",
    "# data dir\n",
    "rootDir = 'A:\\Lip Reading\\Potential Datasets\\BBC LRS2\\\\allFiles'\n",
    "rootDir2 = 'A:\\Lip Reading\\Potential Datasets\\\\BBC LRS2'\n",
    "# r = \"A:\\Lip Reading\\Potential Datasets\\BBC LRS2\\\\allFiles\"\n",
    "\n",
    "errorNums = 0 \n",
    "errorPaths = []\n",
    "errorInfo = []\n",
    "frameSize = None\n",
    "frameSizeOld = None\n",
    "newFrameSize = None\n",
    "grayFrame = None\n",
    "newImageSize = (40, 120)\n",
    "\n",
    "maxCharCt = 145 # found from the dataStats.ipynb\n",
    "maxFrameCt = 2*maxCharCt"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "c2e49edea7bd4712",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T23:07:11.872342Z",
     "start_time": "2024-07-27T23:07:11.857816Z"
    }
   },
   "source": [
    "# util funcs \n",
    "def faceDetection(img):\n",
    "    # TROUBLESHOOTING\n",
    "    # print(\"max size:\",img.shape, img.shape[0] - 3 * padding, img.shape[1] - 3 * padding)\n",
    "    return faceCascade.detectMultiScale(\n",
    "        img,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "    )\n",
    "\n",
    "def cropForMouth(img) -> numpy.ndarray:\n",
    "    global lastKnownCrop\n",
    "    rects = faceDetection(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
    "    \n",
    "    # finding the largest face in a given image \n",
    "    largestFace = (0,0,0,0)\n",
    "    for (x, y, w, l) in rects:\n",
    "        if (w * l) > largestFace[2] * largestFace[3]:\n",
    "            largestFace = (x, y,w,l)\n",
    "        \n",
    "    if largestFace == (0,0,0,0):\n",
    "        largestFace =lastKnownCrop\n",
    "    # cropping for face \n",
    "    lastKnownCrop = largestFace\n",
    "    y1 = lastKnownCrop[1] \n",
    "    x1 = lastKnownCrop[0]\n",
    "    y2 = y1 + lastKnownCrop[3] \n",
    "    x2 = x1 + lastKnownCrop[2]\n",
    "    return img[y1 + int(0.65 * lastKnownCrop[3]): y2, x1 + int(0.05 * lastKnownCrop[2]): int(0.95 * x2)]\n",
    "\n",
    "def numberToWords(num):  \n",
    "    if num == 0:  \n",
    "        return \"zero\"  \n",
    "    ones = [\"\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\"]  \n",
    "    tens = [\"\", \"\", \"twenty\", \"thirty\", \"forty\", \"fifty\", \"sixty\", \"seventy\", \"eighty\", \"ninety\"]  \n",
    "    teens = [\"ten\", \"eleven\", \"twelve\", \"thirteen\", \"fourteen\", \"fifteen\", \"sixteen\", \"seventeen\", \"eighteen\", \"nineteen\"]  \n",
    "    words = \"\"  \n",
    "    if num>= 1000:  \n",
    "        words += ones[num // 1000] + \" thousand \"  \n",
    "        num %= 1000  \n",
    "    if num>= 100:  \n",
    "        words += ones[num // 100] + \" hundred \"  \n",
    "        num %= 100  \n",
    "    if num>= 10 and num<= 19:  \n",
    "        words += teens[num - 10] + \" \"  \n",
    "        num = 0  \n",
    "    elif num>= 20:  \n",
    "        words += tens[num // 10] + \" \"  \n",
    "        num %= 10  \n",
    "    if num>= 1 and num<= 9:  \n",
    "        words += ones[num] + \" \"  \n",
    "    return words.strip().upper()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "c7fbad6e80991f3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T23:07:11.887852Z",
     "start_time": "2024-07-27T23:07:11.873342Z"
    }
   },
   "source": [
    "def loadData(path): \n",
    "    # tf has the paths as bytes so decode that\n",
    "    path = bytes.decode(path.numpy())\n",
    "    \n",
    "    # extract just the file names\n",
    "    global rootDir\n",
    "    fileName = path.split('\\\\')[-1].split('.')[0]\n",
    "    # generate the respective paths of the data\n",
    "    videoPath = os.path.join(rootDir,f'{fileName}.mp4')\n",
    "    alignmentPath = os.path.join(rootDir,f'{fileName}.txt')\n",
    "    \n",
    "    # return the frames and alignments\n",
    "    frames = loadVideo(videoPath) \n",
    "    alignments = loadText(alignmentPath)\n",
    "    return frames, alignments\n",
    "\n",
    "def loadVideo(path): \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    global lastKnownCrop, frameSizeOld, frameSize, newFrameSize, grayFrame\n",
    "    global errorNums\n",
    "    processedFrames = []\n",
    "    isFirstFrame = True\n",
    "    frameShape = None\n",
    "    # for each frame \n",
    "    for n in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))): \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # in case a frame is missing, just continue\n",
    "        if frame is None or frame.shape[0] == 0: \n",
    "            continue\n",
    "        \n",
    "        if isFirstFrame: \n",
    "            frameShape  = frame.shape\n",
    "            isFirstFrame = False\n",
    "        \n",
    "        if frame.shape != frameShape: \n",
    "            continue\n",
    "        # crop only the mouth like we'll do on the RPI \n",
    "        frameSizeOld = frame.shape\n",
    "        frame = cropForMouth(frame)\n",
    "        frameSize = frame.shape\n",
    "        frame = cv2.resize(frame, (newImageSize[1], newImageSize[0]))\n",
    "        newFrameSize = frame.shape\n",
    "        grayFrame = tf.image.rgb_to_grayscale(frame)\n",
    "        processedFrames.append(grayFrame)\n",
    "        # processedFrames = [*processedFrames, grayFrame]\n",
    "\n",
    "    \n",
    "    cap.release()    \n",
    "\n",
    "    # generate the normalized frames (deviation from the average)\n",
    "    mean = tf.math.reduce_mean(processedFrames, keepdims=True)\n",
    "    try: \n",
    "        std = tf.math.reduce_std(tf.cast(processedFrames, tf.float32),  keepdims=True)\n",
    "    except: \n",
    "        \n",
    "        errorPaths.append(path)\n",
    "        errorInfo.append(\"SECOND STATEMENT\")\n",
    "        errorInfo.append(len(processedFrames))\n",
    "        errorInfo.append(frameSizeOld)\n",
    "        errorInfo.append(frameSize)\n",
    "        errorInfo.append(newFrameSize)\n",
    "        errorInfo.append(grayFrame)\n",
    "    std = tf.math.reduce_std(tf.cast(processedFrames, tf.float32), keepdims=True)\n",
    "    frames = tf.cast(processedFrames, tf.float32)\n",
    "    normalizedFrames = (tf.cast(frames, tf.float32) - tf.cast(mean, tf.float32)) / tf.cast(std, tf.float32)\n",
    "    return normalizedFrames\n",
    "\n",
    "def loadText(path): \n",
    "    # open and parse the file \n",
    "    with open(path, 'r') as file: lines = file.readlines()\n",
    "    file.close()\n",
    "    \n",
    "    # return the number equivalent of each of the characters of the word \n",
    "    tokens = []\n",
    "    words = lines[0].split()\n",
    "    del words[0]\n",
    "\n",
    "    for word in words: \n",
    "        if word.isnumeric():\n",
    "            newWord = numberToWords(int(word))\n",
    "            words[words.index(word)] = newWord\n",
    "    words = \" \".join(words).split()\n",
    "    # print(words)\n",
    "    for word in words: \n",
    "        tokens = [*tokens,' ', word]\n",
    "    try:\n",
    "        return charToNum(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]   \n",
    "    except: \n",
    "        print(tokens)\n",
    "\n",
    "def processData(path): \n",
    "    return tf.py_function(loadData, [path],  (tf.float32, tf.int64))"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "a401cd6fa0067aed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T23:07:11.902871Z",
     "start_time": "2024-07-27T23:07:11.889854Z"
    }
   },
   "source": [
    "def getFrameCount(path) -> int: \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frameCount = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    cap.release()\n",
    "    return frameCount\n",
    "\n",
    "def getCharCount(path) -> int: \n",
    "    return len(loadText(path))"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "9203a9532b428b04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T23:07:11.918429Z",
     "start_time": "2024-07-27T23:07:11.903870Z"
    }
   },
   "source": [
    "# numberPath = \"A:\\\\Lip Reading\\\\Potential Datasets\\\\BBC LRS2\\\\Numbers.txt\"\n",
    "# tensorPath = tf.convert_to_tensor(numberPath, dtype=tf.string)\n",
    "# path = bytes.decode(tensorPath.numpy())\n",
    "# fileName = path.split('\\\\')[-1].split('.')[0]\n",
    "# \n",
    "# # testing if the loadData, loadVideo, and loadText function all work\n",
    "# alignmentPath = os.path.join(rootDir2,f'{fileName}.txt')\n",
    "# loadText(alignmentPath)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "1dc8265fa1dc4688",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T23:07:13.292574Z",
     "start_time": "2024-07-27T23:07:11.919429Z"
    }
   },
   "source": [
    "rawPath = \"A:\\\\Lip Reading\\\\Potential Datasets\\\\BBC LRS2\\\\allFiles\\\\5535415699068794046_00006.mp4\"\n",
    "\n",
    "tensorPath = tf.convert_to_tensor(rawPath, dtype=tf.string)\n",
    "path = bytes.decode(tensorPath.numpy())\n",
    "fileName = path.split('\\\\')[-1].split('.')[0]\n",
    "\n",
    "# testing if the loadData, loadVideo, and loadText function all work\n",
    "videoPath = os.path.join(rootDir,f'{fileName}.mp4')\n",
    "alignmentPath = os.path.join(rootDir,f'{fileName}.txt')\n",
    "\n",
    "loadVideo(videoPath)\n",
    "loadText(alignmentPath)\n",
    "\n",
    "frames, text = loadData(tensorPath)\n",
    "print(type(frames))\n",
    "print(frames)\n",
    "print(len(frames[0][0]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(\n",
      "[[[[ 0.9325923 ]\n",
      "   [ 0.97313976]\n",
      "   [ 1.0947822 ]\n",
      "   ...\n",
      "   [-1.8651845 ]\n",
      "   [-2.0273745 ]\n",
      "   [-2.1490169 ]]\n",
      "\n",
      "  [[ 0.8920448 ]\n",
      "   [ 0.97313976]\n",
      "   [ 1.0542347 ]\n",
      "   ...\n",
      "   [-1.8651845 ]\n",
      "   [-2.0273745 ]\n",
      "   [-2.1490169 ]]\n",
      "\n",
      "  [[ 0.8920448 ]\n",
      "   [ 0.9325923 ]\n",
      "   [ 0.97313976]\n",
      "   ...\n",
      "   [-1.905732  ]\n",
      "   [-2.0679219 ]\n",
      "   [-2.1490169 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.9325923 ]\n",
      "   [ 0.8109498 ]\n",
      "   [ 0.68930733]\n",
      "   ...\n",
      "   [-1.7029946 ]\n",
      "   [-1.7029946 ]\n",
      "   [-1.6624471 ]]\n",
      "\n",
      "  [[ 0.8514973 ]\n",
      "   [ 0.7704023 ]\n",
      "   [ 0.68930733]\n",
      "   ...\n",
      "   [-1.7029946 ]\n",
      "   [-1.6624471 ]\n",
      "   [-1.7029946 ]]\n",
      "\n",
      "  [[ 0.7298548 ]\n",
      "   [ 0.68930733]\n",
      "   [ 0.64875984]\n",
      "   ...\n",
      "   [-1.6218996 ]\n",
      "   [-1.6624471 ]\n",
      "   [-1.7029946 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.8514973 ]\n",
      "   [ 0.8920448 ]\n",
      "   [ 0.97313976]\n",
      "   ...\n",
      "   [-1.4191622 ]\n",
      "   [-1.6218996 ]\n",
      "   [-1.7435421 ]]\n",
      "\n",
      "  [[ 0.8514973 ]\n",
      "   [ 0.9325923 ]\n",
      "   [ 0.97313976]\n",
      "   ...\n",
      "   [-1.5002571 ]\n",
      "   [-1.6624471 ]\n",
      "   [-1.7840896 ]]\n",
      "\n",
      "  [[ 0.8920448 ]\n",
      "   [ 0.9325923 ]\n",
      "   [ 0.97313976]\n",
      "   ...\n",
      "   [-1.5408046 ]\n",
      "   [-1.7029946 ]\n",
      "   [-1.7840896 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.68930733]\n",
      "   [ 0.68930733]\n",
      "   [ 0.64875984]\n",
      "   ...\n",
      "   [-1.6624471 ]\n",
      "   [-1.6624471 ]\n",
      "   [-1.6624471 ]]\n",
      "\n",
      "  [[ 0.68930733]\n",
      "   [ 0.68930733]\n",
      "   [ 0.68930733]\n",
      "   ...\n",
      "   [-1.7029946 ]\n",
      "   [-1.7029946 ]\n",
      "   [-1.7029946 ]]\n",
      "\n",
      "  [[ 0.68930733]\n",
      "   [ 0.68930733]\n",
      "   [ 0.68930733]\n",
      "   ...\n",
      "   [-1.7029946 ]\n",
      "   [-1.7029946 ]\n",
      "   [-1.7435421 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.56766486]\n",
      "   [ 0.60821235]\n",
      "   [ 0.68930733]\n",
      "   ...\n",
      "   [-0.9325923 ]\n",
      "   [-1.1353297 ]\n",
      "   [-1.2569722 ]]\n",
      "\n",
      "  [[ 0.56766486]\n",
      "   [ 0.64875984]\n",
      "   [ 0.7298548 ]\n",
      "   ...\n",
      "   [-0.97313976]\n",
      "   [-1.2164247 ]\n",
      "   [-1.3380672 ]]\n",
      "\n",
      "  [[ 0.56766486]\n",
      "   [ 0.60821235]\n",
      "   [ 0.68930733]\n",
      "   ...\n",
      "   [-1.0947822 ]\n",
      "   [-1.2569722 ]\n",
      "   [-1.3786147 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.64875984]\n",
      "   [ 0.60821235]\n",
      "   [ 0.60821235]\n",
      "   ...\n",
      "   [-1.6624471 ]\n",
      "   [-1.6218996 ]\n",
      "   [-1.5813521 ]]\n",
      "\n",
      "  [[ 0.64875984]\n",
      "   [ 0.60821235]\n",
      "   [ 0.60821235]\n",
      "   ...\n",
      "   [-1.6218996 ]\n",
      "   [-1.6218996 ]\n",
      "   [-1.5813521 ]]\n",
      "\n",
      "  [[ 0.64875984]\n",
      "   [ 0.64875984]\n",
      "   [ 0.64875984]\n",
      "   ...\n",
      "   [-1.5408046 ]\n",
      "   [-1.5813521 ]\n",
      "   [-1.5813521 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-0.8920448 ]\n",
      "   [-0.8920448 ]\n",
      "   [-0.8514973 ]\n",
      "   ...\n",
      "   [-0.08109498]\n",
      "   [-0.12164247]\n",
      "   [-0.16218996]]\n",
      "\n",
      "  [[-0.8920448 ]\n",
      "   [-0.8514973 ]\n",
      "   [-0.8514973 ]\n",
      "   ...\n",
      "   [-0.08109498]\n",
      "   [-0.12164247]\n",
      "   [-0.16218996]]\n",
      "\n",
      "  [[-0.8109498 ]\n",
      "   [-0.8109498 ]\n",
      "   [-0.8109498 ]\n",
      "   ...\n",
      "   [-0.08109498]\n",
      "   [-0.12164247]\n",
      "   [-0.16218996]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.64875984]\n",
      "   [-0.64875984]\n",
      "   [-0.64875984]\n",
      "   ...\n",
      "   [-0.32437992]\n",
      "   [-0.32437992]\n",
      "   [-0.28383243]]\n",
      "\n",
      "  [[-0.68930733]\n",
      "   [-0.68930733]\n",
      "   [-0.68930733]\n",
      "   ...\n",
      "   [-0.32437992]\n",
      "   [-0.32437992]\n",
      "   [-0.32437992]]\n",
      "\n",
      "  [[-0.68930733]\n",
      "   [-0.68930733]\n",
      "   [-0.64875984]\n",
      "   ...\n",
      "   [-0.24328494]\n",
      "   [-0.28383243]\n",
      "   [-0.32437992]]]\n",
      "\n",
      "\n",
      " [[[-0.8514973 ]\n",
      "   [-0.8514973 ]\n",
      "   [-0.8109498 ]\n",
      "   ...\n",
      "   [ 0.04054749]\n",
      "   [-0.04054749]\n",
      "   [-0.08109498]]\n",
      "\n",
      "  [[-0.8920448 ]\n",
      "   [-0.8514973 ]\n",
      "   [-0.8109498 ]\n",
      "   ...\n",
      "   [ 0.04054749]\n",
      "   [-0.04054749]\n",
      "   [-0.08109498]]\n",
      "\n",
      "  [[-0.8514973 ]\n",
      "   [-0.8109498 ]\n",
      "   [-0.8109498 ]\n",
      "   ...\n",
      "   [ 0.04054749]\n",
      "   [-0.04054749]\n",
      "   [-0.04054749]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.68930733]\n",
      "   [-0.64875984]\n",
      "   [-0.60821235]\n",
      "   ...\n",
      "   [-0.3649274 ]\n",
      "   [-0.3649274 ]\n",
      "   [-0.3649274 ]]\n",
      "\n",
      "  [[-0.64875984]\n",
      "   [-0.64875984]\n",
      "   [-0.60821235]\n",
      "   ...\n",
      "   [-0.3649274 ]\n",
      "   [-0.3649274 ]\n",
      "   [-0.4054749 ]]\n",
      "\n",
      "  [[-0.60821235]\n",
      "   [-0.60821235]\n",
      "   [-0.56766486]\n",
      "   ...\n",
      "   [-0.3649274 ]\n",
      "   [-0.3649274 ]\n",
      "   [-0.3649274 ]]]\n",
      "\n",
      "\n",
      " [[[-0.97313976]\n",
      "   [-0.97313976]\n",
      "   [-0.9325923 ]\n",
      "   ...\n",
      "   [-0.04054749]\n",
      "   [-0.12164247]\n",
      "   [-0.16218996]]\n",
      "\n",
      "  [[-1.0136873 ]\n",
      "   [-0.97313976]\n",
      "   [-0.97313976]\n",
      "   ...\n",
      "   [-0.12164247]\n",
      "   [-0.16218996]\n",
      "   [-0.20273745]]\n",
      "\n",
      "  [[-0.9325923 ]\n",
      "   [-0.9325923 ]\n",
      "   [-0.9325923 ]\n",
      "   ...\n",
      "   [-0.20273745]\n",
      "   [-0.24328494]\n",
      "   [-0.24328494]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.7298548 ]\n",
      "   [-0.68930733]\n",
      "   [-0.64875984]\n",
      "   ...\n",
      "   [-0.3649274 ]\n",
      "   [-0.3649274 ]\n",
      "   [-0.4054749 ]]\n",
      "\n",
      "  [[-0.8109498 ]\n",
      "   [-0.7704023 ]\n",
      "   [-0.64875984]\n",
      "   ...\n",
      "   [-0.4054749 ]\n",
      "   [-0.4054749 ]\n",
      "   [-0.4054749 ]]\n",
      "\n",
      "  [[-0.8920448 ]\n",
      "   [-0.8109498 ]\n",
      "   [-0.64875984]\n",
      "   ...\n",
      "   [-0.4054749 ]\n",
      "   [-0.4054749 ]\n",
      "   [-0.4054749 ]]]], shape=(68, 40, 120, 1), dtype=float32)\n",
      "120\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "b323b3673a461c65",
   "metadata": {},
   "source": [
    "## reading data"
   ]
  },
  {
   "cell_type": "code",
   "id": "15d040463f02dc61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T23:07:31.397667Z",
     "start_time": "2024-07-27T23:07:31.309028Z"
    }
   },
   "source": [
    "# reading all files within the root directory\n",
    "# data = tf.data.Dataset.list_files('A:\\Lip Reading\\Potential Datasets\\BBC LRS2\\mvlrs_v1\\main\\*\\*.mp4')\n",
    "data = tf.data.Dataset.list_files('A:/Lip Reading/Potential Datasets/BBC LRS2/allFiles2/*.mp4')\n",
    "# data = tf.data.Dataset.list_files('A:/Lip Reading/Potential Datasets/BBC LRS2/trainFiles6/*.mp4')\n",
    "\n",
    "global maxCharCt\n",
    "\n",
    "data = data.shuffle(500, reshuffle_each_iteration=False) # shuffling data\n",
    "data = data.map(processData) # \"processing\" the data to obtain frames and the respective text \n",
    "\n",
    "dim1 = newImageSize[0]\n",
    "dim2 = newImageSize[1]\n",
    "print(\"dataset size before padding:\", len(data))\n",
    "print(\"data shape of example frame:\", newImageSize)\n",
    "print(\"data shape of example video:\", frames.shape)\n",
    "print(\"dims: \",dim1, \"x\",dim2)\n",
    "\n",
    "# combining 8 videos as one \"input\"\n",
    "# ensuring all videos are padded to match the longest video, \n",
    "# ensuring the length of all the alignments is the size of the longest text characters, as some are lower. \n",
    "batchSize = 2\n",
    "data = data.padded_batch(batchSize, padded_shapes=([maxFrameCt,None, None,None], [maxCharCt])) \n",
    "print(\"autotune: \",tf.data.AUTOTUNE)\n",
    "data = data.prefetch(tf.data.AUTOTUNE)\n",
    "# data=data.prefetch(3)\n",
    "print(\"data length after padding:\", len(data))\n",
    "print(\"batch size:\", batchSize)\n",
    "\n",
    "train = data.take(int(len(data) * 0.6))\n",
    "test = data.skip(int(len(data) * 0.6))\n",
    "print(\"train data size:\", len(train))\n",
    "print(\"test data size:\",  len(test))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size before padding: 3783\n",
      "data shape of example frame: (40, 120)\n",
      "data shape of example video: (68, 40, 120, 1)\n",
      "dims:  40 x 120\n",
      "autotune:  -1\n",
      "data length after padding: 1892\n",
      "batch size: 2\n",
      "train data size: 1135\n",
      "test data size: 757\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "b98206929338ffa0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T23:07:32.104357Z",
     "start_time": "2024-07-27T23:07:32.089805Z"
    }
   },
   "source": [
    "data"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 290, None, None, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, 145), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "771515f5cef4617f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T23:07:33.941844Z",
     "start_time": "2024-07-27T23:07:32.803046Z"
    }
   },
   "source": [
    "val = data.as_numpy_iterator().next()\n",
    "plt.imshow(val[0][0][2], cmap='gray_r')\n",
    "print(len(val[0][0]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "e1b71a67fbe998bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T23:07:34.677448Z",
     "start_time": "2024-07-27T23:07:34.376629Z"
    }
   },
   "source": [
    "print(tf.strings.reduce_join([numToChar(word) for word in val[1][0]]))\n",
    "print(\"num of chars:\", len(([numToChar(word) for word in val[1][0]])))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'THE IDEA OF FIXED', shape=(), dtype=string)\n",
      "num of chars: 145\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "7b9fe2e89759a25",
   "metadata": {},
   "source": [
    "## designing the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "44de38608ebec792",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T23:07:34.740543Z",
     "start_time": "2024-07-27T23:07:34.724030Z"
    }
   },
   "source": [
    "# imports for the model architecture \n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPooling3D, TimeDistributed, Flatten, GRU\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, Nadam, SGD\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "a4e35802d732d3c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T23:07:36.186719Z",
     "start_time": "2024-07-27T23:07:35.521561Z"
    }
   },
   "source": [
    "inputShape = data.as_numpy_iterator().next()[0][0].shape\n",
    "print(inputShape)\n",
    "print(charToNum.get_vocabulary())\n",
    "print(len(charToNum.get_vocabulary()))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290, 40, 120, 1)\n",
      "['', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ' ']\n",
      "28\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "84706072692f52d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T23:07:36.702758Z",
     "start_time": "2024-07-27T23:07:36.698249Z"
    }
   },
   "source": [
    "# model to be actually trained\n",
    "def createModel(x): \n",
    "    model = Sequential([\n",
    "    Conv3D(32, 3, input_shape=inputShape, padding='same', activation='relu', name=\"conv1\"),\n",
    "    MaxPooling3D((1,2,2), name=\"maxPool1\"),\n",
    "    \n",
    "    Conv3D(64, 3, padding='same', activation='relu', name=\"conv2\"),\n",
    "    MaxPooling3D((1,2,2), name=\"maxPool2\"),\n",
    "        \n",
    "    Conv3D(96, (2,3,3),  padding='same', activation='relu', name=\"conv3\"),\n",
    "    MaxPooling3D((1,2,2), name=\"maxPool3\"),\n",
    "    \n",
    "    TimeDistributed(Flatten()),\n",
    "    \n",
    "    # Bidirectional(LSTM(256, kernel_initializer='orthogonal', return_sequences=True)),\n",
    "    Bidirectional(GRU(x, kernel_initializer='orthogonal', return_sequences=True)),\n",
    "    Dropout(.5),\n",
    "\n",
    "        \n",
    "    # Bidirectional(LSTM(256, kernel_initializer='orthogonal' , return_sequences=True)),\n",
    "    Bidirectional(GRU(x, kernel_initializer='orthogonal' , return_sequences=True)),\n",
    "    Dropout(.5),\n",
    "    \n",
    "    Dense(charToNum.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "# model to be actually traine"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "d728bc2771721d6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T23:07:39.532351Z",
     "start_time": "2024-07-27T23:07:38.237545Z"
    }
   },
   "source": [
    "model2 = createModel(128)\n",
    "print(\"final model input shape:\",  inputShape)\n",
    "model2.summary()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final model input shape: (290, 40, 120, 1)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1 (Conv3D)              (None, 290, 40, 120, 32)  896       \n",
      "                                                                 \n",
      " maxPool1 (MaxPooling3D)     (None, 290, 20, 60, 32)   0         \n",
      "                                                                 \n",
      " conv2 (Conv3D)              (None, 290, 20, 60, 64)   55360     \n",
      "                                                                 \n",
      " maxPool2 (MaxPooling3D)     (None, 290, 10, 30, 64)   0         \n",
      "                                                                 \n",
      " conv3 (Conv3D)              (None, 290, 10, 30, 96)   110688    \n",
      "                                                                 \n",
      " maxPool3 (MaxPooling3D)     (None, 290, 5, 15, 96)    0         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 290, 7200)        0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 290, 256)         5629440   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 290, 256)          0         \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 290, 256)         296448    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 290, 256)          0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 290, 29)           7453      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,100,285\n",
      "Trainable params: 6,100,285\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "9cd1b05996f23f8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T02:45:44.991666Z",
     "start_time": "2024-07-28T02:45:44.975019Z"
    }
   },
   "source": [
    "# custom functions \n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 15:\n",
    "        return lr        \n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.05)\n",
    "    \n",
    "def scheduler2(epoch, lr):\n",
    "    return lr * tf.math.exp(-0.1)\n",
    "# custom loss function \n",
    "def CTCLoss(yTrue, yPred):\n",
    "    # y true is the text alignment (None, 99) \n",
    "    # y pred is the end result of the model (154, 41) \n",
    "    batchLen = tf.cast(tf.shape(yTrue)[0], dtype=\"int64\")\n",
    "\n",
    "    inputLen = tf.cast(tf.shape(yPred)[1], dtype=\"int64\")\n",
    "    labelLen = tf.cast(tf.shape(yTrue)[1], dtype=\"int64\")\n",
    "    inputLen = inputLen * tf.ones(shape=(batchLen, 1), dtype=\"int64\")\n",
    "    labelLen = labelLen * tf.ones(shape=(batchLen, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = tf.keras.backend.ctc_batch_cost(yTrue, yPred, inputLen, labelLen)   \n",
    "    return loss \n",
    "\n",
    "class ProduceExample(tf.keras.callbacks.Callback): \n",
    "    def __init__(self, dataset) -> None: \n",
    "        self.dataset = dataset.as_numpy_iterator()\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None) -> None:\n",
    "        try: \n",
    "            data = self.dataset.next()\n",
    "            yhat = self.model.predict(data[0])\n",
    "            start = time.time()\n",
    "       \n",
    "            decoded = tf.keras.backend.ctc_decode(yhat, [maxFrameCt,maxFrameCt], greedy=False)[0][0].numpy()\n",
    "            for x in range(len(yhat)):           \n",
    "                print('Original:', tf.strings.reduce_join(numToChar(data[1][x])).numpy().decode('utf-8'))\n",
    "                print('Prediction:', tf.strings.reduce_join(numToChar(decoded[x])).numpy().decode('utf-8'))\n",
    "                print(\"Word Error Rate: \", str(wer(tf.strings.reduce_join(numToChar(data[1][x])).numpy().decode('utf-8'), tf.strings.reduce_join(numToChar(decoded[x])).numpy().decode('utf-8') ) * 100) + \"%\")\n",
    "                print('~'*100)\n",
    "                print(time.time() - start)\n",
    "        except: \n",
    "            pass     \n",
    "      "
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "d5afa6ac776aca30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T02:45:47.338202Z",
     "start_time": "2024-07-28T02:45:47.328691Z"
    }
   },
   "source": [
    "def makePrediction(model, valuePassed=None): \n",
    "    if valuePassed is None: \n",
    "        value = val\n",
    "    else: \n",
    "        value = valuePassed\n",
    "    yHat = model.predict(value[0])\n",
    "    \n",
    "    decoded = tf.keras.backend.ctc_decode(yHat, [maxFrameCt, maxFrameCt], greedy=False)[0][0].numpy()\n",
    "    originalArr = []\n",
    "    predArr = []\n",
    "    for x in range(len(yHat)):          \n",
    "        original = tf.strings.reduce_join(numToChar(val[1][x])).numpy().decode('utf-8')\n",
    "        prediction = tf.strings.reduce_join(numToChar(decoded[x])).numpy().decode('utf-8')\n",
    "        originalArr.append(original)\n",
    "        predArr.append(prediction )\n",
    "        \n",
    "        print('Original:', original)\n",
    "        print('Prediction:', prediction)\n",
    "        print(\"Word Error Rate on Prediction:\", str(wer(original,prediction) * 100) + \"%\")\n",
    "        print('~' * 40)\n",
    "    print(\"Avg Word Error Rate:\", str(wer(originalArr, predArr) * 100) + \"%\")\n",
    "    \n",
    "    return value, yHat, decoded"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T02:45:50.286838Z",
     "start_time": "2024-07-28T02:45:49.794997Z"
    }
   },
   "cell_type": "code",
   "source": "makePrediction(model2)",
   "id": "18278119fccacab6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 316ms/step\n",
      "Original: THE IDEA OF FIXED\n",
      "Prediction: T \n",
      "Word Error Rate on Prediction: 100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WAITING IN THE WINGS ARE ENTREPRENEURS DESPERATE TO SECURE SOME CASH\n",
      "Prediction:  E E\n",
      "Word Error Rate on Prediction: 100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Avg Word Error Rate: 100.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((array([[[[[ 1.3176159 ],\n",
       "            [ 1.9165323 ],\n",
       "            [ 2.1161711 ],\n",
       "            ...,\n",
       "            [-0.23956653],\n",
       "            [-0.2794943 ],\n",
       "            [-0.3593498 ]],\n",
       "  \n",
       "           [[ 0.7985551 ],\n",
       "            [ 1.477327  ],\n",
       "            [ 1.8366767 ],\n",
       "            ...,\n",
       "            [-0.23956653],\n",
       "            [-0.31942204],\n",
       "            [-0.39927754]],\n",
       "  \n",
       "           [[ 0.2794943 ],\n",
       "            [ 0.67877185],\n",
       "            [ 1.2377604 ],\n",
       "            ...,\n",
       "            [-0.23956653],\n",
       "            [-0.31942204],\n",
       "            [-0.39927754]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.07985551],\n",
       "            [-0.07985551],\n",
       "            [-0.19963877],\n",
       "            ...,\n",
       "            [-1.3974714 ],\n",
       "            [-1.3974714 ],\n",
       "            [-1.3974714 ]],\n",
       "  \n",
       "           [[-0.15971102],\n",
       "            [-0.15971102],\n",
       "            [-0.19963877],\n",
       "            ...,\n",
       "            [-1.4373991 ],\n",
       "            [-1.4373991 ],\n",
       "            [-1.4373991 ]],\n",
       "  \n",
       "           [[-0.07985551],\n",
       "            [-0.15971102],\n",
       "            [-0.19963877],\n",
       "            ...,\n",
       "            [-1.477327  ],\n",
       "            [-1.477327  ],\n",
       "            [-1.477327  ]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.19963877],\n",
       "            [ 0.91833836],\n",
       "            [ 1.5971102 ],\n",
       "            ...,\n",
       "            [-0.39927754],\n",
       "            [-0.47913307],\n",
       "            [-0.5589886 ]],\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.47913307],\n",
       "            [ 1.1179771 ],\n",
       "            ...,\n",
       "            [-0.3593498 ],\n",
       "            [-0.43920532],\n",
       "            [-0.5589886 ]],\n",
       "  \n",
       "           [[-0.19963877],\n",
       "            [ 0.        ],\n",
       "            [ 0.3593498 ],\n",
       "            ...,\n",
       "            [-0.47913307],\n",
       "            [-0.59891635],\n",
       "            [-0.67877185]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.07985551],\n",
       "            [ 0.07985551],\n",
       "            [ 0.07985551],\n",
       "            ...,\n",
       "            [-1.477327  ],\n",
       "            [-1.477327  ],\n",
       "            [-1.477327  ]],\n",
       "  \n",
       "           [[ 0.07985551],\n",
       "            [ 0.07985551],\n",
       "            [ 0.03992775],\n",
       "            ...,\n",
       "            [-1.5172547 ],\n",
       "            [-1.5172547 ],\n",
       "            [-1.477327  ]],\n",
       "  \n",
       "           [[ 0.07985551],\n",
       "            [ 0.07985551],\n",
       "            [ 0.03992775],\n",
       "            ...,\n",
       "            [-1.5172547 ],\n",
       "            [-1.5172547 ],\n",
       "            [-1.5172547 ]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.15971102],\n",
       "            [-0.11978327],\n",
       "            [ 0.15971102],\n",
       "            ...,\n",
       "            [-0.23956653],\n",
       "            [-0.31942204],\n",
       "            [-0.39927754]],\n",
       "  \n",
       "           [[-0.19963877],\n",
       "            [-0.19963877],\n",
       "            [-0.03992775],\n",
       "            ...,\n",
       "            [-0.3593498 ],\n",
       "            [-0.39927754],\n",
       "            [-0.5190608 ]],\n",
       "  \n",
       "           [[-0.15971102],\n",
       "            [-0.19963877],\n",
       "            [-0.19963877],\n",
       "            ...,\n",
       "            [-0.3593498 ],\n",
       "            [-0.39927754],\n",
       "            [-0.5190608 ]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.07985551],\n",
       "            [ 0.07985551],\n",
       "            [ 0.03992775],\n",
       "            ...,\n",
       "            [-1.477327  ],\n",
       "            [-1.477327  ],\n",
       "            [-1.477327  ]],\n",
       "  \n",
       "           [[ 0.07985551],\n",
       "            [ 0.07985551],\n",
       "            [ 0.03992775],\n",
       "            ...,\n",
       "            [-1.5172547 ],\n",
       "            [-1.5172547 ],\n",
       "            [-1.5172547 ]],\n",
       "  \n",
       "           [[ 0.11978327],\n",
       "            [ 0.11978327],\n",
       "            [ 0.07985551],\n",
       "            ...,\n",
       "            [-1.5571824 ],\n",
       "            [-1.5172547 ],\n",
       "            [-1.5172547 ]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]]]],\n",
       "  \n",
       "  \n",
       "  \n",
       "         [[[[-2.0140707 ],\n",
       "            [-1.8932265 ],\n",
       "            [-1.8126637 ],\n",
       "            ...,\n",
       "            [-1.3292867 ],\n",
       "            [-1.3695681 ],\n",
       "            [-1.4904124 ]],\n",
       "  \n",
       "           [[-2.0140707 ],\n",
       "            [-1.8932265 ],\n",
       "            [-1.7321008 ],\n",
       "            ...,\n",
       "            [-1.3292867 ],\n",
       "            [-1.4098495 ],\n",
       "            [-1.5709752 ]],\n",
       "  \n",
       "           [[-1.9335079 ],\n",
       "            [-1.7723823 ],\n",
       "            [-1.651538  ],\n",
       "            ...,\n",
       "            [-1.3695681 ],\n",
       "            [-1.4098495 ],\n",
       "            [-1.5709752 ]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.7653469 ],\n",
       "            [ 1.7723823 ],\n",
       "            [ 2.1751964 ],\n",
       "            ...,\n",
       "            [-1.4501309 ],\n",
       "            [-1.6112566 ],\n",
       "            [-1.7321008 ]],\n",
       "  \n",
       "           [[ 1.0473168 ],\n",
       "            [ 2.0140707 ],\n",
       "            [ 2.416885  ],\n",
       "            ...,\n",
       "            [-1.4501309 ],\n",
       "            [-1.6112566 ],\n",
       "            [-1.7723823 ]],\n",
       "  \n",
       "           [[ 1.2487239 ],\n",
       "            [ 2.2557592 ],\n",
       "            [ 2.6585734 ],\n",
       "            ...,\n",
       "            [-1.3695681 ],\n",
       "            [-1.5306938 ],\n",
       "            [-1.7321008 ]]],\n",
       "  \n",
       "  \n",
       "          [[[-1.3695681 ],\n",
       "            [-0.92647254],\n",
       "            [-0.48337698],\n",
       "            ...,\n",
       "            [-1.3695681 ],\n",
       "            [-1.3695681 ],\n",
       "            [-1.4904124 ]],\n",
       "  \n",
       "           [[-1.4098495 ],\n",
       "            [-0.96675396],\n",
       "            [-0.5236584 ],\n",
       "            ...,\n",
       "            [-1.3695681 ],\n",
       "            [-1.3695681 ],\n",
       "            [-1.4904124 ]],\n",
       "  \n",
       "           [[-1.3695681 ],\n",
       "            [-1.0070354 ],\n",
       "            [-0.5236584 ],\n",
       "            ...,\n",
       "            [-1.3695681 ],\n",
       "            [-1.3695681 ],\n",
       "            [-1.4904124 ]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 1.9737893 ],\n",
       "            [ 1.7321008 ],\n",
       "            [ 1.3292867 ],\n",
       "            ...,\n",
       "            [-1.6112566 ],\n",
       "            [-1.8126637 ],\n",
       "            [-1.9335079 ]],\n",
       "  \n",
       "           [[ 1.8529451 ],\n",
       "            [ 1.7723823 ],\n",
       "            [ 1.5709752 ],\n",
       "            ...,\n",
       "            [-1.6112566 ],\n",
       "            [-1.7723823 ],\n",
       "            [-1.8529451 ]],\n",
       "  \n",
       "           [[ 1.9335079 ],\n",
       "            [ 1.8932265 ],\n",
       "            [ 1.7321008 ],\n",
       "            ...,\n",
       "            [-1.5709752 ],\n",
       "            [-1.651538  ],\n",
       "            [-1.7723823 ]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.8861911 ],\n",
       "            [-0.48337698],\n",
       "            [-0.12084424],\n",
       "            ...,\n",
       "            [-1.651538  ],\n",
       "            [-1.6112566 ],\n",
       "            [-1.4501309 ]],\n",
       "  \n",
       "           [[-0.96675396],\n",
       "            [-0.5236584 ],\n",
       "            [-0.20140707],\n",
       "            ...,\n",
       "            [-1.6112566 ],\n",
       "            [-1.5306938 ],\n",
       "            [-1.3695681 ]],\n",
       "  \n",
       "           [[-1.0473168 ],\n",
       "            [-0.6042212 ],\n",
       "            [-0.24168849],\n",
       "            ...,\n",
       "            [-1.4904124 ],\n",
       "            [-1.4501309 ],\n",
       "            [-1.2890053 ]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 2.215478  ],\n",
       "            [ 1.9737893 ],\n",
       "            [ 1.5709752 ],\n",
       "            ...,\n",
       "            [-1.5709752 ],\n",
       "            [-1.3695681 ],\n",
       "            [-1.0875982 ]],\n",
       "  \n",
       "           [[ 2.416885  ],\n",
       "            [ 2.1751964 ],\n",
       "            [ 1.8529451 ],\n",
       "            ...,\n",
       "            [-1.5306938 ],\n",
       "            [-1.3292867 ],\n",
       "            [-1.0875982 ]],\n",
       "  \n",
       "           [[ 2.698855  ],\n",
       "            [ 2.4974477 ],\n",
       "            [ 2.2557592 ],\n",
       "            ...,\n",
       "            [-1.4904124 ],\n",
       "            [-1.3292867 ],\n",
       "            [-1.0875982 ]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]],\n",
       "  \n",
       "           [[ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            ...,\n",
       "            [ 0.        ],\n",
       "            [ 0.        ],\n",
       "            [ 0.        ]]]]], dtype=float32),\n",
       "  array([[20,  8,  5, 27,  9,  4,  5,  1, 27, 15,  6, 27,  6,  9, 24,  5,\n",
       "           4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0],\n",
       "         [23,  1,  9, 20,  9, 14,  7, 27,  9, 14, 27, 20,  8,  5, 27, 23,\n",
       "           9, 14,  7, 19, 27,  1, 18,  5, 27,  5, 14, 20, 18,  5, 16, 18,\n",
       "           5, 14,  5, 21, 18, 19, 27,  4,  5, 19, 16,  5, 18,  1, 20,  5,\n",
       "          27, 20, 15, 27, 19,  5,  3, 21, 18,  5, 27, 19, 15, 13,  5, 27,\n",
       "           3,  1, 19,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0]], dtype=int64)),\n",
       " array([[[2.11056788e-02, 5.91212288e-02, 1.99543945e-02, ...,\n",
       "          7.05843500e-04, 5.70385717e-02, 2.45231867e-01],\n",
       "         [1.82040669e-02, 5.87636121e-02, 1.58005897e-02, ...,\n",
       "          4.24865866e-04, 8.52603242e-02, 2.60138839e-01],\n",
       "         [1.47933941e-02, 5.70780411e-02, 1.35913007e-02, ...,\n",
       "          2.75124767e-04, 1.19733758e-01, 2.56431788e-01],\n",
       "         ...,\n",
       "         [9.69185531e-01, 1.18688195e-06, 1.23108620e-07, ...,\n",
       "          1.34216819e-07, 8.39903009e-07, 3.07783894e-02],\n",
       "         [1.04839601e-01, 5.56180612e-06, 3.08994657e-07, ...,\n",
       "          1.21058520e-07, 3.23116728e-06, 8.95089507e-01],\n",
       "         [9.34761226e-01, 8.09028097e-06, 1.19698086e-06, ...,\n",
       "          1.69513419e-06, 6.73152545e-06, 6.50329068e-02]],\n",
       " \n",
       "        [[1.93095114e-02, 5.04815169e-02, 1.77500136e-02, ...,\n",
       "          5.65513154e-04, 4.32362333e-02, 3.09886754e-01],\n",
       "         [1.53869661e-02, 4.72776070e-02, 1.31185828e-02, ...,\n",
       "          2.84398790e-04, 7.61255696e-02, 3.21175337e-01],\n",
       "         [1.26163177e-02, 4.57427390e-02, 1.08496100e-02, ...,\n",
       "          1.97982474e-04, 1.01796806e-01, 3.21152002e-01],\n",
       "         ...,\n",
       "         [9.68883395e-01, 1.20032303e-06, 1.23704012e-07, ...,\n",
       "          1.38951719e-07, 8.92840205e-07, 3.10791321e-02],\n",
       "         [1.05407037e-01, 5.60132366e-06, 3.10055242e-07, ...,\n",
       "          1.25275193e-07, 3.42820954e-06, 8.94519508e-01],\n",
       "         [9.34069157e-01, 8.18465833e-06, 1.20130869e-06, ...,\n",
       "          1.75387322e-06, 7.15780561e-06, 6.57167435e-02]]], dtype=float32),\n",
       " array([[20, 27,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1],\n",
       "        [27,  5, 27,  5,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1]], dtype=int64))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## compilign the model??",
   "id": "25b028a1d086a394"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T02:45:59.479264Z",
     "start_time": "2024-07-28T02:45:59.456050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model2.compile(optimizer=Adam(learning_rate=0.0005), loss=CTCLoss)\n",
    "# create all the callbacks \n",
    "checkpointCallback2 = ModelCheckpoint('newUpdatedModel/modifiedModelv1.weights.h5', monitor='loss',save_weights_only=False, save_freq='epoch') # save checkpoints after each epoch\n",
    "\n",
    "scheduleCallback2 = LearningRateScheduler(scheduler)\n",
    "exampleCallback2 = ProduceExample(test)"
   ],
   "id": "ec6634918fbbb5b3",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T21:53:41.454372Z",
     "start_time": "2024-07-28T02:46:04.619038Z"
    }
   },
   "cell_type": "code",
   "source": "model2.fit(train, validation_data=test, epochs=300, callbacks=[checkpointCallback2, exampleCallback2, scheduleCallback2], use_multiprocessing=True)",
   "id": "8c3fe5f2bba6b6ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Original: ONE COUPLE MUST LEAVE TONIGHT\n",
      "Prediction: T E E E E E\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.14231491088867188\n",
      "Original: THERE IS A VERY CLOSE KNIT COMMUNITY\n",
      "Prediction: I E E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.14431476593017578\n",
      "1135/1135 [==============================] - 1852s 2s/step - loss: 113.8402 - val_loss: 112.5107 - lr: 2.0000e-04\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "Original: ABOVE ALL OTHERS\n",
      "Prediction: T E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.16151905059814453\n",
      "Original: I WAS VERY KEEN TO GET INVOLVED\n",
      "Prediction: T E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.16351866722106934\n",
      "1135/1135 [==============================] - 1280s 1s/step - loss: 113.1127 - val_loss: 112.5202 - lr: 2.0000e-04\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "Original: I MUST HAVE MADE A MISTAKE\n",
      "Prediction: I E\n",
      "Word Error Rate:  83.33333333333334%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.10551238059997559\n",
      "Original: GET THINGS WRONG AND IT COULD END UP IN A SERIOUS INJURY AND\n",
      "Prediction: I E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.1075127124786377\n",
      "1135/1135 [==============================] - 1275s 1s/step - loss: 110.9237 - val_loss: 109.5117 - lr: 2.0000e-04\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "Original: THE SHOW WHERE A TEAM OF FIVE QUIZ CHALLENGERS PIT THEIR WITS AGAINST POSSIBLY THE GREATEST QUIZ\n",
      "Prediction: WH E E E E E E E E E E E E E E E E E E T E E\n",
      "Word Error Rate:  129.41176470588235%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.06951117515563965\n",
      "Original: DONT LET A SMALL THING LIKE A MAN TYING YOU TO A TRAIN TRACK HOLD YOU BACK FROM DOING WHAT YOU DO\n",
      "Prediction: TE E E E E E E E E E E E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.07151079177856445\n",
      "1135/1135 [==============================] - 1291s 1s/step - loss: 110.9685 - val_loss: 109.5943 - lr: 2.0000e-04\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "Original: WHAT ABOUT ANTIQUES\n",
      "Prediction: I \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.13151192665100098\n",
      "Original: SO PLENTY TO PLAY FOR\n",
      "Prediction: I E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.13351130485534668\n",
      "1135/1135 [==============================] - 1291s 1s/step - loss: 110.9384 - val_loss: 112.0123 - lr: 2.0000e-04\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "Original: AND THATS WHAT\n",
      "Prediction: I E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.1655595302581787\n",
      "Original: I HAVE GOOD NEWS\n",
      "Prediction: I E E\n",
      "Word Error Rate:  75.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.16755890846252441\n",
      "1135/1135 [==============================] - 1293s 1s/step - loss: 110.1207 - val_loss: 111.1203 - lr: 2.0000e-04\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Original: BEHIND US THATS HUNDREDS OF PROGRAMMES AND THOUSANDS OF YOUR ANTIQUES VALUED AND SOLD\n",
      "Prediction: T E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.22209405899047852\n",
      "Original: IT DOESNT MATTER WHAT YOUR DENOMINATION IS\n",
      "Prediction: I E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.22709441184997559\n",
      "1135/1135 [==============================] - 1306s 1s/step - loss: 109.3719 - val_loss: 110.0166 - lr: 2.0000e-04\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Original: WHEN WE WERE LEAVING\n",
      "Prediction: I E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.29108715057373047\n",
      "Original: PEOPLE STICK WITH WHAT THEY KNOW\n",
      "Prediction: I E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.29608750343322754\n",
      "1135/1135 [==============================] - 1778s 2s/step - loss: 110.4225 - val_loss: 108.0006 - lr: 2.0000e-04\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Original: ONCE IVE HAD A WORD WITH HER\n",
      "Prediction: I E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.24115681648254395\n",
      "Original: SHES AWAY FROM HER FAMILY\n",
      "Prediction: I \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.24715662002563477\n",
      "1135/1135 [==============================] - 1963s 2s/step - loss: 109.6755 - val_loss: 111.1703 - lr: 2.0000e-04\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "Original: I THINK THAT MAY BE SLIGHTLY HOPEFUL\n",
      "Prediction: I E\n",
      "Word Error Rate:  85.71428571428571%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.2545313835144043\n",
      "Original: CANADIAN WINTER JACKETS\n",
      "Prediction: I E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.26253175735473633\n",
      "1135/1135 [==============================] - 1965s 2s/step - loss: 108.7900 - val_loss: 107.8550 - lr: 2.0000e-04\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Original: WHEN VISITORS ARRIVE\n",
      "Prediction: I \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.2160205841064453\n",
      "Original: THE SHOW WHERE A TEAM OF FIVE QUIZ CHALLENGERS PIT THEIR WITS AGAINST POSSIBLY THE GREATEST QUIZ\n",
      "Prediction: WH E E E E E E E E E E E T T T T T T T T TI\n",
      "Word Error Rate:  123.52941176470588%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.225020170211792\n",
      "1135/1135 [==============================] - 1969s 2s/step - loss: 108.9974 - val_loss: 109.5063 - lr: 2.0000e-04\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "Original: IF YOU COULD MAINTAIN AN ADVANTAGE\n",
      "Prediction: I \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.2641141414642334\n",
      "Original: ON BARGAIN HUNT\n",
      "Prediction: I N\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.27411413192749023\n",
      "1135/1135 [==============================] - 1960s 2s/step - loss: 106.7931 - val_loss: 107.4325 - lr: 2.0000e-04\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "Original: BECAUSE WHAT DAMAGE IS CAUSED NOW IN THE SHORT TERM IN THE INTERESTS OF FINANCIAL GAIN\n",
      "Prediction: IH E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.22256994247436523\n",
      "Original: BECAUSE THERES SOMETHING I WANT TO ASK YOU\n",
      "Prediction: I T TNT\n",
      "Word Error Rate:  87.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.23157262802124023\n",
      "1135/1135 [==============================] - 1978s 2s/step - loss: 108.8993 - val_loss: 107.0040 - lr: 2.0000e-04\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Original: FIVE QUID LUCK MONEY\n",
      "Prediction: I E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.23001837730407715\n",
      "Original: WHERE AM I AND WILL TODAYS BUYERS BE PUTTING THEIR MONEY WHERE THEIR MOUTH IS\n",
      "Prediction: IH E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.23401880264282227\n",
      "1135/1135 [==============================] - 1963s 2s/step - loss: 107.7192 - val_loss: 107.5134 - lr: 2.0000e-04\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Original: ARE THE CHANCES OF THEM BUYING SAID PROPERTY\n",
      "Prediction: I E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.25708460807800293\n",
      "Original: RATHER THAN JUST SITTING ON THEIR BOTTOMS\n",
      "Prediction: IE ER\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.2620847225189209\n",
      "1135/1135 [==============================] - 1988s 2s/step - loss: 107.6635 - val_loss: 107.5110 - lr: 2.0000e-04\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "Original: THE BETTER EQUIPPED WE ARE OF TAKING DOWN THE SUPER CLINIC\n",
      "Prediction: IE E E E ES\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.2715487480163574\n",
      "Original: I DONT AGREE WITH MARRIAGE\n",
      "Prediction: IH T T\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.2765498161315918\n",
      "1135/1135 [==============================] - 1965s 2s/step - loss: 106.7182 - val_loss: 105.6893 - lr: 2.0000e-04\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "Original: DOGS ARE FAMOUS FOR BEING MANS BEST FRIEND\n",
      "Prediction: I R\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.2015688419342041\n",
      "Original: WHAT I SAID ABOUT WHITNEY\n",
      "Prediction: IH T T TETE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.2055683135986328\n",
      "1135/1135 [==============================] - 2033s 2s/step - loss: 106.1434 - val_loss: 104.1905 - lr: 2.0000e-04\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Original: THERES ALWAYS HISTORICAL TREASURES TO LOOK AT\n",
      "Prediction: IH T T T T T T T T T T\n",
      "Word Error Rate:  157.14285714285714%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.22118759155273438\n",
      "Original: THE SOUTH COAST IN PARTICULAR BECAME REALLY FASHIONABLE\n",
      "Prediction: T T T T\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.22518706321716309\n",
      "1135/1135 [==============================] - 2427s 2s/step - loss: 106.7237 - val_loss: 106.6772 - lr: 2.0000e-04\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "Original: FOUR MINUTES AND FIFTY EIGHT SECONDS INTO YOUR FILM\n",
      "Prediction: IE E E T N\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.10451054573059082\n",
      "Original: I AM DISGUISED AS AN ONION SELLER\n",
      "Prediction: I N\n",
      "Word Error Rate:  85.71428571428571%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.10650968551635742\n",
      "1135/1135 [==============================] - 2136s 2s/step - loss: 104.9685 - val_loss: 104.4365 - lr: 2.0000e-04\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "Original: I LOVE ALL THE COLOURS\n",
      "Prediction: I E\n",
      "Word Error Rate:  80.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.17768526077270508\n",
      "Original: HOW ABOUT THAT FOR A VENUE TODAY\n",
      "Prediction: T T T ES\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.17968392372131348\n",
      "1135/1135 [==============================] - 1279s 1s/step - loss: 104.7193 - val_loss: 104.2914 - lr: 2.0000e-04\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "Original: JUST BECAUSE WEVE\n",
      "Prediction: I E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.17051386833190918\n",
      "Original: THIS TIME OF THE MORNING\n",
      "Prediction: IE EN\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.17251276969909668\n",
      "1135/1135 [==============================] - 1278s 1s/step - loss: 103.8054 - val_loss: 103.1612 - lr: 2.0000e-04\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "Original: PRESS LIFT BUTTONS\n",
      "Prediction: IH E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.12702107429504395\n",
      "Original: ITS THE FIRST TIME YOU MEET THE HORSE\n",
      "Prediction: IH E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.130018949508667\n",
      "1135/1135 [==============================] - 1285s 1s/step - loss: 106.1430 - val_loss: 102.6172 - lr: 2.0000e-04\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "Original: I DID A DREADFUL DEED TO MY BROTHER\n",
      "Prediction: IE E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.09551572799682617\n",
      "Original: WELL LOOK BACK AT SOME OF THE MOST MEMORABLE MOMENTS OF SONGS OF PRAISE\n",
      "Prediction: T T T T T RE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.09751319885253906\n",
      "1135/1135 [==============================] - 1281s 1s/step - loss: 104.1939 - val_loss: 103.1338 - lr: 2.0000e-04\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "Original: WHERE FOUR COUNTRIES ARE ABOUT TO GO HEAD TO HEAD\n",
      "Prediction: TH N\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.09751033782958984\n",
      "Original: WHICH IS WHY YOUVE GOT THIS WHITE IN THE GRAIN\n",
      "Prediction: IH R\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.09951114654541016\n",
      "1135/1135 [==============================] - 1280s 1s/step - loss: 103.8296 - val_loss: 102.8371 - lr: 1.9025e-04\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "Original: WE KNOW THAT BECAUSE THERE IS LESS DEVIATION IN YOUNG BIRDS IF THEY ARE ASSOCIATED WITH ADULT BIRDS\n",
      "Prediction: TH T T T T T T T T T T T T T T T TR\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.11235618591308594\n",
      "Original: THE MAIN CONCERN\n",
      "Prediction: I N\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.11435556411743164\n",
      "1135/1135 [==============================] - 1298s 1s/step - loss: 102.0669 - val_loss: 102.0349 - lr: 1.8097e-04\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Original: SO ITS NOT JUST ABOUT THE FIGHTING\n",
      "Prediction: I T\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.1595137119293213\n",
      "Original: WHAT IS WRONG WITH PEOPLE\n",
      "Prediction: I N\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.16251420974731445\n",
      "1135/1135 [==============================] - 1281s 1s/step - loss: 102.6391 - val_loss: 102.9989 - lr: 1.7214e-04\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "Original: THATS MY MAIN JOB\n",
      "Prediction: I N\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.15001368522644043\n",
      "Original: VERY GOOD EATING\n",
      "Prediction: I N\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.1530141830444336\n",
      "1135/1135 [==============================] - 1280s 1s/step - loss: 102.6024 - val_loss: 101.2202 - lr: 1.6375e-04\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Original: YOU HAVE NO IDEA WHAT THIS IS YEAH\n",
      "Prediction: T T T\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.16705846786499023\n",
      "Original: COME AND GET ME\n",
      "Prediction: T T\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.1700596809387207\n",
      "1135/1135 [==============================] - 1283s 1s/step - loss: 103.1850 - val_loss: 102.6641 - lr: 1.5576e-04\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "Original: STOCKS AND SHARES\n",
      "Prediction: I S\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.1350243091583252\n",
      "Original: ITS A CLASSIC FOOD PAIRING\n",
      "Prediction: I TN\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.1370236873626709\n",
      "1135/1135 [==============================] - 1283s 1s/step - loss: 101.4808 - val_loss: 100.7490 - lr: 1.4816e-04\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "Original: YOU DONT HAVE TO DO ALL THAT HARD WORK\n",
      "Prediction: T T\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.12325596809387207\n",
      "Original: IT WAS ABOUT SOCIABILITY\n",
      "Prediction: T T\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.12625718116760254\n",
      "1135/1135 [==============================] - 1281s 1s/step - loss: 102.2056 - val_loss: 99.9765 - lr: 1.4094e-04\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "Original: SO LETS GO BARGAIN HUNTING\n",
      "Prediction: I \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.14954376220703125\n",
      "Original: SIX FIGURES OR SO\n",
      "Prediction: I N\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.1525435447692871\n",
      "1135/1135 [==============================] - 1279s 1s/step - loss: 100.7168 - val_loss: 98.4240 - lr: 1.3406e-04\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "Original: IM NOT JEREMY VINE\n",
      "Prediction: I E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.1750342845916748\n",
      "Original: WE MET IN LONDON\n",
      "Prediction: I N\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.1770343780517578\n",
      "1135/1135 [==============================] - 1283s 1s/step - loss: 101.4512 - val_loss: 97.4064 - lr: 1.2753e-04\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "Original: WITHOUT FURTHER ADO\n",
      "Prediction: TH T T T \n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.13802218437194824\n",
      "Original: ONE TUTORIAL WITH THE BATTLE AXE LATER\n",
      "Prediction: T T\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.1410222053527832\n",
      "1135/1135 [==============================] - 1274s 1s/step - loss: 100.2162 - val_loss: 99.9981 - lr: 1.2131e-04\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "Original: ITS JUST A WEE VILLAGE\n",
      "Prediction: I N\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.12102437019348145\n",
      "Original: THAT SEEMS TO ME LIKE A PRETTY IMPRESSIVE PERK OF THE JOB BY ANYBODYS STANDARDS\n",
      "Prediction: T T T T T T T T B R R S\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.1240243911743164\n",
      "1135/1135 [==============================] - 1282s 1s/step - loss: 99.9190 - val_loss: 99.4229 - lr: 1.1539e-04\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "Original: THE RESISTANCE ARE DEVELOPING THE NEGATIVE\n",
      "Prediction: TE E E E E E E\n",
      "Word Error Rate:  116.66666666666667%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.1395113468170166\n",
      "Original: WE HAVE A GENTLEMENS CLUB AT MY HOUSE\n",
      "Prediction: IE R\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.1415114402770996\n",
      "1135/1135 [==============================] - 1278s 1s/step - loss: 100.0105 - val_loss: 97.0107 - lr: 1.0976e-04\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Original: THATS OUR PERMIT\n",
      "Prediction: TH R\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.13052868843078613\n",
      "Original: I CANT PROVE THERES NOT AN INVISIBLE UNICORN WELDING A TURD TO THE ROOF OF THIS BUILDING\n",
      "Prediction: I R R R N\n",
      "Word Error Rate:  94.11764705882352%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.1335287094116211\n",
      "1135/1135 [==============================] - 1283s 1s/step - loss: 99.0403 - val_loss: 97.5427 - lr: 1.0441e-04\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "Original: AND I DONT THINK IVE EVER\n",
      "Prediction: IE T T T E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.1736142635345459\n",
      "Original: THATS AN ODD ONE\n",
      "Prediction: T T N\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.17661476135253906\n",
      "1135/1135 [==============================] - 1282s 1s/step - loss: 99.1362 - val_loss: 98.3134 - lr: 9.9317e-05\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Original: ILL E MAIL YOU THE LINK\n",
      "Prediction: T R\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.14554834365844727\n",
      "Original: YOU MOVED AWAY FROM LUTON\n",
      "Prediction: I E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.14754867553710938\n",
      "1135/1135 [==============================] - 1288s 1s/step - loss: 100.8758 - val_loss: 97.7741 - lr: 9.4473e-05\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "Original: I THOUGHT HE WAS DOING IT FOR ME\n",
      "Prediction: TH T T T T T T T O\n",
      "Word Error Rate:  112.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.08305883407592773\n",
      "Original: EVERY SEPTEMBER THIS PLACE WOULD BE TRANSFORMED INTO WHAT WAS\n",
      "Prediction: WE E E LS\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.08705854415893555\n",
      "1135/1135 [==============================] - 1308s 1s/step - loss: 99.4324 - val_loss: 96.1805 - lr: 8.9866e-05\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Original: THE DIRTY LITTLE MARE\n",
      "Prediction: IT T T T T\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.25352978706359863\n",
      "Original: OF COURSE IT CAN\n",
      "Prediction: IE N\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.2565302848815918\n",
      "1135/1135 [==============================] - 1752s 2s/step - loss: 97.5671 - val_loss: 96.8054 - lr: 8.5483e-05\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "Original: I KNOW YOUR SORT\n",
      "Prediction: I \n",
      "Word Error Rate:  75.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.29253411293029785\n",
      "Original: WE HAVE TO BE CAREFUL\n",
      "Prediction: TH ENE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.2975330352783203\n",
      "1135/1135 [==============================] - 2038s 2s/step - loss: 96.6002 - val_loss: 96.1647 - lr: 8.1314e-05\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Original: ITS JUST AS WELL\n",
      "Prediction: IT S LS\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.31555795669555664\n",
      "Original: SHALL WE SCRAMBLE\n",
      "Prediction: WO L\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.3185577392578125\n",
      "1135/1135 [==============================] - 2068s 2s/step - loss: 96.0554 - val_loss: 96.9974 - lr: 7.7348e-05\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Original: AND WHAT YOU SAID EARLIER\n",
      "Prediction: I NE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.31972384452819824\n",
      "Original: FOUR CONTENDERS WHO HAVE MADE A GREAT SUCCESS OF THEIR LIVES\n",
      "Prediction: FE R T T T T T TE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0.32372426986694336\n",
      "1135/1135 [==============================] - 2074s 2s/step - loss: 98.1659 - val_loss: 94.5621 - lr: 7.3576e-05\n",
      "Epoch 44/300\n",
      "1135/1135 [==============================] - ETA: 0s - loss: 97.4026"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[36], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m300\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mcheckpointCallback2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexampleCallback2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduleCallback2\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1606\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1591\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_eval_data_handler\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1592\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eval_data_handler \u001B[38;5;241m=\u001B[39m data_adapter\u001B[38;5;241m.\u001B[39mget_data_handler(\n\u001B[0;32m   1593\u001B[0m         x\u001B[38;5;241m=\u001B[39mval_x,\n\u001B[0;32m   1594\u001B[0m         y\u001B[38;5;241m=\u001B[39mval_y,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1604\u001B[0m         steps_per_execution\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_steps_per_execution,\n\u001B[0;32m   1605\u001B[0m     )\n\u001B[1;32m-> 1606\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1607\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1608\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_y\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1609\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1610\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1611\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1612\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1613\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1614\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1615\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1616\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1617\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_use_cached_eval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1618\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1619\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m   1620\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name: val \u001B[38;5;28;01mfor\u001B[39;00m name, val \u001B[38;5;129;01min\u001B[39;00m val_logs\u001B[38;5;241m.\u001B[39mitems()\n\u001B[0;32m   1621\u001B[0m }\n\u001B[0;32m   1622\u001B[0m epoch_logs\u001B[38;5;241m.\u001B[39mupdate(val_logs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1947\u001B[0m, in \u001B[0;36mModel.evaluate\u001B[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[0;32m   1943\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1944\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m, step_num\u001B[38;5;241m=\u001B[39mstep, _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1945\u001B[0m ):\n\u001B[0;32m   1946\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_test_batch_begin(step)\n\u001B[1;32m-> 1947\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1948\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1949\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    951\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    952\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[0;32m    953\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[1;32m--> 954\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    955\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001B[0;32m    956\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    957\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2493\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   2494\u001B[0m   (graph_function,\n\u001B[0;32m   2495\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2496\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2497\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1858\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1859\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1860\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1861\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1862\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1863\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1864\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1865\u001B[0m     args,\n\u001B[0;32m   1866\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1867\u001B[0m     executing_eagerly)\n\u001B[0;32m   1868\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-07-29T01:01:33.193378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model2.compile(optimizer=Adam(learning_rate=0.0001), loss=CTCLoss)\n",
    "model2.fit(train, validation_data=test, epochs=300, callbacks=[checkpointCallback2, exampleCallback2], use_multiprocessing=True)"
   ],
   "id": "df68abce0cca2684",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "   2/1135 [..............................] - ETA: 7:09 - loss: 69.3661   "
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model2.load_weights('updatedModel_v1.weights.h5')\n",
    "\n",
    "model2.compile(optimizer=Adam(learning_rate=0.00006), loss=CTCLoss)\n",
    "# create all the callbacks \n",
    "checkpointCallback2 = ModelCheckpoint('updatedModel_v2.weights.h5', monitor='loss',save_weights_only=False, save_freq='epoch') # save checkpoints after each epoch\n",
    "exampleCallback2 = ProduceExample(test)\n",
    "scheduleCallback2 = LearningRateScheduler(scheduler)\n",
    "\n",
    "model2.fit(train, validation_data=test, epochs=300, callbacks=[checkpointCallback2, exampleCallback2, scheduler2()], use_multiprocessing=True)\n",
    "\n",
    "# finished with loss ~ 35"
   ],
   "id": "3b9c695e7fa6123e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T04:23:59.376930Z",
     "start_time": "2024-07-10T00:53:45.474628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model2.compile(optimizer=Adam(learning_rate=0.00002), loss=CTCLoss)\n",
    "# create all the callbacks \n",
    "checkpointCallback2 = ModelCheckpoint('updatedModel_v3.weights.h5', monitor='loss',save_weights_only=False, save_freq='epoch') # save checkpoints after each epoch\n",
    "exampleCallback2 = ProduceExample(test)\n",
    "scheduleCallback2 = LearningRateScheduler(scheduler)\n",
    "\n",
    "model2.fit(train, validation_data=test, epochs=300, callbacks=[checkpointCallback2, exampleCallback2, scheduleCallback2], use_multiprocessing=True)"
   ],
   "id": "9ed847ccbbdefe0d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Original: THROUGHOUT THIS YEAR RACHEL HAS MADE FOR THE FIRST TIME A CUT FLOWER GARDEN AND KEPT A DIARY OF IT\n",
      "Prediction: THROUGHOUT THIS YEAR RACHEL HAS MADE FOR THE FIRST TIME A CUT FLOWER GARDEN AND KEPT A DIARY OF IT\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I ENJOY GOING TO GIGS\n",
      "Prediction: I ENJOY GOING TO GIGS\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: OR YOU JUST FANCY HAVING A GO\n",
      "Prediction: I I E I E ET\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I WOULD SAY IM OPTIMISTIC\n",
      "Prediction: I WOULD SAY IM OPTIMISTIC\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2698s 4s/step - loss: 36.4023 - val_loss: 32.2581 - lr: 2.0000e-05\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "Original: JUST TO BRING BACK THESE EXOTIC SPICES FOR US TO ENJOY\n",
      "Prediction: JUST TO BRING BACK THESE EXOTIC SPICES FOR US TO ENJOY\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: FIVE CONTENDERS TONIGHT\n",
      "Prediction: FIVE CONTENDERS TONIGHT\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE PREPARATORY WORK IS ALL IMPORTANT\n",
      "Prediction: WHE E A O A O A O A\n",
      "Word Error Rate:  150.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: RECKONED TO BE WORTH AROUND TWO BILLION TO THE UK ECONOMY\n",
      "Prediction: BE E AN HAN TEMI TI ENE PEA TO E I BESTI\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2163s 3s/step - loss: 36.9049 - val_loss: 32.1921 - lr: 2.0000e-05\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "Original: GARAGE AND TECHNO FUNK\n",
      "Prediction: INE A ANE SOE PECEN O FUNK\n",
      "Word Error Rate:  150.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: MY GRANDMOTHERS RECIPE FOR HER YORKSHIRE PUDDING\n",
      "Prediction: IN N TERASOINT TI OR AR HONE EN OTIN\n",
      "Word Error Rate:  128.57142857142858%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: CONSTANTINE THE GREAT\n",
      "Prediction: THE E TE TO E\n",
      "Word Error Rate:  166.66666666666669%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: MY MONEY WAS ON NAOMI RUSHBROOK\n",
      "Prediction: WA BARTIE ONDINS AN BUSTROK\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2272s 3s/step - loss: 34.6706 - val_loss: 28.6365 - lr: 2.0000e-05\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "Original: FOUR CONTENDERS WITH US THIS EVENING WHOSE CONFIDENCE MAY HAVE BEEN BOOSTED AS MUCH AS POSSIBLE BY\n",
      "Prediction: FOUR CONTENDERS WITH US THIS EVENING WHOSE CONFIDENCE MAY HAVE BEN BOSTED AS UACUSTHENAND SAM HOY\n",
      "Word Error Rate:  35.294117647058826%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHAT ELSE CAN I BE\n",
      "Prediction: WHI IT E HAN TI BE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THIS IS THE PROGRAMME THAT TESTS OUR CONTENDERS ON THREE LEVELS\n",
      "Prediction: TS WOE FRS SOE TA E I E STISR AERSTALE O SPE TE ESINS\n",
      "Word Error Rate:  127.27272727272727%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I DONT MEAN SHES A WOMAN\n",
      "Prediction: I DONT MEAN SHES A WOMAN\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2329s 4s/step - loss: 36.0265 - val_loss: 32.7497 - lr: 2.0000e-05\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "Original: HE REWROTE THE RULES SO IT BECAME ALL ABOUT BECOMING AS RICH AS POSSIBLE AND BANKRUPTING ALL THE\n",
      "Prediction: HE REWROTE THE RULES SO IT BECAME AL ABOUT BECOMING AS RICH AS POSIBLE AND MAN ORTCAUR\n",
      "Word Error Rate:  27.77777777777778%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: CHARLIE HAD SUCH GOOD SUCCESS YESTERDAY\n",
      "Prediction: SOE IS IT THAME TIA THA\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS IN TWENTY FOUR HOURS\n",
      "Prediction: IE WAN A O O OE\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: YOUVE GOT A BAPTIST CHURCH\n",
      "Prediction: IS BE THAR HE UCH\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2267s 3s/step - loss: 35.5068 - val_loss: 30.5419 - lr: 2.0000e-05\n",
      "Epoch 6/300\n",
      "574/662 [=========================>....] - ETA: 2:15 - loss: 35.7935"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[34], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m exampleCallback2 \u001B[38;5;241m=\u001B[39m ProduceExample(test)\n\u001B[0;32m      5\u001B[0m scheduleCallback2 \u001B[38;5;241m=\u001B[39m LearningRateScheduler(scheduler)\n\u001B[1;32m----> 7\u001B[0m \u001B[43mmodel2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m300\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mcheckpointCallback2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexampleCallback2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduleCallback2\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1564\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1556\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1557\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1558\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1561\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1562\u001B[0m ):\n\u001B[0;32m   1563\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1564\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1565\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1566\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateless_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2493\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   2494\u001B[0m   (graph_function,\n\u001B[0;32m   2495\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2496\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2497\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1858\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1859\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1860\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1861\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1862\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1863\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1864\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1865\u001B[0m     args,\n\u001B[0;32m   1866\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1867\u001B[0m     executing_eagerly)\n\u001B[0;32m   1868\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-10T04:25:04.652689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model2.compile(optimizer=Adam(learning_rate=0.000007), loss=CTCLoss)\n",
    "# create all the callbacks \n",
    "checkpointCallback2 = ModelCheckpoint('updatedModel_v4.weights.h5', monitor='loss',save_weights_only=False, save_freq='epoch') # save checkpoints after each epoch\n",
    "exampleCallback2 = ProduceExample(test)\n",
    "scheduleCallback3 = LearningRateScheduler(scheduler2)\n",
    "\n",
    "model2.fit(train, validation_data=test, epochs=300, callbacks=[checkpointCallback2, exampleCallback2, scheduleCallback3], use_multiprocessing=True)"
   ],
   "id": "f11b486a3e527ff3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Original: IT WAS A DECADE OF MASSIVE SOCIAL AND POLITICAL CHANGE BUT FOR THOSE OF US WHO LIVED THROUGH IT\n",
      "Prediction: IE I E AD OF MASIVE SOCIAL AND POLITICAL CHANGE BUT FOR THOSE OF US WHO LIVED THROUGH IT\n",
      "Word Error Rate:  26.31578947368421%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHEN IT COMES TO DESIGNING FABULOUS COSTUMES\n",
      "Prediction: WHE IS O A O I IN T\n",
      "Word Error Rate:  114.28571428571428%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: MARY AND JANE PARMENTER\n",
      "Prediction: MARY AND JANE PARMENTER\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WELCOME TO EGGHEADS\n",
      "Prediction: WELCOME TO EGHEADS\n",
      "Word Error Rate:  33.33333333333333%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2006s 3s/step - loss: 35.4785 - val_loss: 30.0917 - lr: 6.3339e-06\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "Original: THATS WHAT YOU THINK\n",
      "Prediction: WH E A OIN\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: HOW ABOUT SAYING\n",
      "Prediction: HOWOW ABOUT SAYING\n",
      "Word Error Rate:  33.33333333333333%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: FIVE AND THEN THIS ONE HAD SIX\n",
      "Prediction: WIVE AV AND THEN THIS ONE HAD SIX\n",
      "Word Error Rate:  28.57142857142857%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THERE IS NO ONE TO HOLD MY ORSE\n",
      "Prediction: H E T TO ARAR\n",
      "Word Error Rate:  87.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 1428s 2s/step - loss: 35.6308 - val_loss: 32.8134 - lr: 5.7311e-06\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "Original: FROM THEIR FORTIFIED PALACES\n",
      "Prediction: FROM THEIR FORTIFIED PALACES\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: LETS JUST CALM DOWN\n",
      "Prediction: LETS JUST CALM DOWN\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEY ALREADY HAD A SCIENTIFIC NAME\n",
      "Prediction: TY A CANY AD A STIENT OF CICE NAME\n",
      "Word Error Rate:  116.66666666666667%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: A GREAT SELECTION OF ANTIQUES SHOPS\n",
      "Prediction: I I O ON OR R R\n",
      "Word Error Rate:  116.66666666666667%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 1512s 2s/step - loss: 36.0024 - val_loss: 30.5199 - lr: 5.1857e-06\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "Original: SOMEHOW WE MUST RAISE MONEY\n",
      "Prediction: TH A A A A IN \n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: COMES FROM NOTTINGHAM\n",
      "Prediction: CE FOFO TOTINGHAM\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ACTUALLY COMES FROM THE WORD FOR KIDNEY\n",
      "Prediction: A A A E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IF YOU CANT BE WITH KUSH\n",
      "Prediction: I O TA A I ON\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 1559s 2s/step - loss: 35.4174 - val_loss: 30.1066 - lr: 4.6922e-06\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "Original: I THINK IT WOULD PROBABLY IN MOST SENSES\n",
      "Prediction: I WAT O A A E O A A\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: LETS NOT GET CARRIED AWAY\n",
      "Prediction: I E E O O AM\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SEVERAL HUNDRED YEARS AGO\n",
      "Prediction: SEVERAL HUNDRED YEARS AGO\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHEN I WAS IN MY S\n",
      "Prediction: WHE E O A O\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 1418s 2s/step - loss: 35.8165 - val_loss: 32.2309 - lr: 4.2457e-06\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "Original: WEVE GOT HIGH VALUATIONS AND AUCTION TENSION\n",
      "Prediction: WEVE GOT HIGH VALUATIONS AND AUCTION TENSION\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WORKING ALL HOURS\n",
      "Prediction: B OY ACA AN\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: FOUR MORE FAMOUS FACES WILL SHOW US WHAT THEY KNOW ABOUT THEIR SPECIALIST SUBJECT AND HOW MUCH\n",
      "Prediction: IT TIS CON DRER RME CUIE O O A OR EVOEN OSOESANE OS EN TI\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: COUNTERTERROR POLICE TRY TO TRACE THREE MISSING SCHOOLGIRLS FROM EAST LONDON WHO ARE HEADING FOR\n",
      "Prediction: ID ID O O O T O OD S\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 1510s 2s/step - loss: 34.2505 - val_loss: 32.6265 - lr: 3.8417e-06\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "Original: IVE BEEN VERY FORTUNATE AND IVE DANCED IN MAJOR FINALS AT BLACKPOOL DANCE\n",
      "Prediction: IVE BEN VERY FORTUNATE AND IVE DANCED IN M JOR FO A HA HO GO O O O \n",
      "Word Error Rate:  84.61538461538461%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ACCORDING TO THE KENNEL CLUBS LATEST DATA\n",
      "Prediction: AN DOINT THAN TO KE WE BINBIN TEAT ASI HIS\n",
      "Word Error Rate:  128.57142857142858%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: YOUVE MADE THE PROMISE\n",
      "Prediction: WE ER E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: TO ASK THAT ALL IMPORTANT QUESTION\n",
      "Prediction: WEA TA TA IN AT PEOPESTION\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 1970s 3s/step - loss: 35.5586 - val_loss: 32.0773 - lr: 3.4761e-06\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "Original: WE WORK TOGETHER\n",
      "Prediction: WE WORK TOGETHER\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND I REALLY HOPE\n",
      "Prediction: I I I TE\n",
      "Word Error Rate:  75.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND THEYRE LOOKING FOR ALL THESE WONDERFUL SIGNS OF AUTUMN\n",
      "Prediction: AND THEYRE LOKING FOR AL THESE WIN OS PILO HEN\n",
      "Word Error Rate:  60.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SIX HUNDRED SQUARE METRES AT A GUIDE PRICE OF NINETY FIVE\n",
      "Prediction: LAS THUNENS TINE COAC TANSE H E BAESE ININY MOF HIVE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2180s 3s/step - loss: 35.7872 - val_loss: 31.7321 - lr: 3.1453e-06\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "Original: HES ONE OF THE PEOPLE IVE BEEN COACHING\n",
      "Prediction: ITS ONE OF THE PEOPLE IVE BEN COACHING\n",
      "Word Error Rate:  25.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IM INVITING EVERYBODY HERE TO BRING IN TWO THOUSAND AND WHATEVER IT IS\n",
      "Prediction: I AV OVE ONE ONY AE TO BRINGINT SES WAT THAT WT HOURED I\n",
      "Word Error Rate:  107.6923076923077%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND FROSTING IT\n",
      "Prediction: BHT AE O IN HT TEIT NST PATA\n",
      "Word Error Rate:  266.66666666666663%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: YOU ARE FRIENDLY WITH THE COLONEL\n",
      "Prediction: I WE E E ANE E ONE\n",
      "Word Error Rate:  116.66666666666667%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2119s 3s/step - loss: 33.1725 - val_loss: 32.2176 - lr: 2.8460e-06\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "Original: I DONT WANT TO TALK ABOUT IT\n",
      "Prediction: IDINT WANT TO TALK ABOUT IT\n",
      "Word Error Rate:  28.57142857142857%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEY STARTED THE WHOLE THING\n",
      "Prediction: WHE E O TEN\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE FIRST MUSLIM WOMAN TO SERVE AS A CABINET MINISTER\n",
      "Prediction: THE E A I A A A E A ON ON I T\n",
      "Word Error Rate:  110.00000000000001%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: HE WOULD HAVE LEFT IT OVERNIGHT\n",
      "Prediction: WE E E TOE ON \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2129s 3s/step - loss: 34.8191 - val_loss: 31.5654 - lr: 2.5752e-06\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "Original: SPACE TO GROW THINGS\n",
      "Prediction: I E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND DEPART WITH THE FINANCIAL BACKING OF A MULTI MILLIONAIRE DRAGON INVESTOR\n",
      "Prediction: AND DEPART WITH THE FINANCIAL BACKING OF A MULTIE INI STUAT PNT\n",
      "Word Error Rate:  33.33333333333333%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IVE DEFINITELY HAD IT\n",
      "Prediction: I E O INY THE L\n",
      "Word Error Rate:  150.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IVE NEVER TRIED TO REPLACE YOUR MUM\n",
      "Prediction: THUS NO RIED O OBULE MOUNE N\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2107s 3s/step - loss: 35.3964 - val_loss: 30.1299 - lr: 2.3301e-06\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "Original: THIS WAS A BARREN LANDSCAPE NO LEVEL GROUND\n",
      "Prediction: THIS WAS A BAREN LANDSCAPE NO LEVEL GROUND\n",
      "Word Error Rate:  12.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: YOUR PRESENCE IS ENOUGH OF A PRESENT FOR ME\n",
      "Prediction: YOURPRESENCE IS ENOUGH OF A PRESENT ING TE\n",
      "Word Error Rate:  44.44444444444444%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WE HAVE TAKEN THEIR PLACE\n",
      "Prediction: WE HINT U E AN TRAM SESE\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHY YOU COVER FOR HIM\n",
      "Prediction: AS AR\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2124s 3s/step - loss: 35.1665 - val_loss: 32.0968 - lr: 2.1084e-06\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "Original: A CASTLE THATS DOMINATED THE LANDSCAPE EVER SINCE THE MIDDLE AGES\n",
      "Prediction: A CASTLE THATS DOMINATED THE LANDSCAPE EVER SINCE THE MIDLE EGUNH\n",
      "Word Error Rate:  18.181818181818183%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: MY LEGS WERE OK\n",
      "Prediction: AI BELER OUNON\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ALL AFTER A VALUATION AND ALL EAGER TO GET INSIDE\n",
      "Prediction: E E BE TE TH O TO O BE TENET E\n",
      "Word Error Rate:  110.00000000000001%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IM TICKETY BOO\n",
      "Prediction: I I WOMWACS SELIN\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2107s 3s/step - loss: 35.3406 - val_loss: 32.8943 - lr: 1.9077e-06\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "Original: I CANT HELP MYSELF\n",
      "Prediction: WE E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHICH WILL LATER BE TAKEN TO AUCTION WHERE THEYLL BE SOLD AND THE TEAM THAT WINS IS THE TEAM THAT\n",
      "Prediction: WET IE O E E O O T E E E ON I THER T TO T OD DEDE ERT TIE\n",
      "Word Error Rate:  105.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE NATURAL HOME\n",
      "Prediction: THE HE PRE HOUR MY U A\n",
      "Word Error Rate:  200.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SCALE AND MAYBE AN INTERESTING FOCAL POINT FOR YOUR VIEWER TO DISCOVER\n",
      "Prediction: SHALE AND MAYBE AN RE RIRESTON THE TET UN F FOUR EVIE WER TO IR GAVE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2102s 3s/step - loss: 35.2602 - val_loss: 32.1400 - lr: 1.7262e-06\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "Original: TO FIND OUT IF THE TUMOURS SHRUNK\n",
      "Prediction: TO E I O ON TE\n",
      "Word Error Rate:  85.71428571428571%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE UNDERLYING PATTERN WAS CLEAR\n",
      "Prediction: THE UNDERLYING PATERN WAS CLEAR\n",
      "Word Error Rate:  20.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE KING IS NOT ALONE HE HAS DARTAGNAN\n",
      "Prediction: THE KING IS NOT ALONE HE HEY STMALIN\n",
      "Word Error Rate:  25.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BUT SHES NOT CONFUSED\n",
      "Prediction: BETHE THE ONG A OU\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2103s 3s/step - loss: 35.0421 - val_loss: 33.8047 - lr: 1.5619e-06\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "Original: WERE QUITE SERIOUS\n",
      "Prediction: WHE A A E\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SO ITS A MASSIVE RISK\n",
      "Prediction: I S S O I I\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IF SOMEBODY WHO UNFORTUNATELY HAS RENAL CANCER OR KIDNEY CANCER\n",
      "Prediction: I O E E O TH E E E E TENE E BE\n",
      "Word Error Rate:  130.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: COME TO MY BOSOM\n",
      "Prediction: SHS O THS HISE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2097s 3s/step - loss: 35.3031 - val_loss: 30.0062 - lr: 1.4133e-06\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "Original: I KNOW WHAT YOURE LIKE\n",
      "Prediction: I KNOW WHAT YOURE LIKE\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHICH IS BOTH A CITY AND A REGION ON THE SPANISH MEDITERRANEAN COAST\n",
      "Prediction: WO A A A TIS TAD AD REGION ON THE SPANISH MEDOITAS MON LORS\n",
      "Word Error Rate:  69.23076923076923%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SOMEBODY WHO HAS BEEN TRIPPING THE LIGHT FANTASTIC\n",
      "Prediction: SOMY MAE SE OUN LOTS A THIR OA MOINS\n",
      "Word Error Rate:  112.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: EVEN THOUGH THERES SOMETHING WHICH CAN BE QUITE POMPOUS ABOUT IT AND QUITE SORT OF HAUGHTY\n",
      "Prediction: THE MENE TUTHUR SRMET THE TE TO EGHE TEMASESIET DOE OUT OF TH PE S\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2103s 3s/step - loss: 35.3080 - val_loss: 31.0874 - lr: 1.2788e-06\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "Original: IF YOU CAN LEAD ME\n",
      "Prediction: I A A A \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: COMING UP ON TONIGHTS SHOW\n",
      "Prediction: COMING UP ON TONIGHTS SHOW\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WAS WILLIAM CAXTON\n",
      "Prediction: WHE I WE EL\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: INDIGENOUS PEOPLE AND RELATIVELY FEW EUROPEANS THAT CREATED SOME OF THE ESSENTIAL CHARACTERISTICS\n",
      "Prediction: I E O E E E E E A HE A AN TO E I ENER\n",
      "Word Error Rate:  123.07692307692308%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2091s 3s/step - loss: 35.1188 - val_loss: 31.6047 - lr: 1.1571e-06\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "Original: IF YOU GOT A POINT TO MAKE\n",
      "Prediction: IF YOU GOT A POINT TO MAKE\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS NOT SO BAD\n",
      "Prediction: ITS NOT SO BAD\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I ENJOY WATCHING SPORT ON TV\n",
      "Prediction: I N NOY WON CH POS TYIY IT CAT\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE SOUTH COAST IN PARTICULAR BECAME REALLY FASHIONABLE\n",
      "Prediction: WHT WHE THAS PIN LONTON WUN U THU H UT\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2104s 3s/step - loss: 34.6158 - val_loss: 32.7251 - lr: 1.0470e-06\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "Original: ARE YOU GOING HOME FOR THE HOLIDAYS\n",
      "Prediction: WR YOUROING HOME FOR THE HOLIDAYS\n",
      "Word Error Rate:  42.857142857142854%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHAT DID YOU PUT IN THE MULLED WINE\n",
      "Prediction: THAT DID YOU PUT IN THE MULED WINE\n",
      "Word Error Rate:  25.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IF YOU TAKE THAT LONELINESS AWAY FROM IT\n",
      "Prediction: T AT LON EN TA ONO THAND BANY Y\n",
      "Word Error Rate:  112.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: FIVE CONTENDERS TONIGHT\n",
      "Prediction: THIS ARIT GOD SECRA HAGHE\n",
      "Word Error Rate:  166.66666666666669%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2093s 3s/step - loss: 33.9601 - val_loss: 31.7795 - lr: 9.4735e-07\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "Original: THE FIRST WAS THE SECRET INTELLIGENCE SERVICE\n",
      "Prediction: THE FIRST WAS THE SECRET INTELIGENCE SERVICE\n",
      "Word Error Rate:  14.285714285714285%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS BEEN A POPULAR HOLIDAY DESTINATION FOR WELL OVER ONE HUNDRED YEARS\n",
      "Prediction: ITS BEN A POPULAR HOLIDAY DESTINATION FOR WEL ON ERT THE AY YEARS\n",
      "Word Error Rate:  50.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: LETS PLAY A GAME\n",
      "Prediction: SOTE TA LG GHAVE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IT SEEMED TO BE\n",
      "Prediction: IS WARED OME OR\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2105s 3s/step - loss: 34.6373 - val_loss: 31.1932 - lr: 8.5719e-07\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "Original: AND I WOULD LIKE THAT FOR MYSELF\n",
      "Prediction: I O E O I R\n",
      "Word Error Rate:  85.71428571428571%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IN MY HOME COUNTY\n",
      "Prediction: IN MY HOME COUNTY\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: CHARLIE HAD SUCH GOOD SUCCESS YESTERDAY\n",
      "Prediction: SO E O T CES STESDAY\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE NUMBER OF HORSES IN BRITAIN DROPPED DRAMATICALLY BECAUSE OF THE USE OF CARS AND TRACTORS\n",
      "Prediction: THEN NUBER O GOY SHINTIT TOUHAS EA US IEARGLAYT SISOS HO EN CO A A THATOR\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2099s 3s/step - loss: 35.0029 - val_loss: 33.3531 - lr: 7.7562e-07\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "Original: IVE NEVER HEARD OF THAT\n",
      "Prediction: IN E E AN I\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS THAT TIME OF THE DAY AGAIN\n",
      "Prediction: ITS THAT TIME OF THE DAY AGAIN\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ALL IVE GOT IN HERE IS MY LAUNDRY\n",
      "Prediction: I E E T TN T\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WE WOULD NOT HAVE A SHOW\n",
      "Prediction: W O O A \n",
      "Word Error Rate:  83.33333333333334%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2120s 3s/step - loss: 34.8716 - val_loss: 30.3236 - lr: 7.0181e-07\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "Original: REGULARLY WITH THE COURT\n",
      "Prediction: REGULARLY WITH THE COURT\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: COS YOU CAN HARDLY HEAR OVER THE FAN\n",
      "Prediction: COS YOU CAN HARDLY HEAR OVER THE FAN\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE USUAL RULES APPLY A MINUTE AND A HALF ON THEIR SPECIALIST SUBJECT AND TWO MINUTES ON GENERAL\n",
      "Prediction: THEN LE ILE ORS TE WA O HANE AN A I E TPON ELT RO TEROUN HE IE BEAL\n",
      "Word Error Rate:  105.55555555555556%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I GET THE OPPORTUNITY TO EXPLORE THE BRONTES HOME\n",
      "Prediction: I INTE TOY A PLORE THE BIE TORE\n",
      "Word Error Rate:  77.77777777777779%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2106s 3s/step - loss: 35.7334 - val_loss: 33.9456 - lr: 6.3502e-07\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "Original: ITS COMPANY POLICY\n",
      "Prediction: S IS TO E A \n",
      "Word Error Rate:  166.66666666666669%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE BEST THING FOR YOU WOULD BE TO STAY AS FAR AWAY FROM ME AS POSSIBLE\n",
      "Prediction: THE E THING FOR YOU WOULD BE TO STAY AS FAR AWAY FROM ME AS POE TETE\n",
      "Word Error Rate:  18.75%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: GET YOU A DRINK\n",
      "Prediction: I E O E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: LETS GO BARGAIN HUNTING\n",
      "Prediction: ES GO GOHANG ST THAN\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2111s 3s/step - loss: 34.7869 - val_loss: 32.4313 - lr: 5.7459e-07\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "Original: DONT LETS BOTHER DRESSING UP\n",
      "Prediction: TO E A O O IG\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IM NOT WILD ABOUT IT\n",
      "Prediction: SO ON CON\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: HE ROLLED ACROSS CENTRAL ASIA LIKE A SANDSTORM A CENTURY AFTER GENGHIS KHAN\n",
      "Prediction: I E O E TO O I O OE O A O HA E THE HE\n",
      "Word Error Rate:  115.38461538461537%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: HES CHARLIES DAD\n",
      "Prediction: A AE AE ERE HATIAN\n",
      "Word Error Rate:  166.66666666666669%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2105s 3s/step - loss: 34.4697 - val_loss: 30.3074 - lr: 5.1991e-07\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "Original: WHY WOULDNT THEY\n",
      "Prediction: WHY WOULDNT THEY\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE PATTERNS WENT A LITTLE BIT\n",
      "Prediction: THA ATES WENT A LITLE BIT\n",
      "Word Error Rate:  50.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEY KNOW WHAT THEYRE DOING\n",
      "Prediction: THEY KNOW WHAT THEYRE DOING\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: GARAGE AND TECHNO FUNK\n",
      "Prediction: GHARG AEN SE ETA TETHIN LIKE\n",
      "Word Error Rate:  150.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2107s 3s/step - loss: 35.9058 - val_loss: 30.9014 - lr: 4.7044e-07\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "Original: I HONOURED MY FATHER WHILE HE WAS ALIVE\n",
      "Prediction: I O O O HE HE TO E E\n",
      "Word Error Rate:  87.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHAT MONEY WE GET\n",
      "Prediction: WHAT MONEY WE GET\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I HAVE TO WRITE THEM DOWN JUST LIKE THEY DID WITH THE BIBLE\n",
      "Prediction: I HAVE TO WRITE THEM DOWN UST LIE EOL TIARCDEIG THOUNE\n",
      "Word Error Rate:  53.84615384615385%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THINGS HAVE GONE FROM BAD TO WORSE\n",
      "Prediction: THINGS HVE BEN DR ONT AMN \n",
      "Word Error Rate:  85.71428571428571%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2095s 3s/step - loss: 35.5868 - val_loss: 33.1286 - lr: 4.2567e-07\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "Original: LETTER BY LETTER\n",
      "Prediction: TETAR BY LETER\n",
      "Word Error Rate:  66.66666666666666%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: YOU HAVE TO LOOK AT BROWN BEARS OR POLAR BEARS\n",
      "Prediction: YOU HAVE TRO OA AT BRON BEARS OR POLAR BEARS\n",
      "Word Error Rate:  30.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BUT EVERYONE GOING INTO THE DEN GETS A FRESH CHANCE TO TURN THINGS ROUND\n",
      "Prediction: BUT EVERYONE GOING INTO TO EME HEN OT E STS CHOACH A TOT THER THE COUND\n",
      "Word Error Rate:  85.71428571428571%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHAT WERE LOOKING FOR IS WHIPPED\n",
      "Prediction: I E TO E I O O T\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2079s 3s/step - loss: 34.6899 - val_loss: 32.5525 - lr: 3.8516e-07\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "Original: ILL BE DISCOVERING THE SCIENCE BEHIND THAT THINKING\n",
      "Prediction: IL BE DISCOVERING THE SCIENCE BEHIND THAT THINKING\n",
      "Word Error Rate:  12.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: PRESS LIFT BUTTONS\n",
      "Prediction: I LAT BOUS\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: HOW MANY DO YOU WANT ME TO SELL\n",
      "Prediction: THE O O O AN NOT TO M LILOD\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IN THIS WEEK OF REMEMBRANCE\n",
      "Prediction: IE HE E OR OR ORLET\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2104s 3s/step - loss: 34.0625 - val_loss: 31.6914 - lr: 3.4851e-07\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "Original: IM TALKING SHOTS\n",
      "Prediction: IM TALKING SHOTS\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: CAN THEY STAY AHEAD AND BEAT THE PACK\n",
      "Prediction: CAN THEY STAY AHEAD AND BEAT THE PACK\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THIS IS A PLACE OF WORK\n",
      "Prediction: TH O O O \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: CHARTERING A SPECIAL TRAIN\n",
      "Prediction: IMIE TET TATH OE NE ORESOINT IN\n",
      "Word Error Rate:  175.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "662/662 [==============================] - 2227s 3s/step - loss: 34.7448 - val_loss: 33.4997 - lr: 3.1534e-07\n",
      "Epoch 32/300\n",
      "662/662 [==============================] - ETA: 0s - loss: 34.7501"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[36], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m exampleCallback2 \u001B[38;5;241m=\u001B[39m ProduceExample(test)\n\u001B[0;32m      5\u001B[0m scheduleCallback3 \u001B[38;5;241m=\u001B[39m LearningRateScheduler(scheduler2)\n\u001B[1;32m----> 7\u001B[0m \u001B[43mmodel2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m300\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mcheckpointCallback2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexampleCallback2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduleCallback3\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1606\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1591\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_eval_data_handler\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1592\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eval_data_handler \u001B[38;5;241m=\u001B[39m data_adapter\u001B[38;5;241m.\u001B[39mget_data_handler(\n\u001B[0;32m   1593\u001B[0m         x\u001B[38;5;241m=\u001B[39mval_x,\n\u001B[0;32m   1594\u001B[0m         y\u001B[38;5;241m=\u001B[39mval_y,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1604\u001B[0m         steps_per_execution\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_steps_per_execution,\n\u001B[0;32m   1605\u001B[0m     )\n\u001B[1;32m-> 1606\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1607\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1608\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_y\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1609\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1610\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1611\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1612\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1613\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1614\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1615\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1616\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1617\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_use_cached_eval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1618\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1619\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m   1620\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name: val \u001B[38;5;28;01mfor\u001B[39;00m name, val \u001B[38;5;129;01min\u001B[39;00m val_logs\u001B[38;5;241m.\u001B[39mitems()\n\u001B[0;32m   1621\u001B[0m }\n\u001B[0;32m   1622\u001B[0m epoch_logs\u001B[38;5;241m.\u001B[39mupdate(val_logs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1947\u001B[0m, in \u001B[0;36mModel.evaluate\u001B[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[0;32m   1943\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1944\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m, step_num\u001B[38;5;241m=\u001B[39mstep, _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1945\u001B[0m ):\n\u001B[0;32m   1946\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_test_batch_begin(step)\n\u001B[1;32m-> 1947\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1948\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1949\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    951\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    952\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[0;32m    953\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[1;32m--> 954\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    955\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001B[0;32m    956\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    957\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2493\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   2494\u001B[0m   (graph_function,\n\u001B[0;32m   2495\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2496\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2497\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1858\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1859\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1860\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1861\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1862\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1863\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1864\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1865\u001B[0m     args,\n\u001B[0;32m   1866\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1867\u001B[0m     executing_eagerly)\n\u001B[0;32m   1868\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T22:14:48.094443Z",
     "start_time": "2024-07-10T22:14:47.867720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = model2.history.history['loss']\n",
    "test_loss = model2.history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ],
   "id": "6eff0658378dde17",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T22:14:52.406743Z",
     "start_time": "2024-07-10T22:14:51.425033Z"
    }
   },
   "cell_type": "code",
   "source": "value, yHat, decoded = makePrediction(model2)",
   "id": "2a4447c34db46abd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 549ms/step\n",
      "Original: THEY THINK I SWAN ROUND MAYFAIR SPENDING RICH PEOPLES MONEY\n",
      "Prediction: THEY THINK I SWAN ROUND MAYFAIR SPENDING RICH PEOPLES MONEY\n",
      "Word Error Rate on Prediction: 0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: HE WAS VERY HAPPY\n",
      "Prediction: HE WAS VERY HAPY\n",
      "Word Error Rate on Prediction: 25.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: DO I HAVE A MOBILE\n",
      "Prediction: YO I HAVE A MOBILE\n",
      "Word Error Rate on Prediction: 20.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: CHRIS IS STAYING IN AUSTRALIA\n",
      "Prediction: TE A E O A E\n",
      "Word Error Rate on Prediction: 120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Avg Word Error Rate: 33.33333333333333%\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290, 40, 120, 1)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 111,
   "source": "val[0][0].shape",
   "id": "949ed77bc9baf9e7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T23:24:53.059945Z",
     "start_time": "2024-07-05T23:24:53.055433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def padTensor(tensor, target_shape, padding_value=0):\n",
    "  \"\"\"Pads a tensor to the specified target shape with a given padding value.\n",
    "\n",
    "  Args:\n",
    "      tensor: The tensor to be padded.\n",
    "      target_shape: The desired padded shape.\n",
    "      padding_value: The value to use for padding (default: 0).\n",
    "\n",
    "  Returns:\n",
    "      The padded tensor.\n",
    "  \"\"\"\n",
    "\n",
    "  paddings = [[0, target_shape[0] - tensor.shape[0]],  # Pad leading and trailing dimensions 0\n",
    "             [0, target_shape[1] - tensor.shape[1]],  # for the first 3 dimensions\n",
    "             [0, target_shape[2] - tensor.shape[2]],\n",
    "             [0, target_shape[3] - tensor.shape[3]]]  # Pad only for dimension 3\n",
    "  return tf.pad(tensor, paddings, constant_values=padding_value)\n",
    "  \n",
    "def fixPath(path): \n",
    "    return path.replace('\\\\', '\\\\\\\\')\n",
    "  "
   ],
   "id": "4192a78f190f1ea5",
   "outputs": [],
   "execution_count": 198
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T23:35:20.759129Z",
     "start_time": "2024-07-05T23:35:20.744128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def loadData2(fileName): \n",
    "    # tf has the paths as bytes so decode that\n",
    " \n",
    "    # generate the respective paths of the data\n",
    "    vidName = fileName + (\".mp4\")\n",
    "    txtName = fileName + (\".txt\")\n",
    "    print(vidName)\n",
    "    videoPath = os.path.join(rootDir2, \"customVids\", vidName)\n",
    "    alignmentPath = os.path.join(rootDir2, \"customVids\", txtName)\n",
    "    \n",
    "    # return the frames and alignments\n",
    "    frames = loadVideo(videoPath) \n",
    "    alignments = loadText(alignmentPath)\n",
    "    return frames, alignments\n",
    "\n",
    "def loadVideo2(path, ): \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    global lastKnownCrop, frameSizeOld, frameSize, newFrameSize, grayFrame\n",
    "    global errorNums, maxFrameCt\n",
    "    processedFrames = []\n",
    "    isFirstFrame = True\n",
    "    frameShape = None\n",
    "    frameCount = 0\n",
    "    \n",
    "    # for each frame \n",
    "    for n in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))): \n",
    "        if frameCount != maxFrameCt:\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            # in case a frame is missing, just continue\n",
    "            if frame is None or frame.shape[0] == 0: \n",
    "                continue\n",
    "            \n",
    "            if isFirstFrame: \n",
    "                frameShape  = frame.shape\n",
    "                isFirstFrame = False\n",
    "            \n",
    "            if frame.shape != frameShape: \n",
    "                continue\n",
    "            # crop only the mouth like we'll do on the RPI \n",
    "            frameSizeOld = frame.shape\n",
    "            frame = cropForMouth(frame)\n",
    "            frameSize = frame.shape\n",
    "            frame = cv2.resize(frame, (newImageSize[1], newImageSize[0]))\n",
    "            newFrameSize = frame.shape\n",
    "            try: \n",
    "                grayFrame = tf.image.rgb_to_grayscale(frame)\n",
    "            except: \n",
    "                continue\n",
    "            processedFrames.append(grayFrame)\n",
    "            # processedFrames = [*processedFrames, grayFrame]\n",
    "            lastFrame = grayFrame\n",
    "            frameCount += 1\n",
    "\n",
    "    while len(processedFrames) < maxFrameCt: \n",
    "        processedFrames.append(lastFrame)\n",
    "    cap.release()    \n",
    "\n",
    "    # generate the normalized frames (deviation from the average)\n",
    "    mean = tf.math.reduce_mean(processedFrames, keepdims=True)\n",
    "    try: \n",
    "        std = tf.math.reduce_std(tf.cast(processedFrames, tf.float32),  keepdims=True)\n",
    "    except: \n",
    "        \n",
    "        errorPaths.append(path)\n",
    "        errorInfo.append(\"SECOND STATEMENT\")\n",
    "        errorInfo.append(len(processedFrames))\n",
    "        errorInfo.append(frameSizeOld)\n",
    "        errorInfo.append(frameSize)\n",
    "        errorInfo.append(newFrameSize)\n",
    "        errorInfo.append(grayFrame)\n",
    "    std = tf.math.reduce_std(tf.cast(processedFrames, tf.float32), keepdims=True)\n",
    "    frames = tf.cast(processedFrames, tf.float32)\n",
    "    normalizedFrames = (tf.cast(frames, tf.float32) - tf.cast(mean, tf.float32)) / tf.cast(std, tf.float32)\n",
    "    return normalizedFrames\n",
    "\n",
    "def makePredictionOnVid(path, model):\n",
    "    sample = loadData(tf.convert_to_tensor(path))\n",
    "    print('~'*60)\n",
    "    original = tf.strings.reduce_join(numToChar(sample[1])).numpy().decode('utf-8')\n",
    "    paddedVid =  padTensor(sample[0], (290, 40, 120, 1))\n",
    "    yhat = model.predict(tf.expand_dims(paddedVid, axis=0))\n",
    "    \n",
    "    decoded = tf.keras.backend.ctc_decode(yhat, input_length=[maxFrameCt], greedy=True)[0][0].numpy()\n",
    "    prediction = tf.strings.reduce_join(numToChar(decoded[0])).numpy().decode('utf-8')\n",
    "    print('Original:', original)\n",
    "    print('Prediction:', prediction)\n",
    "    print(\"Word Error Rate on Prediction:\", str(wer(original,prediction) * 100) + \"%\")\n",
    "\n",
    "def makePredictionCustomVid(path, model): \n",
    "    sample = loadData2((path))\n",
    "    original = tf.strings.reduce_join(numToChar(sample[1])).numpy().decode('utf-8')\n",
    "    paddedVid =  padTensor(sample[0], (290, 40, 120, 1))\n",
    "    yhat = model.predict(tf.expand_dims(paddedVid, axis=0))\n",
    "    \n",
    "    decoded = tf.keras.backend.ctc_decode(yhat, input_length=[maxFrameCt], greedy=True)[0][0].numpy()\n",
    "    prediction = tf.strings.reduce_join(numToChar(decoded[0])).numpy().decode('utf-8')\n",
    "    print('Original:', original)\n",
    "    print('Prediction:', prediction)\n",
    "    print(\"Word Error Rate on Prediction:\", str(wer(original,prediction) * 100) + \"%\")"
   ],
   "id": "9b8c8a3c40b391a8",
   "outputs": [],
   "execution_count": 241
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T23:39:00.452939Z",
     "start_time": "2024-07-05T23:38:58.526473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "makePredictionCustomVid(\"5570920046221178499_00015\", model2)\n",
    "\n",
    "path = \"A:\\Lip Reading\\Potential Datasets\\BBC LRS2\\\\allFiles\\\\5570920046221178499_00015.mp4\"\n",
    "makePredictionOnVid(path, model2)"
   ],
   "id": "d3e17401309985fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5570920046221178499_00015.mp4\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "Original: WHICH OF OUR CONTESTANTS TODAY IS GOING TO MAKE A THUMPING GREAT PROFIT\n",
      "Prediction: WHICH OF OUR CONTESTANTS TODAY IS GOING TO MAKE A THUMPING GREAT PROFIT\n",
      "Word Error Rate on Prediction: 0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "Original: WHICH OF OUR CONTESTANTS TODAY IS GOING TO MAKE A THUMPING GREAT PROFIT\n",
      "Prediction: WHICH OF OUR CONTESTANTS TODAY IS GOING TO MAKE A THUMPING GREAT PROFIT\n",
      "Word Error Rate on Prediction: 0.0%\n"
     ]
    }
   ],
   "execution_count": 248
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T22:17:18.268174Z",
     "start_time": "2024-07-10T22:17:05.294327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model2.save('finalModelMOREDATA.h5')\n",
    "tf.saved_model.save(model2, 'finalModelMOREDATA')"
   ],
   "id": "cb4ee05381ede6ad",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, gru_cell_7_layer_call_fn, gru_cell_7_layer_call_and_return_conditional_losses while saving (showing 5 of 11). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: finalModelMOREDATA\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: finalModelMOREDATA\\assets\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T22:18:05.808836Z",
     "start_time": "2024-07-10T22:17:36.030307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model2)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "converter.experimental_new_converter=True\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('finalModelMOREDATA.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ],
   "id": "a54706f60d61aa2c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, gru_cell_7_layer_call_fn, gru_cell_7_layer_call_and_return_conditional_losses while saving (showing 5 of 11). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\monis\\AppData\\Local\\Temp\\tmpy067d2og\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\monis\\AppData\\Local\\Temp\\tmpy067d2og\\assets\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4c9ea03a888895ba"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
