{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-20T16:12:14.054703Z",
     "start_time": "2024-06-20T16:12:14.044189Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T16:19:36.575245Z",
     "start_time": "2024-06-20T16:19:36.550661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def faceDetection(img):\n",
    "    # TROUBLESHOOTING\n",
    "    # print(\"max size:\",img.shape, img.shape[0] - 3 * padding, img.shape[1] - 3 * padding)\n",
    "    return faceCascade.detectMultiScale(\n",
    "        img,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "    )\n",
    "def cropForFace(img) -> numpy.ndarray:\n",
    "    global lastKnownCrop\n",
    "    rects = faceDetection(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
    "    \n",
    "    print(type(rects))\n",
    "    # finding the largest face in a given image \n",
    "    largestFace = (0,0,0,0)\n",
    "    for (x, y, w, l) in rects:\n",
    "        if (w * l) > largestFace[2] * largestFace[3]:\n",
    "            largestFace = (x, y,w,l)\n",
    "\n",
    "    (x, y, w, l) = largestFace\n",
    "    \n",
    "    lastKnownCrop = (x,y,w,l)\n",
    "    y1 = lastKnownCrop[1] \n",
    "    x1 = lastKnownCrop[0]\n",
    "    y2 = y1 + lastKnownCrop[3] \n",
    "    x2 = x1 + lastKnownCrop[2]\n",
    "    \n",
    "    return img[y1:y2, x1:x2]"
   ],
   "id": "a5dee4e035c28c41",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T16:23:58.540824Z",
     "start_time": "2024-06-20T16:21:51.964392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img = cv2.imread('sampleData/familyPic.jpg')\n",
    "imgd = cropForFace(img)\n",
    "cv2.imshow('img', img[101: 101+64, 371:371+64])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# cropForFace(img)"
   ],
   "id": "5bc0111a0cb1ca3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(371, 101, 64, 64)\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T16:12:14.943740Z",
     "start_time": "2024-06-20T16:12:14.938743Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "77e38f537d230e89",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ef20557d0956a06"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
