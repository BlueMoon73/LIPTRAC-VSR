{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:57:53.552631Z",
     "start_time": "2024-07-04T05:57:53.538550Z"
    }
   },
   "source": [
    "# imports \n",
    "import os \n",
    "import tensorflow as tf \n",
    "import cv2 \n",
    "import numpy\n",
    "from matplotlib import pyplot as plt\n",
    "from jiwer import wer \n",
    "# making GPU be used, and setting memory limits\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "# gpus = tf.config.list_logical_devices('GPU')\n",
    "print(gpus)\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    print(\"gpu set\")\n",
    "except:\n",
    "    pass\n",
    "    print(\"failed\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "gpu set\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "7c48bcf107f4c31b",
   "metadata": {},
   "source": [
    "## basic functions"
   ]
  },
  {
   "cell_type": "code",
   "id": "787272fefa6ec811",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:57:54.205993Z",
     "start_time": "2024-07-04T05:57:54.172937Z"
    }
   },
   "source": [
    "# setting up the functions to convert from chars to num and vice versa\n",
    "vocab = [x for x in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ \"]\n",
    "charToNum = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
    "numToChar = tf.keras.layers.StringLookup(vocabulary=charToNum.get_vocabulary(), oov_token=\"\", invert=True)\n",
    "\n",
    "# facial detection vars \n",
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "lastKnownCrop = (0, 0, 160, 150)\n",
    "\n",
    "# data dir\n",
    "rootDir = 'A:\\Lip Reading\\Potential Datasets\\BBC LRS2\\\\allFiles'\n",
    "rootDir2 = 'A:\\Lip Reading\\Potential Datasets\\\\BBC LRS2'\n",
    "# r = \"A:\\Lip Reading\\Potential Datasets\\BBC LRS2\\\\allFiles\"\n",
    "\n",
    "errorNums = 0 \n",
    "errorPaths = []\n",
    "errorInfo = []\n",
    "frameSize = None\n",
    "frameSizeOld = None\n",
    "newFrameSize = None\n",
    "grayFrame = None\n",
    "newImageSize = (40, 120)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "c2e49edea7bd4712",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:57:54.532628Z",
     "start_time": "2024-07-04T05:57:54.512567Z"
    }
   },
   "source": [
    "# util funcs \n",
    "def faceDetection(img):\n",
    "    # TROUBLESHOOTING\n",
    "    # print(\"max size:\",img.shape, img.shape[0] - 3 * padding, img.shape[1] - 3 * padding)\n",
    "    return faceCascade.detectMultiScale(\n",
    "        img,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "    )\n",
    "\n",
    "def cropForMouth(img) -> numpy.ndarray:\n",
    "    global lastKnownCrop\n",
    "    rects = faceDetection(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
    "    \n",
    "    # finding the largest face in a given image \n",
    "    largestFace = (0,0,0,0)\n",
    "    for (x, y, w, l) in rects:\n",
    "        if (w * l) > largestFace[2] * largestFace[3]:\n",
    "            largestFace = (x, y,w,l)\n",
    "        \n",
    "    if largestFace == (0,0,0,0):\n",
    "        largestFace =lastKnownCrop\n",
    "    # cropping for face \n",
    "    lastKnownCrop = largestFace\n",
    "    y1 = lastKnownCrop[1] \n",
    "    x1 = lastKnownCrop[0]\n",
    "    y2 = y1 + lastKnownCrop[3] \n",
    "    x2 = x1 + lastKnownCrop[2]\n",
    "    return img[y1 + int(0.65 * lastKnownCrop[3]): y2, x1 + int(0.05 * lastKnownCrop[2]): int(0.95 * x2)]\n",
    "\n",
    "def numberToWords(num):  \n",
    "    if num == 0:  \n",
    "        return \"zero\"  \n",
    "    ones = [\"\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\"]  \n",
    "    tens = [\"\", \"\", \"twenty\", \"thirty\", \"forty\", \"fifty\", \"sixty\", \"seventy\", \"eighty\", \"ninety\"]  \n",
    "    teens = [\"ten\", \"eleven\", \"twelve\", \"thirteen\", \"fourteen\", \"fifteen\", \"sixteen\", \"seventeen\", \"eighteen\", \"nineteen\"]  \n",
    "    words = \"\"  \n",
    "    if num>= 1000:  \n",
    "        words += ones[num // 1000] + \" thousand \"  \n",
    "        num %= 1000  \n",
    "    if num>= 100:  \n",
    "        words += ones[num // 100] + \" hundred \"  \n",
    "        num %= 100  \n",
    "    if num>= 10 and num<= 19:  \n",
    "        words += teens[num - 10] + \" \"  \n",
    "        num = 0  \n",
    "    elif num>= 20:  \n",
    "        words += tens[num // 10] + \" \"  \n",
    "        num %= 10  \n",
    "    if num>= 1 and num<= 9:  \n",
    "        words += ones[num] + \" \"  \n",
    "    return words.strip().upper()"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "c7fbad6e80991f3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:57:54.704612Z",
     "start_time": "2024-07-04T05:57:54.682930Z"
    }
   },
   "source": [
    "def loadData(path): \n",
    "    # tf has the paths as bytes so decode that\n",
    "    path = bytes.decode(path.numpy())\n",
    "    \n",
    "    # extract just the file names\n",
    "    global rootDir\n",
    "    fileName = path.split('\\\\')[-1].split('.')[0]\n",
    "    # generate the respective paths of the data\n",
    "    videoPath = os.path.join(rootDir,f'{fileName}.mp4')\n",
    "    alignmentPath = os.path.join(rootDir,f'{fileName}.txt')\n",
    "    \n",
    "    # return the frames and alignments\n",
    "    frames = loadVideo(videoPath) \n",
    "    alignments = loadText(alignmentPath)\n",
    "    return frames, alignments\n",
    "\n",
    "def loadVideo(path): \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    global lastKnownCrop, frameSizeOld, frameSize, newFrameSize, grayFrame\n",
    "    global errorNums\n",
    "    processedFrames = []\n",
    "    isFirstFrame = True\n",
    "    frameShape = None\n",
    "    # for each frame \n",
    "    for n in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))): \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # in case a frame is missing, just continue\n",
    "        if frame is None or frame.shape[0] == 0: \n",
    "            continue\n",
    "        \n",
    "        if isFirstFrame: \n",
    "            frameShape  = frame.shape\n",
    "            isFirstFrame = False\n",
    "        \n",
    "        if frame.shape != frameShape: \n",
    "            continue\n",
    "        # crop only the mouth like we'll do on the RPI \n",
    "        frameSizeOld = frame.shape\n",
    "        frame = cropForMouth(frame)\n",
    "        frameSize = frame.shape\n",
    "        frame = cv2.resize(frame, (newImageSize[1], newImageSize[0]))\n",
    "        newFrameSize = frame.shape\n",
    "        grayFrame = tf.image.rgb_to_grayscale(frame)\n",
    "        processedFrames.append(grayFrame)\n",
    "        # processedFrames = [*processedFrames, grayFrame]\n",
    "\n",
    "    \n",
    "    cap.release()    \n",
    "\n",
    "    # generate the normalized frames (deviation from the average)\n",
    "    mean = tf.math.reduce_mean(processedFrames, keepdims=True)\n",
    "    try: \n",
    "        std = tf.math.reduce_std(tf.cast(processedFrames, tf.float32),  keepdims=True)\n",
    "    except: \n",
    "        \n",
    "        errorPaths.append(path)\n",
    "        errorInfo.append(\"SECOND STATEMENT\")\n",
    "        errorInfo.append(len(processedFrames))\n",
    "        errorInfo.append(frameSizeOld)\n",
    "        errorInfo.append(frameSize)\n",
    "        errorInfo.append(newFrameSize)\n",
    "        errorInfo.append(grayFrame)\n",
    "    std = tf.math.reduce_std(tf.cast(processedFrames, tf.float32), keepdims=True)\n",
    "    frames = tf.cast(processedFrames, tf.float32)\n",
    "    normalizedFrames = (tf.cast(frames, tf.float32) - tf.cast(mean, tf.float32)) / tf.cast(std, tf.float32)\n",
    "    return normalizedFrames\n",
    "\n",
    "def loadText(path): \n",
    "    # open and parse the file \n",
    "    with open(path, 'r') as file: lines = file.readlines()\n",
    "    file.close()\n",
    "    \n",
    "    # return the number equivalent of each of the characters of the word \n",
    "    tokens = []\n",
    "    words = lines[0].split()\n",
    "    del words[0]\n",
    "\n",
    "    for word in words: \n",
    "        if word.isnumeric():\n",
    "            newWord = numberToWords(int(word))\n",
    "            words[words.index(word)] = newWord\n",
    "    words = \" \".join(words).split()\n",
    "    # print(words)\n",
    "    for word in words: \n",
    "        tokens = [*tokens,' ', word]\n",
    "    try:\n",
    "        return charToNum(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]   \n",
    "    except: \n",
    "        print(tokens)\n",
    "\n",
    "def processData(path): \n",
    "    return tf.py_function(loadData, [path],  (tf.float32, tf.int64))"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "a401cd6fa0067aed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:57:54.874708Z",
     "start_time": "2024-07-04T05:57:54.864667Z"
    }
   },
   "source": [
    "def getFrameCount(path) -> int: \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frameCount = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    cap.release()\n",
    "    return frameCount\n",
    "\n",
    "def getCharCount(path) -> int: \n",
    "    return len(loadText(path))"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:57:56.123040Z",
     "start_time": "2024-07-04T05:57:55.019493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "firstEntry  = errorPaths[0]\n",
    "\n",
    "for entry in errorPaths: \n",
    "    if entry != firstEntry: \n",
    "        print(entry)\n",
    "firstEntry"
   ],
   "id": "1e2c476f9e3a351a",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m firstEntry  \u001B[38;5;241m=\u001B[39m \u001B[43merrorPaths\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m entry \u001B[38;5;129;01min\u001B[39;00m errorPaths: \n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m entry \u001B[38;5;241m!=\u001B[39m firstEntry: \n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "9203a9532b428b04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:05.718793Z",
     "start_time": "2024-07-04T05:58:05.704776Z"
    }
   },
   "source": [
    "# numberPath = \"A:\\\\Lip Reading\\\\Potential Datasets\\\\BBC LRS2\\\\Numbers.txt\"\n",
    "# tensorPath = tf.convert_to_tensor(numberPath, dtype=tf.string)\n",
    "# path = bytes.decode(tensorPath.numpy())\n",
    "# fileName = path.split('\\\\')[-1].split('.')[0]\n",
    "# \n",
    "# # testing if the loadData, loadVideo, and loadText function all work\n",
    "# alignmentPath = os.path.join(rootDir2,f'{fileName}.txt')\n",
    "# loadText(alignmentPath)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "1dc8265fa1dc4688",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:08.657472Z",
     "start_time": "2024-07-04T05:58:06.280087Z"
    }
   },
   "source": [
    "rawPath = \"A:\\\\Lip Reading\\\\Potential Datasets\\\\BBC LRS2\\\\allFiles\\\\5535415699068794046_00006.mp4\"\n",
    "maxCharCt = 145 # found from the dataStats.ipynb\n",
    "maxFrameCt = 2*maxCharCt\n",
    "tensorPath = tf.convert_to_tensor(rawPath, dtype=tf.string)\n",
    "path = bytes.decode(tensorPath.numpy())\n",
    "fileName = path.split('\\\\')[-1].split('.')[0]\n",
    "\n",
    "# testing if the loadData, loadVideo, and loadText function all work\n",
    "videoPath = os.path.join(rootDir,f'{fileName}.mp4')\n",
    "alignmentPath = os.path.join(rootDir,f'{fileName}.txt')\n",
    "\n",
    "loadVideo(videoPath)\n",
    "loadText(alignmentPath)\n",
    "\n",
    "frames, text = loadData(tensorPath)\n",
    "print(type(frames))\n",
    "print(frames)\n",
    "print(len(frames[0][0]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(\n",
      "[[[[ 0.9325923 ]\n",
      "   [ 0.97313976]\n",
      "   [ 1.0947822 ]\n",
      "   ...\n",
      "   [-1.8651845 ]\n",
      "   [-2.0273745 ]\n",
      "   [-2.1490169 ]]\n",
      "\n",
      "  [[ 0.8920448 ]\n",
      "   [ 0.97313976]\n",
      "   [ 1.0542347 ]\n",
      "   ...\n",
      "   [-1.8651845 ]\n",
      "   [-2.0273745 ]\n",
      "   [-2.1490169 ]]\n",
      "\n",
      "  [[ 0.8920448 ]\n",
      "   [ 0.9325923 ]\n",
      "   [ 0.97313976]\n",
      "   ...\n",
      "   [-1.905732  ]\n",
      "   [-2.0679219 ]\n",
      "   [-2.1490169 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.9325923 ]\n",
      "   [ 0.8109498 ]\n",
      "   [ 0.68930733]\n",
      "   ...\n",
      "   [-1.7029946 ]\n",
      "   [-1.7029946 ]\n",
      "   [-1.6624471 ]]\n",
      "\n",
      "  [[ 0.8514973 ]\n",
      "   [ 0.7704023 ]\n",
      "   [ 0.68930733]\n",
      "   ...\n",
      "   [-1.7029946 ]\n",
      "   [-1.6624471 ]\n",
      "   [-1.7029946 ]]\n",
      "\n",
      "  [[ 0.7298548 ]\n",
      "   [ 0.68930733]\n",
      "   [ 0.64875984]\n",
      "   ...\n",
      "   [-1.6218996 ]\n",
      "   [-1.6624471 ]\n",
      "   [-1.7029946 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.8514973 ]\n",
      "   [ 0.8920448 ]\n",
      "   [ 0.97313976]\n",
      "   ...\n",
      "   [-1.4191622 ]\n",
      "   [-1.6218996 ]\n",
      "   [-1.7435421 ]]\n",
      "\n",
      "  [[ 0.8514973 ]\n",
      "   [ 0.9325923 ]\n",
      "   [ 0.97313976]\n",
      "   ...\n",
      "   [-1.5002571 ]\n",
      "   [-1.6624471 ]\n",
      "   [-1.7840896 ]]\n",
      "\n",
      "  [[ 0.8920448 ]\n",
      "   [ 0.9325923 ]\n",
      "   [ 0.97313976]\n",
      "   ...\n",
      "   [-1.5408046 ]\n",
      "   [-1.7029946 ]\n",
      "   [-1.7840896 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.68930733]\n",
      "   [ 0.68930733]\n",
      "   [ 0.64875984]\n",
      "   ...\n",
      "   [-1.6624471 ]\n",
      "   [-1.6624471 ]\n",
      "   [-1.6624471 ]]\n",
      "\n",
      "  [[ 0.68930733]\n",
      "   [ 0.68930733]\n",
      "   [ 0.68930733]\n",
      "   ...\n",
      "   [-1.7029946 ]\n",
      "   [-1.7029946 ]\n",
      "   [-1.7029946 ]]\n",
      "\n",
      "  [[ 0.68930733]\n",
      "   [ 0.68930733]\n",
      "   [ 0.68930733]\n",
      "   ...\n",
      "   [-1.7029946 ]\n",
      "   [-1.7029946 ]\n",
      "   [-1.7435421 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.56766486]\n",
      "   [ 0.60821235]\n",
      "   [ 0.68930733]\n",
      "   ...\n",
      "   [-0.9325923 ]\n",
      "   [-1.1353297 ]\n",
      "   [-1.2569722 ]]\n",
      "\n",
      "  [[ 0.56766486]\n",
      "   [ 0.64875984]\n",
      "   [ 0.7298548 ]\n",
      "   ...\n",
      "   [-0.97313976]\n",
      "   [-1.2164247 ]\n",
      "   [-1.3380672 ]]\n",
      "\n",
      "  [[ 0.56766486]\n",
      "   [ 0.60821235]\n",
      "   [ 0.68930733]\n",
      "   ...\n",
      "   [-1.0947822 ]\n",
      "   [-1.2569722 ]\n",
      "   [-1.3786147 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.64875984]\n",
      "   [ 0.60821235]\n",
      "   [ 0.60821235]\n",
      "   ...\n",
      "   [-1.6624471 ]\n",
      "   [-1.6218996 ]\n",
      "   [-1.5813521 ]]\n",
      "\n",
      "  [[ 0.64875984]\n",
      "   [ 0.60821235]\n",
      "   [ 0.60821235]\n",
      "   ...\n",
      "   [-1.6218996 ]\n",
      "   [-1.6218996 ]\n",
      "   [-1.5813521 ]]\n",
      "\n",
      "  [[ 0.64875984]\n",
      "   [ 0.64875984]\n",
      "   [ 0.64875984]\n",
      "   ...\n",
      "   [-1.5408046 ]\n",
      "   [-1.5813521 ]\n",
      "   [-1.5813521 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-0.8920448 ]\n",
      "   [-0.8920448 ]\n",
      "   [-0.8514973 ]\n",
      "   ...\n",
      "   [-0.08109498]\n",
      "   [-0.12164247]\n",
      "   [-0.16218996]]\n",
      "\n",
      "  [[-0.8920448 ]\n",
      "   [-0.8514973 ]\n",
      "   [-0.8514973 ]\n",
      "   ...\n",
      "   [-0.08109498]\n",
      "   [-0.12164247]\n",
      "   [-0.16218996]]\n",
      "\n",
      "  [[-0.8109498 ]\n",
      "   [-0.8109498 ]\n",
      "   [-0.8109498 ]\n",
      "   ...\n",
      "   [-0.08109498]\n",
      "   [-0.12164247]\n",
      "   [-0.16218996]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.64875984]\n",
      "   [-0.64875984]\n",
      "   [-0.64875984]\n",
      "   ...\n",
      "   [-0.32437992]\n",
      "   [-0.32437992]\n",
      "   [-0.28383243]]\n",
      "\n",
      "  [[-0.68930733]\n",
      "   [-0.68930733]\n",
      "   [-0.68930733]\n",
      "   ...\n",
      "   [-0.32437992]\n",
      "   [-0.32437992]\n",
      "   [-0.32437992]]\n",
      "\n",
      "  [[-0.68930733]\n",
      "   [-0.68930733]\n",
      "   [-0.64875984]\n",
      "   ...\n",
      "   [-0.24328494]\n",
      "   [-0.28383243]\n",
      "   [-0.32437992]]]\n",
      "\n",
      "\n",
      " [[[-0.8514973 ]\n",
      "   [-0.8514973 ]\n",
      "   [-0.8109498 ]\n",
      "   ...\n",
      "   [ 0.04054749]\n",
      "   [-0.04054749]\n",
      "   [-0.08109498]]\n",
      "\n",
      "  [[-0.8920448 ]\n",
      "   [-0.8514973 ]\n",
      "   [-0.8109498 ]\n",
      "   ...\n",
      "   [ 0.04054749]\n",
      "   [-0.04054749]\n",
      "   [-0.08109498]]\n",
      "\n",
      "  [[-0.8514973 ]\n",
      "   [-0.8109498 ]\n",
      "   [-0.8109498 ]\n",
      "   ...\n",
      "   [ 0.04054749]\n",
      "   [-0.04054749]\n",
      "   [-0.04054749]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.68930733]\n",
      "   [-0.64875984]\n",
      "   [-0.60821235]\n",
      "   ...\n",
      "   [-0.3649274 ]\n",
      "   [-0.3649274 ]\n",
      "   [-0.3649274 ]]\n",
      "\n",
      "  [[-0.64875984]\n",
      "   [-0.64875984]\n",
      "   [-0.60821235]\n",
      "   ...\n",
      "   [-0.3649274 ]\n",
      "   [-0.3649274 ]\n",
      "   [-0.4054749 ]]\n",
      "\n",
      "  [[-0.60821235]\n",
      "   [-0.60821235]\n",
      "   [-0.56766486]\n",
      "   ...\n",
      "   [-0.3649274 ]\n",
      "   [-0.3649274 ]\n",
      "   [-0.3649274 ]]]\n",
      "\n",
      "\n",
      " [[[-0.97313976]\n",
      "   [-0.97313976]\n",
      "   [-0.9325923 ]\n",
      "   ...\n",
      "   [-0.04054749]\n",
      "   [-0.12164247]\n",
      "   [-0.16218996]]\n",
      "\n",
      "  [[-1.0136873 ]\n",
      "   [-0.97313976]\n",
      "   [-0.97313976]\n",
      "   ...\n",
      "   [-0.12164247]\n",
      "   [-0.16218996]\n",
      "   [-0.20273745]]\n",
      "\n",
      "  [[-0.9325923 ]\n",
      "   [-0.9325923 ]\n",
      "   [-0.9325923 ]\n",
      "   ...\n",
      "   [-0.20273745]\n",
      "   [-0.24328494]\n",
      "   [-0.24328494]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.7298548 ]\n",
      "   [-0.68930733]\n",
      "   [-0.64875984]\n",
      "   ...\n",
      "   [-0.3649274 ]\n",
      "   [-0.3649274 ]\n",
      "   [-0.4054749 ]]\n",
      "\n",
      "  [[-0.8109498 ]\n",
      "   [-0.7704023 ]\n",
      "   [-0.64875984]\n",
      "   ...\n",
      "   [-0.4054749 ]\n",
      "   [-0.4054749 ]\n",
      "   [-0.4054749 ]]\n",
      "\n",
      "  [[-0.8920448 ]\n",
      "   [-0.8109498 ]\n",
      "   [-0.64875984]\n",
      "   ...\n",
      "   [-0.4054749 ]\n",
      "   [-0.4054749 ]\n",
      "   [-0.4054749 ]]]], shape=(68, 40, 120, 1), dtype=float32)\n",
      "120\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "b323b3673a461c65",
   "metadata": {},
   "source": [
    "## reading data"
   ]
  },
  {
   "cell_type": "code",
   "id": "15d040463f02dc61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:13.564312Z",
     "start_time": "2024-07-04T05:58:13.457703Z"
    }
   },
   "source": [
    "# reading all files within the root directory\n",
    "# data = tf.data.Dataset.list_files('A:\\Lip Reading\\Potential Datasets\\BBC LRS2\\mvlrs_v1\\main\\*\\*.mp4')\n",
    "data = tf.data.Dataset.list_files('A:/Lip Reading/Potential Datasets/BBC LRS2/trainFiles1/*.mp4')\n",
    "# data = tf.data.Dataset.list_files('A:/Lip Reading/Potential Datasets/BBC LRS2/trainFiles6/*.mp4')\n",
    "\n",
    "\n",
    "data = data.shuffle(500, reshuffle_each_iteration=False) # shuffling data\n",
    "data = data.map(processData) # \"processing\" the data to obtain frames and the respective text \n",
    "\n",
    "dim1 = newImageSize[0]\n",
    "dim2 = newImageSize[1]\n",
    "print(\"dataset size before padding:\", len(data))\n",
    "print(\"data shape of example frame:\", newImageSize)\n",
    "print(\"data shape of example video:\", frames.shape)\n",
    "print(\"dims: \",dim1, \"x\",dim2)\n",
    "\n",
    "# combining 8 videos as one \"input\"\n",
    "# ensuring all videos are padded to match the longest video, \n",
    "# ensuring the length of all the alignments is the size of the longest text characters, as some are lower. \n",
    "batchSize = 4\n",
    "data = data.padded_batch(batchSize, padded_shapes=([2*maxCharCt,None, None,None], [maxCharCt])) \n",
    "print(\"autotune: \",tf.data.AUTOTUNE)\n",
    "data = data.prefetch(tf.data.AUTOTUNE)\n",
    "# data=data.prefetch(3)\n",
    "print(\"data length after padding:\", len(data))\n",
    "print(\"batch size:\", batchSize)\n",
    "\n",
    "train = data.take(int(len(data) * 0.6))\n",
    "test = data.skip(int(len(data) * 0.6))\n",
    "print(\"train data size:\", len(train))\n",
    "print(\"test data size:\",  len(test))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size before padding: 1139\n",
      "data shape of example frame: (40, 120)\n",
      "data shape of example video: (68, 40, 120, 1)\n",
      "dims:  40 x 120\n",
      "autotune:  -1\n",
      "data length after padding: 285\n",
      "batch size: 4\n",
      "train data size: 171\n",
      "test data size: 114\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "b98206929338ffa0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:14.097067Z",
     "start_time": "2024-07-04T05:58:14.077522Z"
    }
   },
   "source": [
    "data"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 290, None, None, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, 145), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:14.519011Z",
     "start_time": "2024-07-04T05:58:14.510399Z"
    }
   },
   "cell_type": "code",
   "source": "print(set(errorPaths))",
   "id": "83cd97bc3fe5774f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "771515f5cef4617f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:17.387235Z",
     "start_time": "2024-07-04T05:58:14.859061Z"
    }
   },
   "source": [
    "val = data.as_numpy_iterator().next()\n",
    "plt.imshow(val[0][0][2], cmap='gray_r')\n",
    "print(len(val[0][0]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "e1b71a67fbe998bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:17.542872Z",
     "start_time": "2024-07-04T05:58:17.388741Z"
    }
   },
   "source": [
    "tf.strings.reduce_join([numToChar(word) for word in val[1][0]])\n",
    "print(\"num of chars:\", len(([numToChar(word) for word in val[1][0]])))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of chars: 145\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "7b9fe2e89759a25",
   "metadata": {},
   "source": [
    "## designing the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "44de38608ebec792",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:19.952783Z",
     "start_time": "2024-07-04T05:58:19.939730Z"
    }
   },
   "source": [
    "# imports for the model architecture \n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPooling3D, TimeDistributed, Flatten, GRU\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, Nadam, SGD\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "a4e35802d732d3c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:22.079998Z",
     "start_time": "2024-07-04T05:58:20.389893Z"
    }
   },
   "source": [
    "inputShape = data.as_numpy_iterator().next()[0][0].shape\n",
    "print(inputShape)\n",
    "print(charToNum.get_vocabulary())\n",
    "print(len(charToNum.get_vocabulary()))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290, 40, 120, 1)\n",
      "['', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ' ']\n",
      "28\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "84706072692f52d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:37.047892Z",
     "start_time": "2024-07-04T05:58:37.031835Z"
    }
   },
   "source": [
    "# model to be actually trained\n",
    "def createModel(x): \n",
    "    model = Sequential([\n",
    "    Conv3D(32, 3, input_shape=inputShape, padding='same', activation='relu', name=\"conv1\"),\n",
    "    MaxPooling3D((1,2,2), name=\"maxPool1\"),\n",
    "    \n",
    "    Conv3D(64, 3, padding='same', activation='relu', name=\"conv2\"),\n",
    "    MaxPooling3D((1,2,2), name=\"maxPool2\"),\n",
    "        \n",
    "    Conv3D(96, 3,  padding='same', activation='relu', name=\"conv3\"),\n",
    "    MaxPooling3D((1,2,2), name=\"maxPool3\"),\n",
    "    \n",
    "    TimeDistributed(Flatten()),\n",
    "    \n",
    "    # Bidirectional(LSTM(256, kernel_initializer='orthogonal', return_sequences=True)),\n",
    "    Bidirectional(GRU(x, kernel_initializer='orthogonal', return_sequences=True)),\n",
    "    Dropout(.5),\n",
    "        \n",
    "    # Bidirectional(LSTM(256, kernel_initializer='orthogonal' , return_sequences=True)),\n",
    "    Bidirectional(GRU(x, kernel_initializer='orthogonal' , return_sequences=True)),\n",
    "    Dropout(.5),\n",
    "    \n",
    "    Dense(charToNum.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "# model to be actually trained\n",
    "def createModel2(x): \n",
    "    model = Sequential([\n",
    "    Conv3D(180, kernel_size=(1,3,3), strides=(1,2,2), input_shape=inputShape, padding='same', activation='relu', name=\"conv1\"),\n",
    "    MaxPooling3D((1,2,2), name=\"maxPool1\"),\n",
    "    \n",
    "    Conv3D(256, kernel_size=(1,2,2), strides=(1,2,2), padding='same', activation='relu', name=\"conv2\"),\n",
    "    MaxPooling3D((1,2,2), name=\"maxPool2\"),\n",
    "    Conv3D(256, kernel_size=(2,2,2), strides=(1,2,2), padding='same', activation='relu', name=\"conv3\"),\n",
    "    \n",
    "    TimeDistributed(Flatten()),\n",
    "    \n",
    "    # Bidirectional(LSTM(256, kernel_initializer='orthogonal', return_sequences=True)),\n",
    "    Bidirectional(GRU(x, kernel_initializer='orthogonal', return_sequences=True)),\n",
    "    Dropout(.5),\n",
    "        \n",
    "    # Bidirectional(LSTM(256, kernel_initializer='orthogonal' , return_sequences=True)),\n",
    "    Bidirectional(GRU(x, kernel_initializer='orthogonal' , return_sequences=True)),\n",
    "    Dropout(.5),\n",
    "    \n",
    "    Dense(charToNum.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax')\n",
    "    ])\n",
    "    return model\n"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "d728bc2771721d6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:40.859070Z",
     "start_time": "2024-07-04T05:58:37.467431Z"
    }
   },
   "source": [
    "model2 = createModel(256)\n",
    "\n",
    "print(\"final model input shape:\",  inputShape)\n",
    "model2.summary()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final model input shape: (290, 40, 120, 1)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1 (Conv3D)              (None, 290, 40, 120, 32)  896       \n",
      "                                                                 \n",
      " maxPool1 (MaxPooling3D)     (None, 290, 20, 60, 32)   0         \n",
      "                                                                 \n",
      " conv2 (Conv3D)              (None, 290, 20, 60, 64)   55360     \n",
      "                                                                 \n",
      " maxPool2 (MaxPooling3D)     (None, 290, 10, 30, 64)   0         \n",
      "                                                                 \n",
      " conv3 (Conv3D)              (None, 290, 10, 30, 96)   165984    \n",
      "                                                                 \n",
      " maxPool3 (MaxPooling3D)     (None, 290, 5, 15, 96)    0         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 290, 7200)        0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 290, 512)         11455488  \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 290, 512)          0         \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 290, 512)         1182720   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 290, 512)          0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 290, 29)           14877     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,875,325\n",
      "Trainable params: 12,875,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "9cd1b05996f23f8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:40.875023Z",
     "start_time": "2024-07-04T05:58:40.861007Z"
    }
   },
   "source": [
    "# custom functions \n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 40:\n",
    "        return lr        \n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "# custom loss function \n",
    "def CTCLoss(yTrue, yPred):\n",
    "    # y true is the text alignment (None, 99) \n",
    "    # y pred is the end result of the model (154, 41) \n",
    "    batchLen = tf.cast(tf.shape(yTrue)[0], dtype=\"int64\")\n",
    "\n",
    "    inputLen = tf.cast(tf.shape(yPred)[1], dtype=\"int64\")\n",
    "    labelLen = tf.cast(tf.shape(yTrue)[1], dtype=\"int64\")\n",
    "    inputLen = inputLen * tf.ones(shape=(batchLen, 1), dtype=\"int64\")\n",
    "    labelLen = labelLen * tf.ones(shape=(batchLen, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = tf.keras.backend.ctc_batch_cost(yTrue, yPred, inputLen, labelLen)   \n",
    "    return loss \n",
    "\n",
    "class ProduceExample(tf.keras.callbacks.Callback): \n",
    "    def __init__(self, dataset) -> None: \n",
    "        self.dataset = dataset.as_numpy_iterator()\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None) -> None:\n",
    "        try: \n",
    "            data = self.dataset.next()\n",
    "            yhat = self.model.predict(data[0])\n",
    "       \n",
    "            decoded = tf.keras.backend.ctc_decode(yhat, [maxFrameCt, maxFrameCt, maxFrameCt, maxFrameCt], greedy=False)[0][0].numpy()\n",
    "            for x in range(len(yhat)):           \n",
    "                print('Original:', tf.strings.reduce_join(numToChar(data[1][x])).numpy().decode('utf-8'))\n",
    "                print('Prediction:', tf.strings.reduce_join(numToChar(decoded[x])).numpy().decode('utf-8'))\n",
    "                print(\"Word Error Rate: \", str(wer(tf.strings.reduce_join(numToChar(data[1][x])).numpy().decode('utf-8'), tf.strings.reduce_join(numToChar(decoded[x])).numpy().decode('utf-8') ) * 100) + \"%\")\n",
    "                print('~'*100)\n",
    "        except: \n",
    "            pass     \n",
    "      "
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "d5afa6ac776aca30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:40.890571Z",
     "start_time": "2024-07-04T05:58:40.876022Z"
    }
   },
   "source": [
    "def makePrediction(model, valuePassed=None): \n",
    "    if valuePassed is None: \n",
    "        value = val\n",
    "    else: \n",
    "        value = valuePassed\n",
    "    yhat = model.predict(value[0])\n",
    "    \n",
    "    decoded = tf.keras.backend.ctc_decode(yhat, [maxFrameCt, maxFrameCt, maxFrameCt, maxFrameCt], greedy=False)[0][0].numpy()\n",
    "    originalArr = []\n",
    "    predArr = []\n",
    "    for x in range(len(yhat)):          \n",
    "        original = tf.strings.reduce_join(numToChar(val[1][x])).numpy().decode('utf-8')\n",
    "        prediction = tf.strings.reduce_join(numToChar(decoded[x])).numpy().decode('utf-8')\n",
    "        originalArr.append(original)\n",
    "        predArr.append(prediction )\n",
    "        \n",
    "        print('Original:', original)\n",
    "        print('Prediction:', prediction)\n",
    "        print(\"Word Error Rate on Prediction:\", str(wer(original,prediction) * 100) + \"%\")\n",
    "        print('~' * 40)\n",
    "    print(\"Original:\", originalArr, \"\\nPredictions:\", predArr)\n",
    "    print(\"Avg Word Error Rate:\", str(wer(originalArr, predArr) * 100) + \"%\")"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:46.004372Z",
     "start_time": "2024-07-04T05:58:40.891571Z"
    }
   },
   "cell_type": "code",
   "source": "makePrediction(model2)",
   "id": "18278119fccacab6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n",
      "Original: THEY MEET EACH OTHER OUTSIDE THE CHURCH\n",
      "Prediction: GZGZGZGZGZGZGZYZGZGYLYE EJQJI EGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGHYN\n",
      "Word Error Rate on Prediction: 100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEY WERE NEVER QUITE THE SAME WITHOUT HIM BECAUSE THE LEARINESS OF THE CARRY ON FILMS\n",
      "Prediction: GRMRMGGMMMMFGRMMGMMRMRFMFRMRMRMRMMMLMYMYMYMQMOJAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAHZ\n",
      "Word Error Rate on Prediction: 100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IVE BEEN VERY BUSY BABY SITTING MY NEW THREE WEEK OLD GRANDDAUGHTER\n",
      "Prediction: GRMRFRFMVMVMRMMRMRMRMVMVMVMVMVRMRMVXVXMRMRMKMYMYMYMYMYMYKMUFEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEV\n",
      "Word Error Rate on Prediction: 100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THESE GUYS HAVE MEMORIES OF THE DAY THEY BUILT AN EXTENSION SOMEWHERE IN GLOUCESTER\n",
      "Prediction: AKYKRKRKYKRKYKYKYKYGYKGKGKGKRGRKRYRKRKRKRKRKYMYMYMYMLMCYJEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKX\n",
      "Word Error Rate on Prediction: 100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ['THEY MEET EACH OTHER OUTSIDE THE CHURCH', 'THEY WERE NEVER QUITE THE SAME WITHOUT HIM BECAUSE THE LEARINESS OF THE CARRY ON FILMS', 'IVE BEEN VERY BUSY BABY SITTING MY NEW THREE WEEK OLD GRANDDAUGHTER', 'THESE GUYS HAVE MEMORIES OF THE DAY THEY BUILT AN EXTENSION SOMEWHERE IN GLOUCESTER'] \n",
      "Predictions: ['GZGZGZGZGZGZGZYZGZGYLYE EJQJI EGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGHYN', 'GRMRMGGMMMMFGRMMGMMRMRFMFRMRMRMRMMMLMYMYMYMQMOJAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAHZ', 'GRMRFRFMVMVMRMMRMRMRMVMVMVMVMVRMRMVXVXMRMRMKMYMYMYMYMYMYKMUFEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEV', 'AKYKRKRKYKRKYKYKYKYGYKGKGKGKRGRKRYRKRKRKRKRKYMYMYMYMLMCYJEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKX']\n",
      "Avg Word Error Rate: 100.0%\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## compilign the model??",
   "id": "25b028a1d086a394"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:46.904755Z",
     "start_time": "2024-07-04T05:58:46.901754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(errorPaths)\n",
    "print(errorNums)\n",
    "print(errorInfo)\n",
    "print(lastKnownCrop)"
   ],
   "id": "bee0ff8af265b787",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n",
      "[]\n",
      "(36, 5, 101, 101)\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:47.370534Z",
     "start_time": "2024-07-04T05:58:47.362535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(errorPaths)\n",
    "print(errorInfo)\n",
    "print(lastKnownCrop)"
   ],
   "id": "d64883637ac7da02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "(36, 5, 101, 101)\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:47.931205Z",
     "start_time": "2024-07-04T05:58:47.913205Z"
    }
   },
   "cell_type": "code",
   "source": "errorNums",
   "id": "4b417c386fbd4f3d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:48.599941Z",
     "start_time": "2024-07-04T05:58:48.576945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model2.compile(optimizer=Adam(learning_rate=0.0002), loss=CTCLoss)\n",
    "# create all the callbacks \n",
    "checkpointCallback2 = ModelCheckpoint('newLipModelv11_m2.weights.h5', monitor='loss',save_weights_only=False, save_freq='epoch') # save checkpoints after each epoch\n",
    "scheduleCallback2 = LearningRateScheduler(scheduler)\n",
    "exampleCallback2 = ProduceExample(test)"
   ],
   "id": "ec6634918fbbb5b3",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T16:03:55.491102Z",
     "start_time": "2024-07-04T08:15:50.887584Z"
    }
   },
   "cell_type": "code",
   "source": "model2.fit(train, validation_data=test, epochs=300, callbacks=[checkpointCallback2, exampleCallback2], use_multiprocessing=True)",
   "id": "8c3fe5f2bba6b6ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Original: AND THE LOWER HALF OF ALEXANDERS BODY WAS SHATTERED\n",
      "Prediction: I E E E E E E E E E E E E \n",
      "Word Error Rate:  144.44444444444443%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: JOE PASSED AWAY AND WITH ADAM AND HIS FAMILYS PERMISSION\n",
      "Prediction: I E E E E E E E E E E E E E E \n",
      "Word Error Rate:  150.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SO A FARM LIKE THIS\n",
      "Prediction: I E E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ONE OF US DECIDES THAT WERE GOING TO DO SOMETHING TOGETHER OF THEIR CHOICE\n",
      "Prediction: I E E E E E E E E E E E E E E E E E E \n",
      "Word Error Rate:  135.71428571428572%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 806s 5s/step - loss: 202.7820 - val_loss: 200.8653\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "Original: ALL RIGHT FOR THE ESTABLISHMENT TO TELL ME OPEN THE BORDERS\n",
      "Prediction: IH E T T T T E E E E E E E \n",
      "Word Error Rate:  118.18181818181819%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE GREAT BRITISH SHOWMAN\n",
      "Prediction: IH E T T T E E \n",
      "Word Error Rate:  175.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BORDER CONTROLS ON\n",
      "Prediction: I E E E E\n",
      "Word Error Rate:  166.66666666666669%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THAT MAN WAS JUDGE DREAD\n",
      "Prediction: IH E E T E E E E \n",
      "Word Error Rate:  160.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 600s 4s/step - loss: 200.1648 - val_loss: 199.3079\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "Original: IF YOU COME ACROSS A BOOK OF SUCH QUALITY\n",
      "Prediction: IH E E E E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE WONDERFUL THING IS ITS BEEN DOUBLE GLAZED\n",
      "Prediction: IH E E E E E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEYVE HAD POSITIVE THINGS TO SAY ABOUT ALL THE PROPERTIES\n",
      "Prediction: IH E E E E E E E E E  \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IS THAT THE TRUE REFLECTION\n",
      "Prediction: I E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 601s 4s/step - loss: 199.2603 - val_loss: 197.9945\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "Original: IM AFRAID THAT BECKY HAS SINGLED YOU OUT\n",
      "Prediction: T E E E E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHAT REALLY MAKES A CHIP A CHIP IS THE CRUNCH\n",
      "Prediction: T E E E E E E E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE WAY THINGS ARE LOOKING\n",
      "Prediction: TE E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I DONT WANT TO DO IT\n",
      "Prediction: TE E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 597s 4s/step - loss: 199.7089 - val_loss: 197.4216\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "Original: THE DIFFERENCE BETWEEN TWO VERY BIG NUMBERS\n",
      "Prediction: TE E E E E E E E E E \n",
      "Word Error Rate:  142.85714285714286%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE BIG QUESTION IS\n",
      "Prediction: AH E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IT WAS PRESENTED BY GEORGE III TO MY GREAT GREAT GREAT GREAT GREAT UNCLE\n",
      "Prediction: TH E E E E E E E E E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEY KEPT IT FOR THREE MONTHS\n",
      "Prediction: AH E E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 597s 4s/step - loss: 198.2024 - val_loss: 197.1380\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "Original: WHERE DOES THAT LEAVE US\n",
      "Prediction: IE E E  \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BECAUSE THEYRE VERY AMENABLE TO NEGOTIATION\n",
      "Prediction: IE E E E E E E E E E E \n",
      "Word Error Rate:  183.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS GOT EVERYTHING THAT THEYVE ASKED FOR\n",
      "Prediction: IE E E E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THIS PROGRAMME IS FOURTEEN MINUTES LONG AND WE LIKE TO TRY TO COVER AT LEAST ONE TOPIC FROM A VARIETY OF\n",
      "Prediction: IE E E E E E E E E E E E E E E E E E E E E E E E \n",
      "Word Error Rate:  114.28571428571428%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 596s 3s/step - loss: 198.7497 - val_loss: 197.8039\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "Original: WHAT IS NOT TO LIKE ABOUT THIS DUPLEX\n",
      "Prediction: IH E E E E E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND THEN ITS GOING TO COME DOWN TO A QUESTION OF COST\n",
      "Prediction: IH E E E E E E E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I THINK HIS LOVE WAS THE WORD\n",
      "Prediction: IH E E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I WROTE THIS BOOK\n",
      "Prediction: IH E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 598s 4s/step - loss: 198.4187 - val_loss: 195.0121\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "Original: BEARING THAT IN MIND\n",
      "Prediction: IH E E E E \n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHICH IS WHY WERE DOING IT\n",
      "Prediction: IH E E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THERE ARE ABOUT FOUR HUNDRED GRAND MASTERS\n",
      "Prediction: IH E E E E E E E E E E E E \n",
      "Word Error Rate:  185.71428571428572%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND ITS REALLY\n",
      "Prediction: IH E E E \n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 594s 3s/step - loss: 196.7961 - val_loss: 137.3825\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "Original: SHE WAS STRUGGLING\n",
      "Prediction: IH E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I WOULD SAY NINETY OF THAT WAS\n",
      "Prediction: IH E E T \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IT WILL BE LOVELY TO EAT\n",
      "Prediction: IE E E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE OWNERS INFORMED\n",
      "Prediction: IH E E E \n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 598s 4s/step - loss: 118.6882 - val_loss: 113.4193\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "Original: WIDE OPEN FIELDS\n",
      "Prediction: IH E E E\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: YOU ARE PART OF THAT PICTURE\n",
      "Prediction: IH E E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND OPING YOU WILL WIN\n",
      "Prediction: IH E E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND WHEN YOU SEE SOMEONE YOU LOVE\n",
      "Prediction: IH E E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 592s 3s/step - loss: 114.4030 - val_loss: 115.5458\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "Original: THERE ARE SOME CONVERTED BARNS\n",
      "Prediction: IH E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SHE HAD NO ENGLISH\n",
      "Prediction: IH E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IM A LITTLE BIT NERVOUS\n",
      "Prediction: IH E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS STILL VERY BUOYANT FOR RARE AND UNUSUAL ITEMS\n",
      "Prediction: IH E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 599s 4s/step - loss: 112.8335 - val_loss: 113.0488\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "Original: THERE HAVE BEEN SO MANY MOMENTS DURING THE WEEK WHICH REMIND US ALL OF THE COURAGE AND BRAVERY OF\n",
      "Prediction: IE E E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: YOU COME BACK YEAR AFTER YEAR\n",
      "Prediction: IH E E E E E E\n",
      "Word Error Rate:  116.66666666666667%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WITH A MARVELLOUS MUSICAL MEDLEY THAT INCLUDES A BURST OF ONE OF THE BEST LOVED\n",
      "Prediction: IE E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WE WERE GONE FOR A COUPLE OF DAYS AND CAME BACK\n",
      "Prediction: IH E E E E E E E E E E E\n",
      "Word Error Rate:  109.09090909090908%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 604s 4s/step - loss: 115.2198 - val_loss: 116.2201\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "Original: AND THE NEXT DAY\n",
      "Prediction: I E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SEEMS ALMOST JAW DROPPING\n",
      "Prediction: I E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE BIDS IN THE ROOM THEN\n",
      "Prediction: I T E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IVE JUST SPOTTED SOMETHING FANTASTIC\n",
      "Prediction: I E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 605s 4s/step - loss: 116.3331 - val_loss: 116.3827\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "Original: WE WOULD LOVE TO SELL IT\n",
      "Prediction: IH E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SEX CHANGING INVERTEBRATE MASQUERADING AS A ROCK\n",
      "Prediction: IH E E E E E E E\n",
      "Word Error Rate:  114.28571428571428%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I WOULD PUT HSA\n",
      "Prediction: IH E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEY LEARNED TO DANCES\n",
      "Prediction: IH E E E E E E E E E\n",
      "Word Error Rate:  250.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 599s 4s/step - loss: 113.9422 - val_loss: 112.1469\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "Original: AS DEMAND FOR THE WHITE STUFF GROWS EVER HIGHER\n",
      "Prediction: IOE E E E E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: MY BRAIN PICKS UP THE ELECTRICAL VIBRATIONS\n",
      "Prediction: IH E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: MY GUESS WOULD BE RIGA\n",
      "Prediction: IE E E E E E E\n",
      "Word Error Rate:  140.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: DIES OF RADIATION SICKNESS\n",
      "Prediction: IE E E E E E E E\n",
      "Word Error Rate:  200.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 598s 4s/step - loss: 113.6011 - val_loss: 113.5183\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "Original: DEALS ON WHEELS\n",
      "Prediction: IH E E E\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I FINISHED UP TEACHING\n",
      "Prediction: IH AE E E E E E E\n",
      "Word Error Rate:  200.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: FIVE CONTENDERS TONIGHT\n",
      "Prediction: IHE E E E E E E E\n",
      "Word Error Rate:  266.66666666666663%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WE ARE COMING BACK LATER ON IN THE SHOW\n",
      "Prediction: IHE T E E E E E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 600s 4s/step - loss: 111.3793 - val_loss: 109.7041\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "Original: SENSIBLE LITTLE CARS\n",
      "Prediction: IH E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: CLARISSA FROM THE TWO FAT LADIES ABSOLUTELY LOATHES IN THE WILD\n",
      "Prediction: IH E T T \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: NOW HAVING OVER A QUARTER OF A MILLION\n",
      "Prediction: IH E E T T\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: TURN OUT AND PLAY THE ODD GAME OF CRICKET\n",
      "Prediction: IH E E E T \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 602s 4s/step - loss: 111.1746 - val_loss: 111.0985\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "Original: I WENT WITH MY GUT FEELING ON THIS\n",
      "Prediction: IH E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I THINK HOPING TO MAKE A PROFIT ON IT\n",
      "Prediction: IH E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WATER LEVELS ROSE\n",
      "Prediction: TH E E E\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WE DONT WANT TO GET STUCK IN THE PAST\n",
      "Prediction: IH E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 602s 4s/step - loss: 112.2612 - val_loss: 111.6184\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "Original: BUT THEYRE REALLY EATING HIGH QUALITY FOOD\n",
      "Prediction: THE T T T T T T T T T\n",
      "Word Error Rate:  142.85714285714286%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHAT IS WORRYING YOU ABOUT HAVING BOUGHT THIS\n",
      "Prediction: IH A A T\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHERE WAS THE MONEY COMING FROM FOR THIS AND THAT\n",
      "Prediction: TE E E E E E E E E E E\n",
      "Word Error Rate:  110.00000000000001%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEY MEET EACH OTHER OUTSIDE THE CHURCH\n",
      "Prediction: TE T E E ET\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 602s 4s/step - loss: 111.3344 - val_loss: 111.1686\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "Original: THE SKYLINE CHANGED\n",
      "Prediction: THE E\n",
      "Word Error Rate:  66.66666666666666%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS NOT UPSTAIRS\n",
      "Prediction: IH \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WANDERING THROUGH SPACE AND TIME IN\n",
      "Prediction: THE \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: OF WHAT HAPPENED HERE THOSE MILLIONS OF YEARS AGO\n",
      "Prediction: T E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 601s 4s/step - loss: 111.4158 - val_loss: 110.6524\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "Original: IM AFRAID I MUST RESIGN\n",
      "Prediction: IH E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: HE SET UP HIS STALL HERE AT THE MAPPIN PAVILION AWAY FROM THE CROWDS\n",
      "Prediction: THE T E E E \n",
      "Word Error Rate:  92.85714285714286%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND IT WAS LIKE\n",
      "Prediction: IH E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BECAUSE THEY HAVE NOT BEEN AT THE TOP\n",
      "Prediction: THE E \n",
      "Word Error Rate:  87.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 601s 4s/step - loss: 112.4454 - val_loss: 112.6412\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "Original: I LIKE TO SPEND THE MONEY IF IM GIVEN IT\n",
      "Prediction: IE E O\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THIS IS GOLD DUST\n",
      "Prediction: IH A \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND THEN WALK TO THE PLACE IM GOING\n",
      "Prediction: IH E T E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SO WEVE GOT SOME WHOPPING GREAT GAPS HERE\n",
      "Prediction: IH T T E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 596s 3s/step - loss: 110.2823 - val_loss: 114.1703\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "Original: WE SAW THIS IN A LOCAL AUCTION ABOUT FIVE YEARS AGO AND THOUGHT IT WAS JUST THE PIECE\n",
      "Prediction: IH I \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE MID TH CENTURY\n",
      "Prediction: IH E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: A WAGE THAT ALLOWS YOU TO BRING UP A FAMILY AND ALLOWS YOU TO LIVE A DECENT LIFE\n",
      "Prediction: IH E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE VALUES OF THEM\n",
      "Prediction: IHE T E T OE\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 597s 4s/step - loss: 107.8107 - val_loss: 109.0104\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "Original: HOPEFULLY TOWARDS MY DADS\n",
      "Prediction: I A T O E\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THIS IS AMAZING\n",
      "Prediction: IE I I E\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IVE HAD SOME GOOD TIMES NO\n",
      "Prediction: IE A A A A A A O OE\n",
      "Word Error Rate:  150.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: HE WAS OBVIOUSLY VERY\n",
      "Prediction: IH I O R\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 601s 4s/step - loss: 109.5942 - val_loss: 106.7807\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "Original: OVER THE LAST FEW YEARS\n",
      "Prediction: I O E O H IT\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I DONT WANT TO BE THE MOUSE\n",
      "Prediction: I I A O O O\n",
      "Word Error Rate:  85.71428571428571%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IT WASNT JUST A TRAGEDY\n",
      "Prediction: I A A A A A O\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: FOR MANY PEOPLE\n",
      "Prediction: I O O O\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 602s 4s/step - loss: 107.6142 - val_loss: 102.6303\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "Original: FOR OUR ANCESTORS\n",
      "Prediction: I O OE O OE\n",
      "Word Error Rate:  166.66666666666669%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: TWENTY KILOMETRES ACROSS\n",
      "Prediction: I E E E E E\n",
      "Word Error Rate:  200.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE PASTEUR INSTITUTE HAS BEEN PRIMARILY INVOLVED IN RESEARCHING\n",
      "Prediction: I I I I E IE I I I E\n",
      "Word Error Rate:  111.11111111111111%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I HAD ONE MYSELF\n",
      "Prediction: I OE O OES\n",
      "Word Error Rate:  75.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 602s 4s/step - loss: 107.2316 - val_loss: 102.1314\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "Original: ITS WELL THUMBED\n",
      "Prediction: I W H \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BEFORE BUT IVE NEVER SEEN ONE WITH ROLLED PAPERWORK\n",
      "Prediction: IE H BE E E E E N H E E E OE\n",
      "Word Error Rate:  144.44444444444443%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BREATHLESS OF COURSE\n",
      "Prediction: I IN IE WU OE\n",
      "Word Error Rate:  166.66666666666669%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I WOULD IMAGINE A BUILDING LIKE THIS\n",
      "Prediction: I E E E E E T E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 602s 4s/step - loss: 106.2461 - val_loss: 103.6305\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "Original: I WOULD SAY IT WAS WORTH FOUR HUNDRED TWENTY FIVE PER CALENDAR MONTH\n",
      "Prediction: I WO WO WO WO OR WE TE TE E AE RER RNTHT\n",
      "Word Error Rate:  92.3076923076923%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IT WOULD BE FORTY PLUS YEARS AGO\n",
      "Prediction: I L O O T A E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHETHER ITS FROM A SHOP OR BEING SERVED TO US IN A RESTAURANT\n",
      "Prediction: I A A A A O A A O\n",
      "Word Error Rate:  84.61538461538461%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THROUGHOUT THE WHOLE SHOW\n",
      "Prediction: I O O O O\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 600s 4s/step - loss: 103.5953 - val_loss: 100.7992\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "Original: I WILL BE IN THE KITCHEN\n",
      "Prediction: I IE I IET\n",
      "Word Error Rate:  83.33333333333334%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHEN I RETURNED\n",
      "Prediction: IE E A IN\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: YOU NEVER WANT TO SEE DAMAGE\n",
      "Prediction: IE AE E E A AE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THAT TELLS US SOMETHING ABOUT THE SIZE OF THE PIPES\n",
      "Prediction: I A AE A A OE E E IE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 600s 4s/step - loss: 102.5922 - val_loss: 100.9517\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "Original: FOR MY FIRST LORD MAYORS SHOW\n",
      "Prediction: I OE OE O HE A A A A \n",
      "Word Error Rate:  150.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WE HAVE A ROOM DEDICATED IN THE PANDA FACILITY TO DO THAT\n",
      "Prediction: IE A AE AE AE ON T O O O O O O O\n",
      "Word Error Rate:  116.66666666666667%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: EIGHTY FOUR CHARING CROSS ROAD\n",
      "Prediction: IN H PU O\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WE ARE GOING TO HAVE A RACE AND ITS A VERY\n",
      "Prediction: IE OE AE I IN TIN IE A A AN N T T\n",
      "Word Error Rate:  109.09090909090908%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 596s 3s/step - loss: 102.7033 - val_loss: 98.6022\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "Original: SO ON THAT BASIS\n",
      "Prediction: I O O I I OIS IS\n",
      "Word Error Rate:  175.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHEN IM GOING ROUND\n",
      "Prediction: WO O ON O O\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: FAMOUS FOR ITS MINING IN THE PAST\n",
      "Prediction: I O O S O I A O IE\n",
      "Word Error Rate:  128.57142857142858%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND YOU HAVE TO LOOK VERY CLOSELY\n",
      "Prediction: IHE A H H O OS E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 604s 4s/step - loss: 103.6571 - val_loss: 100.1046\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "Original: WHO KNOWS WHERE TO START\n",
      "Prediction: TH O WS WHE HE \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: EAST AND WEST TO SIT AT YOUR TABLE\n",
      "Prediction: TE E E T A A A A \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: PLEASE MAKE YOUR WAY TO THE SAFE AREA\n",
      "Prediction: THE S AE AE OE O A AT\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: DECORATING COMES UNDER MAINTENANCE\n",
      "Prediction: THE ESE E A O H\n",
      "Word Error Rate:  150.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 598s 4s/step - loss: 99.0116 - val_loss: 99.6678\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "Original: THE DEER ARENT MANAGED SO WELL\n",
      "Prediction: I E E E A IG\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: HES BEEN UP ALL NIGHT\n",
      "Prediction: TH E A A A \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THAT IS SUCH A HARSH WORD\n",
      "Prediction: THE E H O H HA A\n",
      "Word Error Rate:  116.66666666666667%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE BAIT FISHING MAY STILL BE A LITTLE BIT OF A CHINK IN HIS ARMOUR\n",
      "Prediction: IE HAT AE AS A A O H T\n",
      "Word Error Rate:  86.66666666666667%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 600s 4s/step - loss: 100.5494 - val_loss: 97.7184\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "Original: IF YOU CARED ANYTHING ABOUT YOUR KID\n",
      "Prediction: IE E E E E O O OI\n",
      "Word Error Rate:  114.28571428571428%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IT WAS A BATTLE THAT CHANGED THE COURSE OF HISTORY\n",
      "Prediction: T E T A A A HE E R O R\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHAT COLLECTORS MIGHT BE LOOKING FOR\n",
      "Prediction: IE E OE HE O O\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IS GETTING IN A BIT OF NICHE COLLECTING\n",
      "Prediction: TE AS AN AN IN IN IN\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 595s 3s/step - loss: 96.3315 - val_loss: 92.6008\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "Original: YOU HOUSEWIVES AT HOME SAY TO ME\n",
      "Prediction: WOD OE O WA TO O A O ONE\n",
      "Word Error Rate:  128.57142857142858%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS A TOP SPOT\n",
      "Prediction: IT T TOT\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHICH MEANS YOURE STILL PLUS TWENTY\n",
      "Prediction: WU OE E E A WO O\n",
      "Word Error Rate:  116.66666666666667%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND THE OTHER ONE IS A HOUSEHOLD NAME\n",
      "Prediction: THD HES H OS OE O L HU HA \n",
      "Word Error Rate:  112.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 605s 4s/step - loss: 99.3613 - val_loss: 92.8189\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "Original: TO BE PERFECTLY FRANK\n",
      "Prediction: IE AE E E IE\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SO WONDERFUL TO SEE THAT\n",
      "Prediction: IO WONE FU O H\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ABOUT YOUR ITALIAN AND YOUR INFLUENZA AND EVERYTHING\n",
      "Prediction: TOT O AS A T TA OA AET TE THT\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I WOULDNT WEAR THAT\n",
      "Prediction: IE OE O IT\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 604s 4s/step - loss: 95.8526 - val_loss: 90.2021\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "Original: A LITTLE BIT OF PEACE WOULD BE LOVELY\n",
      "Prediction: IN T OE A O OD LELY\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: DURING THE NIGHT\n",
      "Prediction: BHE E E E\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND WITH STEALTH\n",
      "Prediction: AND WL TH T H\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I WANT TO BE CONSIDERED FOR ADVANCEMENT\n",
      "Prediction: IETIT TE TE E E E E E TI IE\n",
      "Word Error Rate:  142.85714285714286%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 605s 4s/step - loss: 95.4937 - val_loss: 91.1306\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "Original: LOVELY FAMILY HOME\n",
      "Prediction: IE AI IE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE DERBYSHIRE ANTIQUES ADMIRATION SOCIETY\n",
      "Prediction: I IE I I IUS U IE I O O O O O ORM OA\n",
      "Word Error Rate:  300.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND WHAT ARE THESE\n",
      "Prediction: I HE O OT\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND IN MARTINS CASE YOUR BRAIN\n",
      "Prediction: I I A A O O A O O\n",
      "Word Error Rate:  150.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 599s 4s/step - loss: 90.9302 - val_loss: 87.8357\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "Original: AND THE EVER PRESENT RISK OF ATTACK\n",
      "Prediction: AND HE ER PRERE ON O ATAC\n",
      "Word Error Rate:  85.71428571428571%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: TIME TO TALK TO A COUPLE WHO ARE OFFICIALLY THE UNDEFEATED CHAMPIONS OF THE DANCE OFF\n",
      "Prediction: TE AE AE OE HE TE OD O AN H OAD L IO TI O AE O O I OE\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WE WOULD NOT HAVE HAD THE JOY OF SEEING THE LABOUR HIGH COMMAND IN A GREGGS TRYING TO PRETEND\n",
      "Prediction: IE ED OE O AN A A A ORD AN AD H H O ON ON AL O PRE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE BEST IN THE WORLD\n",
      "Prediction: I L INL HOEDS\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 597s 4s/step - loss: 89.8260 - val_loss: 84.4533\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "Original: WE SHOULD PURSUE THIS STRATEGY\n",
      "Prediction: TE O OE US THES THES\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WAY BEFORE YOUR TIME\n",
      "Prediction: I BEFOR OR U\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WERE USING MORE COAL TO MAKE ELECTRICITY\n",
      "Prediction: THE ON NG HE AL O ON OR IEIN\n",
      "Word Error Rate:  128.57142857142858%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IT WILL ALLOW US TO LOOK UP AT OUR GALAXY AND DEDUCE THE PROPERTIES OF DARK MATTER FROM WHAT\n",
      "Prediction: TE WE E E E AE OE O BO O OE UE TE HIE HE E OE AE OE AN TRN N TH TE O O HON\n",
      "Word Error Rate:  142.10526315789474%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 602s 4s/step - loss: 87.9231 - val_loss: 86.9244\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "Original: AND ONE LAST THING\n",
      "Prediction: AD ON ALTHIN\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND TWO DAYS AFTER LANDING\n",
      "Prediction: AND WOAY FE AI\n",
      "Word Error Rate:  80.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHICH IS WHAT I DO\n",
      "Prediction: THE OS O ID\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: HE DESPISED IT WITH A PASSION\n",
      "Prediction: TS OU L E H R\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 599s 4s/step - loss: 84.3201 - val_loss: 82.3074\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "Original: THE GOVERNMENT HAS PROMISED THOSE COMMUNITIES DESTROYED BY THE RIOTS THAT THE BBC WILL MAKE A DRAMA\n",
      "Prediction: TE OE EN HS POE E TOE E O TIE A O O O TI TE THT THES SE HE A HE E A\n",
      "Word Error Rate:  135.29411764705884%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: PAULS A HOST AT ONE OF THE LOCAL HOTELS IN TORQUAY\n",
      "Prediction: WHE IS T HA AU A I T ON\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE GROUNDS ARE SO EXTENSIVE\n",
      "Prediction: THE OUN S RE OE HE E\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHAT ARE YOU DOING HERE\n",
      "Prediction: WH O OE HE ET\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 603s 4s/step - loss: 85.5497 - val_loss: 80.5749\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "Original: WHICH ROUGHLY TRANSLATES AS DYE SPOTS\n",
      "Prediction: IH H ROU A A AS OS\n",
      "Word Error Rate:  116.66666666666667%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND EXQUISITE DANCING\n",
      "Prediction: AND QISTIS ACIG\n",
      "Word Error Rate:  66.66666666666666%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: LETS FIND OUT WHAT THE BIDDERS THINK\n",
      "Prediction: IHI A OUT HOE O O AN \n",
      "Word Error Rate:  85.71428571428571%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: DONT OVER ANALYSE IT\n",
      "Prediction: I OVR AE A\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 598s 4s/step - loss: 83.7086 - val_loss: 75.1172\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "Original: AND THE FIRST THING SHE KNEW ABOUT IT WAS WHEN IT APPEARED IN THE TELEGRAPH\n",
      "Prediction: TH HE WE HE WE WHE WHE WE WE WE WE WE IE E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: EIGHT OCLOCK ON A MONDAY NIGHT\n",
      "Prediction: IH A E HE AE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IF I VERE IN CHARGE OF SECURITY\n",
      "Prediction: I I IE AN HARE O BO IT\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: FOUR CELEBRITIES WHO HAVE BOWED TO PRESSURE AND AGREED TO BE TESTED ON HOW MUCH THEY KNOW\n",
      "Prediction: WHE REIE IE TOE OE WOR HE THE RE HAN TE IE TAT THETE A E THE TI E E\n",
      "Word Error Rate:  117.64705882352942%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 607s 4s/step - loss: 80.2266 - val_loss: 78.4711\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "Original: SO MAYBE WE SHOULD SAY TO NICK\n",
      "Prediction: TE AE AS O O OI\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: MEMORIES AND OUR EMOTIONAL STATES\n",
      "Prediction: IMRIS AD OUR ME OI ATASTHSTH\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I LIKE TO KEEP FIGURES ROUND\n",
      "Prediction: I IK O I I IE\n",
      "Word Error Rate:  83.33333333333334%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SOMETIMES ONE HAS TO EMBARK ON AN UNKNOWN JOURNEY LIKE THIS\n",
      "Prediction: IH A OE HE E O I I IE I IE IN OT A\n",
      "Word Error Rate:  127.27272727272727%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 605s 4s/step - loss: 80.6453 - val_loss: 73.1334\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "Original: SO IT ACTS AS A VERY EFFECTIVE DECOY AND IT MIGHT KEEP THE PREDATOR OCCUPIED\n",
      "Prediction: T IS AS AY AE E ED OE AND I IG TE HE PAED O ORCIE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: FINDING THREE MONTH OLD CURRIES UNDER THE BED\n",
      "Prediction: TH HE L IY TOR TA AS TO A P TOT\n",
      "Word Error Rate:  137.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BRINGING WEATHER SYSTEM AFTER WEATHER SYSTEM\n",
      "Prediction: TRINS AT ES TO Y MAE R ATES THE HE\n",
      "Word Error Rate:  166.66666666666669%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IT WAS MY ANCESTORS WHO WERE HUNTING THEIR HEADS\n",
      "Prediction: THE HE HTE OE AE TAS OE LA A ES\n",
      "Word Error Rate:  111.11111111111111%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 602s 4s/step - loss: 75.9482 - val_loss: 69.5705\n",
      "Epoch 47/300\n",
      "171/171 [==============================] - ETA: 0s - loss: 74.5386"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  InvalidArgumentError: {{function_node __wrapped__Pack_N_67_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [40,120,1] != values[19].shape = [40,1,120] [Op:Pack] name: packed\nTraceback (most recent call last):\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\monis\\AppData\\Local\\Temp\\ipykernel_9104\\3629012439.py\", line 13, in loadData\n    frames = loadVideo(videoPath)\n\n  File \"C:\\Users\\monis\\AppData\\Local\\Temp\\ipykernel_9104\\3629012439.py\", line 52, in loadVideo\n    mean = tf.math.reduce_mean(processedFrames, keepdims=True)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 7209, in raise_from_not_ok_status\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Pack_N_67_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [40,120,1] != values[19].shape = [40,1,120] [Op:Pack] name: packed\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) UNKNOWN:  InvalidArgumentError: {{function_node __wrapped__Pack_N_67_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [40,120,1] != values[19].shape = [40,1,120] [Op:Pack] name: packed\nTraceback (most recent call last):\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\monis\\AppData\\Local\\Temp\\ipykernel_9104\\3629012439.py\", line 13, in loadData\n    frames = loadVideo(videoPath)\n\n  File \"C:\\Users\\monis\\AppData\\Local\\Temp\\ipykernel_9104\\3629012439.py\", line 52, in loadVideo\n    mean = tf.math.reduce_mean(processedFrames, keepdims=True)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 7209, in raise_from_not_ok_status\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Pack_N_67_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [40,120,1] != values[19].shape = [40,1,120] [Op:Pack] name: packed\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_test_function_698881]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnknownError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m300\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mcheckpointCallback2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexampleCallback2\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     55\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mUnknownError\u001B[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  InvalidArgumentError: {{function_node __wrapped__Pack_N_67_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [40,120,1] != values[19].shape = [40,1,120] [Op:Pack] name: packed\nTraceback (most recent call last):\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\monis\\AppData\\Local\\Temp\\ipykernel_9104\\3629012439.py\", line 13, in loadData\n    frames = loadVideo(videoPath)\n\n  File \"C:\\Users\\monis\\AppData\\Local\\Temp\\ipykernel_9104\\3629012439.py\", line 52, in loadVideo\n    mean = tf.math.reduce_mean(processedFrames, keepdims=True)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 7209, in raise_from_not_ok_status\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Pack_N_67_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [40,120,1] != values[19].shape = [40,1,120] [Op:Pack] name: packed\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) UNKNOWN:  InvalidArgumentError: {{function_node __wrapped__Pack_N_67_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [40,120,1] != values[19].shape = [40,1,120] [Op:Pack] name: packed\nTraceback (most recent call last):\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\monis\\AppData\\Local\\Temp\\ipykernel_9104\\3629012439.py\", line 13, in loadData\n    frames = loadVideo(videoPath)\n\n  File \"C:\\Users\\monis\\AppData\\Local\\Temp\\ipykernel_9104\\3629012439.py\", line 52, in loadVideo\n    mean = tf.math.reduce_mean(processedFrames, keepdims=True)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 7209, in raise_from_not_ok_status\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Pack_N_67_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [40,120,1] != values[19].shape = [40,1,120] [Op:Pack] name: packed\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_test_function_698881]"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-07-04T19:24:26.520087Z"
    }
   },
   "cell_type": "code",
   "source": "model2.fit(train, validation_data=test, epochs=300, callbacks=[checkpointCallback2, exampleCallback2], use_multiprocessing=True)",
   "id": "df68abce0cca2684",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "121/171 [====================>.........] - ETA: 52s - loss: 74.4674"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "try: \n",
    "    model2.fit(train, validation_data=test, epochs=300, callbacks=[checkpointCallback2, exampleCallback2], use_multiprocessing=True)\n",
    "except: \n",
    "    try: \n",
    "        model2.load_weights('newLipModelv11_m2.weights.h5')\n",
    "        model2.fit(train, validation_data=test, epochs=300, callbacks=[checkpointCallback2, exampleCallback2], use_multiprocessing=True)\n",
    "    except: \n",
    "        try: \n",
    "            model2.load_weights('newLipModelv11_m2.weights.h5')\n",
    "            model2.fit(train, validation_data=test, epochs=300, callbacks=[checkpointCallback2, exampleCallback2], use_multiprocessing=True)\n",
    "        except: \n",
    "            try: \n",
    "                model2.load_weights('newLipModelv11_m2.weights.h5')\n",
    "                model2.fit(train, validation_data=test, epochs=300, callbacks=[checkpointCallback2, exampleCallback2], use_multiprocessing=True)\n",
    "            except: \n",
    "                try: \n",
    "                    model2.load_weights('newLipModelv11_m2.weights.h5')\n",
    "                    model2.fit(train, validation_data=test, epochs=300, callbacks=[checkpointCallback2, exampleCallback2], use_multiprocessing=True)\n",
    "                except: \n",
    "                    print(\"fml\")"
   ],
   "id": "a7c3148d288c8a16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T04:49:37.285290Z",
     "start_time": "2024-07-03T04:49:37.064554Z"
    }
   },
   "cell_type": "code",
   "source": "model2.save_weights('')",
   "id": "9ed847ccbbdefe0d",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid bias shape: (1024,)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[229], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# image size msut be \u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mmodel2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_weights\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnewLipModelv1_m2.weights.h5\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\saving\\hdf5_format.py:649\u001B[0m, in \u001B[0;36m_convert_rnn_weights\u001B[1;34m(layer, weights)\u001B[0m\n\u001B[0;32m    647\u001B[0m     source \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGRU(reset_after=False)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    648\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 649\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid bias shape: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(bias_shape))\n\u001B[0;32m    651\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m target_class \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCuDNNGRU\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    652\u001B[0m     target \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCuDNNGRU\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[1;31mValueError\u001B[0m: Invalid bias shape: (1024,)"
     ]
    }
   ],
   "execution_count": 229
  },
  {
   "cell_type": "code",
   "id": "441f0789798741da",
   "metadata": {},
   "source": "model.fit(train, validation_data=test, epochs=200, callbacks=[scheduleCallback, checkpointCallback, exampleCallback])",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8c641bb605c23341",
   "metadata": {},
   "source": [
    "yHat = model.predict(val[0])\n",
    "print(tf.strings.reduce_join([numToChar(tf.argmax(x)) for x in yHat[0]]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1a18ff5285cbb556",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6eff0658378dde17",
   "metadata": {},
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = model.history.history['loss']\n",
    "test_loss = model.history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "88f6fecc2fb453ef",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
