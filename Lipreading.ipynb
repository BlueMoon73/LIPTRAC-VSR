{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T06:15:43.868167Z",
     "start_time": "2024-06-24T06:15:43.854655Z"
    }
   },
   "source": [
    "# imports \n",
    "import os \n",
    "import tensorflow as tf \n",
    "import cv2 \n",
    "import numpy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# making GPU be used, and setting memory limits\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "# gpus = tf.config.list_logical_devices('GPU')\n",
    "print(gpus)\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    print(\"gpu set\")\n",
    "except:\n",
    "    pass\n",
    "    print(\"failed\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "gpu set\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "cell_type": "markdown",
   "id": "7c48bcf107f4c31b",
   "metadata": {},
   "source": [
    "## basic functions"
   ]
  },
  {
   "cell_type": "code",
   "id": "787272fefa6ec811",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T06:39:12.304673Z",
     "start_time": "2024-06-24T06:39:12.260436Z"
    }
   },
   "source": [
    "# setting up the functions to convert from chars to num and vice versa\n",
    "vocab = [x for x in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 \"]\n",
    "charToNum = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
    "numToChar = tf.keras.layers.StringLookup(vocabulary=charToNum.get_vocabulary(), oov_token=\"\", invert=True)\n",
    "\n",
    "# facial detection vars \n",
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "lastKnownCrop = (0, 0, 160, 150)\n",
    "\n",
    "# data dir\n",
    "rootDir = 'A:\\Lip Reading\\Potential Datasets\\BBC LRS2\\\\allFiles'\n",
    "# r = \"A:\\Lip Reading\\Potential Datasets\\BBC LRS2\\\\allFiles\"\n",
    "\n",
    "batchSize = 2"
   ],
   "outputs": [],
   "execution_count": 133
  },
  {
   "cell_type": "code",
   "id": "c2e49edea7bd4712",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T06:39:12.415605Z",
     "start_time": "2024-06-24T06:39:12.407092Z"
    }
   },
   "source": [
    "def faceDetection(img):\n",
    "    # TROUBLESHOOTING\n",
    "    # print(\"max size:\",img.shape, img.shape[0] - 3 * padding, img.shape[1] - 3 * padding)\n",
    "    return faceCascade.detectMultiScale(\n",
    "        img,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "    )\n",
    "\n",
    "def cropForMouth(img) -> numpy.ndarray:\n",
    "    global lastKnownCrop\n",
    "    rects = faceDetection(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
    "    \n",
    "    # finding the largest face in a given image \n",
    "    largestFace = (0,0,0,0)\n",
    "    for (x, y, w, l) in rects:\n",
    "        if (w * l) > largestFace[2] * largestFace[3]:\n",
    "            largestFace = (x, y,w,l)\n",
    "        \n",
    "    if largestFace == (0,0,0,0):\n",
    "        largestFace =lastKnownCrop\n",
    "    # cropping for face \n",
    "    lastKnownCrop = largestFace\n",
    "    y1 = lastKnownCrop[1] \n",
    "    x1 = lastKnownCrop[0]\n",
    "    y2 = y1 + lastKnownCrop[3] \n",
    "    x2 = x1 + lastKnownCrop[2]\n",
    "    return img[y1 + int(0.65 * lastKnownCrop[3]): y2, x1 + int(0.05 * lastKnownCrop[2]): int(0.95 * x2)]"
   ],
   "outputs": [],
   "execution_count": 134
  },
  {
   "cell_type": "code",
   "id": "c7fbad6e80991f3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T06:40:24.063402Z",
     "start_time": "2024-06-24T06:40:24.052559Z"
    }
   },
   "source": [
    "def loadData(path): \n",
    "    # tf has the paths as bytes so decode that\n",
    "    path = bytes.decode(path.numpy())\n",
    "    \n",
    "    # extract just the file names\n",
    "    global rootDir\n",
    "    fileName = path.split('\\\\')[-1].split('.')[0]\n",
    "    # generate the respective paths of the data\n",
    "    videoPath = os.path.join(rootDir,f'{fileName}.mp4')\n",
    "    alignmentPath = os.path.join(rootDir,f'{fileName}.txt')\n",
    "    \n",
    "    # return the frames and alignments\n",
    "    frames = loadVideo(videoPath) \n",
    "    alignments = loadText(alignmentPath)\n",
    "    return frames, alignments\n",
    "\n",
    "def loadVideo(path): \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    global lastKnownCrop\n",
    "    processedFrames = []\n",
    "    # for each frame \n",
    "    for n in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))): \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # in case a frame is missing, just continue\n",
    "        if frame is None or frame.shape[0] == 0: \n",
    "            continue\n",
    "        \n",
    "        # crop only the mouth like we'll do on the RPI \n",
    "        frame = cropForMouth(frame)\n",
    "        frame = cv2.resize(frame, (150, 50))\n",
    "        \n",
    "        try: frame = tf.image.rgb_to_grayscale(frame)\n",
    "        except: continue\n",
    "        \n",
    "        processedFrames.append(frame)\n",
    "        \n",
    "    cap.release()    \n",
    "\n",
    "    # generate the normalized frames (deviation from the average) \n",
    "    mean = tf.math.reduce_mean(processedFrames)\n",
    "    std = tf.math.reduce_std(tf.cast(processedFrames, tf.float32), axis=[0, 1, 2], keepdims=True)\n",
    "    frames = tf.cast(processedFrames, tf.float32)\n",
    "    normalizedFrames = (tf.cast(frames, tf.float32) - tf.cast(mean, tf.float32)) / tf.cast(std, tf.float32)\n",
    "    return normalizedFrames\n",
    "\n",
    "def loadText(path): \n",
    "    # open and parse the file \n",
    "    with open(path, 'r') as file: lines = file.readlines()\n",
    "    file.close()\n",
    "    \n",
    "    # return the number equivalent of each of the characters of the word \n",
    "    tokens = []\n",
    "    words = lines[0].split()\n",
    "    del words[0]\n",
    "    for word in words: tokens = [*tokens,' ', word]\n",
    "    \n",
    "    return charToNum(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]   \n",
    "\n",
    "def processData(path): \n",
    "    return tf.py_function(loadData, [path],  (tf.float32, tf.int64))"
   ],
   "outputs": [],
   "execution_count": 144
  },
  {
   "cell_type": "code",
   "id": "a401cd6fa0067aed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T06:40:24.201395Z",
     "start_time": "2024-06-24T06:40:24.183879Z"
    }
   },
   "source": [
    "def getFrameCount(path) -> int: \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frameCount = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    cap.release()\n",
    "    return frameCount\n",
    "\n",
    "def getCharCount(path) -> int: \n",
    "    return len(loadText(path))"
   ],
   "outputs": [],
   "execution_count": 145
  },
  {
   "cell_type": "code",
   "id": "1dc8265fa1dc4688",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T06:40:24.777420Z",
     "start_time": "2024-06-24T06:40:24.332529Z"
    }
   },
   "source": [
    "rawPath = \"A:\\\\Lip Reading\\\\Potential Datasets\\\\BBC LRS2\\\\allFiles\\\\5535415699068794046_00001.mp4\"\n",
    "maxframeCt = 154\n",
    "maxCharCt = 99\n",
    "\n",
    "tensorPath = tf.convert_to_tensor(rawPath, dtype=tf.string)\n",
    "path = bytes.decode(tensorPath.numpy())\n",
    "fileName = path.split('\\\\')[-1].split('.')[0]\n",
    "\n",
    "# testing if the loadData, loadVideo, and loadText function all work\n",
    "videoPath = os.path.join(rootDir,f'{fileName}.mp4')\n",
    "alignmentPath = os.path.join(rootDir,f'{fileName}.txt')\n",
    "\n",
    "loadVideo(videoPath)\n",
    "loadText(alignmentPath)\n",
    "frames, text = loadData(tensorPath)\n",
    "print(type(frames))\n",
    "print(len(frames[0][0]))\n",
    "# print(videoPath)\n",
    "# print(alignmentPath)\n",
    "# print(text)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "150\n"
     ]
    }
   ],
   "execution_count": 146
  },
  {
   "cell_type": "markdown",
   "id": "b323b3673a461c65",
   "metadata": {},
   "source": [
    "## reading data"
   ]
  },
  {
   "cell_type": "code",
   "id": "15d040463f02dc61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T06:40:26.490543Z",
     "start_time": "2024-06-24T06:40:26.445548Z"
    }
   },
   "source": [
    "# reading all files within the root directory\n",
    "# data = tf.data.Dataset.list_files('A:\\Lip Reading\\Potential Datasets\\BBC LRS2\\mvlrs_v1\\main\\*\\*.mp4')\n",
    "data = tf.data.Dataset.list_files('A:/Lip Reading/Potential Datasets/BBC LRS2/trainFiles2/*.mp4')\n",
    "\n",
    "data = data.shuffle(int(len(data) / 4), reshuffle_each_iteration=False) # shuffling data\n",
    "data = data.map(processData) # \"processing\" the data to obtain frames and the respective text \n",
    "\n",
    "dim1 = frames.shape[1]\n",
    "dim2 = frames.shape[2]\n",
    "print(\"dataset size before padding:\", len(data))\n",
    "print(\"data shape of example video:\", frames.shape)\n",
    "\n",
    "# combining 8 videos as one \"input\"\n",
    "# ensuring all videos are padded to match the longest video, \n",
    "# ensuring the length of all the alignments is the size of the longest text characters, as some are lower. \n",
    "data = data.padded_batch(batchSize, padded_shapes=([2*maxCharCt,dim1, dim2,1], [maxCharCt])) \n",
    "data = data.prefetch(tf.data.AUTOTUNE)\n",
    "print(\"data length after padding:\", len(data))\n",
    "print(\"batch size:\", batchSize)\n",
    "\n",
    "train = data.take(int(len(data) * 0.9))\n",
    "test = data.skip(int(len(data) * 0.9))\n",
    "print(\"train data size:\", len(train))\n",
    "print(\"test data size:\",  len(test))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size before padding: 1115\n",
      "data shape of example video: (35, 50, 150, 1)\n",
      "data length after padding: 558\n",
      "batch size: 2\n",
      "train data size: 502\n",
      "test data size: 56\n"
     ]
    }
   ],
   "execution_count": 147
  },
  {
   "cell_type": "code",
   "id": "771515f5cef4617f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T06:40:27.706867Z",
     "start_time": "2024-06-24T06:40:26.575385Z"
    }
   },
   "source": [
    "val = data.as_numpy_iterator().next()\n",
    "plt.imshow(val[0][0][30])\n",
    "print(len(val[0][0]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 148
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T06:40:27.816875Z",
     "start_time": "2024-06-24T06:40:27.708855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tf.strings.reduce_join([numToChar(word) for word in val[1][0]])\n",
    "print(\"num of chars:\", len(([numToChar(word) for word in val[1][0]])))"
   ],
   "id": "e1b71a67fbe998bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of chars: 99\n"
     ]
    }
   ],
   "execution_count": 149
  },
  {
   "cell_type": "markdown",
   "id": "7b9fe2e89759a25",
   "metadata": {},
   "source": [
    "## designing the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "44de38608ebec792",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T06:40:27.832391Z",
     "start_time": "2024-06-24T06:40:27.819879Z"
    }
   },
   "source": [
    "# imports for the model architecture \n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPooling3D, TimeDistributed, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ],
   "outputs": [],
   "execution_count": 150
  },
  {
   "cell_type": "code",
   "id": "a4e35802d732d3c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T06:40:29.005068Z",
     "start_time": "2024-06-24T06:40:27.834525Z"
    }
   },
   "source": [
    "inputShape = data.as_numpy_iterator().next()[0][0].shape\n",
    "print(inputShape)\n",
    "print(charToNum.get_vocabulary())\n",
    "print(len(charToNum.get_vocabulary()))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198, 50, 150, 1)\n",
      "['', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ' ']\n",
      "38\n"
     ]
    }
   ],
   "execution_count": 151
  },
  {
   "cell_type": "code",
   "id": "84706072692f52d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T06:40:29.317559Z",
     "start_time": "2024-06-24T06:40:29.007071Z"
    }
   },
   "source": [
    "# model to be actually trained\n",
    "model = Sequential([\n",
    "Conv3D(32, 3, input_shape=inputShape, padding='same', activation='relu'),\n",
    "MaxPooling3D((1,6,10)),\n",
    "\n",
    "Conv3D(maxframeCt, 5, padding='same', activation='relu'),\n",
    "\n",
    "TimeDistributed(Flatten()),\n",
    "\n",
    "Bidirectional(LSTM(16, return_sequences=True)),\n",
    "Dropout(.5),\n",
    "\n",
    "Dense(charToNum.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax')\n",
    "])\n",
    "\n",
    "# model = Sequential([\n",
    "# Conv3D(128, 3, input_shape=inputShape, padding='same', activation='relu'),\n",
    "# MaxPooling3D((1,2,2)),\n",
    "# \n",
    "# Conv3D(256, 3, padding='same', activation='relu'),\n",
    "# MaxPooling3D((1,2,2)),\n",
    "# \n",
    "# Conv3D(154, 3, padding='same', activation='relu'),\n",
    "# MaxPooling3D((1,2,2)),\n",
    "# \n",
    "# TimeDistributed(Flatten()),\n",
    "# \n",
    "# Bidirectional(LSTM(128, return_sequences=True)),\n",
    "# Dropout(.5),\n",
    "# \n",
    "# Bidirectional(LSTM(128,  return_sequences=True)),\n",
    "# Dropout(.5),\n",
    "# \n",
    "# Dense(charToNum.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax')\n",
    "# ])\n",
    "\n",
    "# \n",
    "# testModel = Sequential([\n",
    "# Conv3D(154, 5, input_shape=inputShape, padding='same', activation='relu'),\n",
    "# MaxPooling3D((1,3,5)),\n",
    "#  \n",
    "# TimeDistributed(Flatten()),\n",
    "#     \n",
    "# Dense(charToNum.vocabulary_size()+1, activation='softmax')\n",
    "# ])\n",
    "# \n",
    "# model3 = Sequential([\n",
    "# Conv3D(32, 3, input_shape=inputShape, padding='same', activation='relu'),\n",
    "# MaxPooling3D((1,2,2)),\n",
    "# \n",
    "# Conv3D(64, 3, input_shape=inputShape, padding='same', activation='relu'),\n",
    "# MaxPooling3D((1,2,2)),\n",
    "# \n",
    "# Conv3D(154, 3, padding='same', activation='relu'),\n",
    "# MaxPooling3D((1,2,2)),\n",
    "# \n",
    "# TimeDistributed(Flatten()),\n",
    "# \n",
    "# Bidirectional(LSTM(64, return_sequences=True)),\n",
    "# Dropout(0.5),\n",
    "# \n",
    "# Bidirectional(LSTM(64, return_sequences=True)),\n",
    "# Dropout(0.5),\n",
    "# \n",
    "# Dense(charToNum.vocabulary_size()+1, activation='softmax')\n",
    "# ])"
   ],
   "outputs": [],
   "execution_count": 152
  },
  {
   "cell_type": "code",
   "id": "d728bc2771721d6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T06:40:29.332699Z",
     "start_time": "2024-06-24T06:40:29.318560Z"
    }
   },
   "source": [
    "model.summary()\n",
    "# testModel.summary()\n",
    "# model3.summary()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_22 (Conv3D)          (None, 198, 50, 150, 32)  896       \n",
      "                                                                 \n",
      " max_pooling3d_11 (MaxPoolin  (None, 198, 8, 15, 32)   0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_23 (Conv3D)          (None, 198, 8, 15, 154)   616154    \n",
      "                                                                 \n",
      " time_distributed_11 (TimeDi  (None, 198, 18480)       0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " bidirectional_11 (Bidirecti  (None, 198, 32)          2367616   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 198, 32)           0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 198, 39)           1287      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,985,953\n",
      "Trainable params: 2,985,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 153
  },
  {
   "cell_type": "code",
   "id": "9cd1b05996f23f8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T06:40:31.676598Z",
     "start_time": "2024-06-24T06:40:31.660529Z"
    }
   },
   "source": [
    "# custom functions \n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 30:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "# custom loss function \n",
    "def CTCLoss(yTrue, yPred):\n",
    "    \n",
    "    # y true is the text alignment (None, 99) \n",
    "    # y pred is the end result of the model (154, 41) \n",
    "    batchLen = tf.cast(tf.shape(yTrue)[0], dtype=\"int64\")\n",
    "    # print(\"tf.shape(yTrue)[0]:\", tf.shape(yTrue)[0])\n",
    "    inputLen = tf.cast(tf.shape(yPred)[1], dtype=\"int64\")\n",
    "    labelLen = tf.cast(tf.shape(yTrue)[1], dtype=\"int64\")\n",
    "    # print(\"initial inputlen\", inputLen)\n",
    "    # print(\"initial labellen\", labelLen)\n",
    "\n",
    "    inputLen = inputLen * tf.ones(shape=(batchLen, 1), dtype=\"int64\")\n",
    "    labelLen = labelLen * tf.ones(shape=(batchLen, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = tf.keras.backend.ctc_batch_cost(yTrue, yPred, inputLen, labelLen)   \n",
    "    # print(\"ytrue\", yTrue)\n",
    "    # print(\"ypred\",yPred)\n",
    "    # print(\"batchlen\", batchLen)\n",
    "    # print(\"inputlen\", inputLen)\n",
    "    # print(\"labellen\",labelLen)\n",
    "    # print(\"loss\",loss)\n",
    "    # print(\"*\" * 50) \n",
    "\n",
    "    # return loss\n",
    "    return loss \n",
    "\n",
    "\n",
    "class ProduceExample(tf.keras.callbacks.Callback): \n",
    "    def __init__(self, dataset) -> None: \n",
    "        self.dataset = dataset.as_numpy_iterator()\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None) -> None:\n",
    "        data = self.dataset.next()\n",
    "        yhat = self.model.predict(data[0])\n",
    "        \n",
    "        decoded = tf.keras.backend.ctc_decode(yhat, [maxframeCt, maxframeCt], greedy=False)[0][0].numpy()\n",
    "        for x in range(len(yhat)):           \n",
    "            print('Original:', tf.strings.reduce_join(numToChar(data[1][x])).numpy().decode('utf-8'))\n",
    "            print('Prediction:', tf.strings.reduce_join(numToChar(decoded[x])).numpy().decode('utf-8'))\n",
    "            print('~'*100)"
   ],
   "outputs": [],
   "execution_count": 154
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T06:40:32.803301Z",
     "start_time": "2024-06-24T06:40:31.841034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "yHat = model.predict(val[0])\n",
    "print(tf.strings.reduce_join([numToChar(tf.argmax(x)) for x in yHat[0]]))\n",
    "print(len(([numToChar(tf.argmax(x)) for x in yHat[0]])))"
   ],
   "id": "d5afa6ac776aca30",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 734ms/step\n",
      "tf.Tensor(b'LLLN7777WWWWWWWWWWNWWWWWWW7N77777777777777777777777777NN222NNNYYYYYYYYYYYIIIIIIIIIIII                5555555555555444444444WWWWTTTTTTTTTTTTNNHEEDDCCCA', shape=(), dtype=string)\n",
      "198\n"
     ]
    }
   ],
   "execution_count": 155
  },
  {
   "cell_type": "code",
   "id": "f92dcff213216a6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T06:40:32.834460Z",
     "start_time": "2024-06-24T06:40:32.805811Z"
    }
   },
   "source": [
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(learning_rate=0.0001), loss=CTCLoss)\n",
    "checkpointCallback = ModelCheckpoint('newLipModelv2_m1.weights.h5', monitor='loss',save_weights_only=False) \n",
    "scheduleCallback = LearningRateScheduler(scheduler)\n",
    "exampleCallback = ProduceExample(test)\n",
    "# \n",
    "# model3.compile(optimizer=RMSprop(learning_rate=0.001), loss=CTCLoss)\n",
    "# # checkpointCallback = ModelCheckpoint('newLipModelm3.weights.h5', monitor='loss',save_weights_only=False) \n",
    "# scheduleCallback = LearningRateScheduler(scheduler)\n",
    "# # exampleCallback = ProduceExample(test)\n",
    "#  \n",
    "# testModel.compile(optimizer=Adam(learning_rate=0.001), loss=CTCLoss)\n",
    "# scheduleCallback = LearningRateScheduler(scheduler)"
   ],
   "outputs": [],
   "execution_count": 156
  },
  {
   "cell_type": "code",
   "id": "441f0789798741da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T06:40:40.035563Z",
     "start_time": "2024-06-24T06:40:32.905660Z"
    }
   },
   "source": "model.fit(train, validation_data=test, epochs=100, callbacks=[scheduleCallback, checkpointCallback])",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  9/502 [..............................] - ETA: 3:17 - loss: 591.0393"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[157], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mscheduleCallback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheckpointCallback\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1564\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1556\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1557\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1558\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1561\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1562\u001B[0m ):\n\u001B[0;32m   1563\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1564\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1565\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1566\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateless_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2493\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   2494\u001B[0m   (graph_function,\n\u001B[0;32m   2495\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2496\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2497\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1858\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1859\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1860\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1861\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1862\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1863\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1864\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1865\u001B[0m     args,\n\u001B[0;32m   1866\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1867\u001B[0m     executing_eagerly)\n\u001B[0;32m   1868\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 157
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "yHat = model.predict(val[0])\n",
    "print(tf.strings.reduce_join([numToChar(tf.argmax(x)) for x in yHat[0]]))"
   ],
   "id": "8c641bb605c23341",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.load_weights('newLipModel_m1.weights.h5')",
   "id": "1a18ff5285cbb556",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = model.history.history['loss']\n",
    "test_loss = model.history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ],
   "id": "6eff0658378dde17",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "88f6fecc2fb453ef",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
