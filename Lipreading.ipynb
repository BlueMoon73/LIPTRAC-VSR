{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:57:53.552631Z",
     "start_time": "2024-07-04T05:57:53.538550Z"
    }
   },
   "source": [
    "# imports \n",
    "import os \n",
    "import tensorflow as tf \n",
    "import cv2 \n",
    "import numpy\n",
    "from matplotlib import pyplot as plt\n",
    "from jiwer import wer \n",
    "# making GPU be used, and setting memory limits\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "# gpus = tf.config.list_logical_devices('GPU')\n",
    "print(gpus)\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    print(\"gpu set\")\n",
    "except:\n",
    "    pass\n",
    "    print(\"failed\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "gpu set\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "7c48bcf107f4c31b",
   "metadata": {},
   "source": [
    "## basic functions"
   ]
  },
  {
   "cell_type": "code",
   "id": "787272fefa6ec811",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T23:46:42.749627Z",
     "start_time": "2024-07-05T23:46:42.671028Z"
    }
   },
   "source": [
    "# setting up the functions to convert from chars to num and vice versa\n",
    "vocab = [x for x in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ \"]\n",
    "charToNum = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
    "numToChar = tf.keras.layers.StringLookup(vocabulary=charToNum.get_vocabulary(), oov_token=\"\", invert=True)\n",
    "\n",
    "# facial detection vars \n",
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "lastKnownCrop = (0, 0, 160, 150)\n",
    "\n",
    "# data dir\n",
    "rootDir = 'A:\\Lip Reading\\Potential Datasets\\BBC LRS2\\\\allFiles'\n",
    "rootDir2 = 'A:\\Lip Reading\\Potential Datasets\\\\BBC LRS2'\n",
    "# r = \"A:\\Lip Reading\\Potential Datasets\\BBC LRS2\\\\allFiles\"\n",
    "\n",
    "errorNums = 0 \n",
    "errorPaths = []\n",
    "errorInfo = []\n",
    "frameSize = None\n",
    "frameSizeOld = None\n",
    "newFrameSize = None\n",
    "grayFrame = None\n",
    "newImageSize = (40, 120)\n",
    "\n",
    "maxCharCt = 145 # found from the dataStats.ipynb\n",
    "maxFrameCt = 2*maxCharCt"
   ],
   "outputs": [],
   "execution_count": 249
  },
  {
   "cell_type": "code",
   "id": "c2e49edea7bd4712",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T23:46:43.061322Z",
     "start_time": "2024-07-05T23:46:43.044804Z"
    }
   },
   "source": [
    "# util funcs \n",
    "def faceDetection(img):\n",
    "    # TROUBLESHOOTING\n",
    "    # print(\"max size:\",img.shape, img.shape[0] - 3 * padding, img.shape[1] - 3 * padding)\n",
    "    return faceCascade.detectMultiScale(\n",
    "        img,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "    )\n",
    "\n",
    "def cropForMouth(img) -> numpy.ndarray:\n",
    "    global lastKnownCrop\n",
    "    rects = faceDetection(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
    "    \n",
    "    # finding the largest face in a given image \n",
    "    largestFace = (0,0,0,0)\n",
    "    for (x, y, w, l) in rects:\n",
    "        if (w * l) > largestFace[2] * largestFace[3]:\n",
    "            largestFace = (x, y,w,l)\n",
    "        \n",
    "    if largestFace == (0,0,0,0):\n",
    "        largestFace =lastKnownCrop\n",
    "    # cropping for face \n",
    "    lastKnownCrop = largestFace\n",
    "    y1 = lastKnownCrop[1] \n",
    "    x1 = lastKnownCrop[0]\n",
    "    y2 = y1 + lastKnownCrop[3] \n",
    "    x2 = x1 + lastKnownCrop[2]\n",
    "    return img[y1 + int(0.65 * lastKnownCrop[3]): y2, x1 + int(0.05 * lastKnownCrop[2]): int(0.95 * x2)]\n",
    "\n",
    "def numberToWords(num):  \n",
    "    if num == 0:  \n",
    "        return \"zero\"  \n",
    "    ones = [\"\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\"]  \n",
    "    tens = [\"\", \"\", \"twenty\", \"thirty\", \"forty\", \"fifty\", \"sixty\", \"seventy\", \"eighty\", \"ninety\"]  \n",
    "    teens = [\"ten\", \"eleven\", \"twelve\", \"thirteen\", \"fourteen\", \"fifteen\", \"sixteen\", \"seventeen\", \"eighteen\", \"nineteen\"]  \n",
    "    words = \"\"  \n",
    "    if num>= 1000:  \n",
    "        words += ones[num // 1000] + \" thousand \"  \n",
    "        num %= 1000  \n",
    "    if num>= 100:  \n",
    "        words += ones[num // 100] + \" hundred \"  \n",
    "        num %= 100  \n",
    "    if num>= 10 and num<= 19:  \n",
    "        words += teens[num - 10] + \" \"  \n",
    "        num = 0  \n",
    "    elif num>= 20:  \n",
    "        words += tens[num // 10] + \" \"  \n",
    "        num %= 10  \n",
    "    if num>= 1 and num<= 9:  \n",
    "        words += ones[num] + \" \"  \n",
    "    return words.strip().upper()"
   ],
   "outputs": [],
   "execution_count": 250
  },
  {
   "cell_type": "code",
   "id": "c7fbad6e80991f3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T23:46:43.577412Z",
     "start_time": "2024-07-05T23:46:43.557729Z"
    }
   },
   "source": [
    "def loadData(path): \n",
    "    # tf has the paths as bytes so decode that\n",
    "    path = bytes.decode(path.numpy())\n",
    "    \n",
    "    # extract just the file names\n",
    "    global rootDir\n",
    "    fileName = path.split('\\\\')[-1].split('.')[0]\n",
    "    # generate the respective paths of the data\n",
    "    videoPath = os.path.join(rootDir,f'{fileName}.mp4')\n",
    "    alignmentPath = os.path.join(rootDir,f'{fileName}.txt')\n",
    "    \n",
    "    # return the frames and alignments\n",
    "    frames = loadVideo(videoPath) \n",
    "    alignments = loadText(alignmentPath)\n",
    "    return frames, alignments\n",
    "\n",
    "def loadVideo(path): \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    global lastKnownCrop, frameSizeOld, frameSize, newFrameSize, grayFrame\n",
    "    global errorNums\n",
    "    processedFrames = []\n",
    "    isFirstFrame = True\n",
    "    frameShape = None\n",
    "    # for each frame \n",
    "    for n in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))): \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # in case a frame is missing, just continue\n",
    "        if frame is None or frame.shape[0] == 0: \n",
    "            continue\n",
    "        \n",
    "        if isFirstFrame: \n",
    "            frameShape  = frame.shape\n",
    "            isFirstFrame = False\n",
    "        \n",
    "        if frame.shape != frameShape: \n",
    "            continue\n",
    "        # crop only the mouth like we'll do on the RPI \n",
    "        frameSizeOld = frame.shape\n",
    "        frame = cropForMouth(frame)\n",
    "        frameSize = frame.shape\n",
    "        frame = cv2.resize(frame, (newImageSize[1], newImageSize[0]))\n",
    "        newFrameSize = frame.shape\n",
    "        grayFrame = tf.image.rgb_to_grayscale(frame)\n",
    "        processedFrames.append(grayFrame)\n",
    "        # processedFrames = [*processedFrames, grayFrame]\n",
    "\n",
    "    \n",
    "    cap.release()    \n",
    "\n",
    "    # generate the normalized frames (deviation from the average)\n",
    "    mean = tf.math.reduce_mean(processedFrames, keepdims=True)\n",
    "    try: \n",
    "        std = tf.math.reduce_std(tf.cast(processedFrames, tf.float32),  keepdims=True)\n",
    "    except: \n",
    "        \n",
    "        errorPaths.append(path)\n",
    "        errorInfo.append(\"SECOND STATEMENT\")\n",
    "        errorInfo.append(len(processedFrames))\n",
    "        errorInfo.append(frameSizeOld)\n",
    "        errorInfo.append(frameSize)\n",
    "        errorInfo.append(newFrameSize)\n",
    "        errorInfo.append(grayFrame)\n",
    "    std = tf.math.reduce_std(tf.cast(processedFrames, tf.float32), keepdims=True)\n",
    "    frames = tf.cast(processedFrames, tf.float32)\n",
    "    normalizedFrames = (tf.cast(frames, tf.float32) - tf.cast(mean, tf.float32)) / tf.cast(std, tf.float32)\n",
    "    return normalizedFrames\n",
    "\n",
    "def loadText(path): \n",
    "    # open and parse the file \n",
    "    with open(path, 'r') as file: lines = file.readlines()\n",
    "    file.close()\n",
    "    \n",
    "    # return the number equivalent of each of the characters of the word \n",
    "    tokens = []\n",
    "    words = lines[0].split()\n",
    "    del words[0]\n",
    "\n",
    "    for word in words: \n",
    "        if word.isnumeric():\n",
    "            newWord = numberToWords(int(word))\n",
    "            words[words.index(word)] = newWord\n",
    "    words = \" \".join(words).split()\n",
    "    # print(words)\n",
    "    for word in words: \n",
    "        tokens = [*tokens,' ', word]\n",
    "    try:\n",
    "        return charToNum(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]   \n",
    "    except: \n",
    "        print(tokens)\n",
    "\n",
    "def processData(path): \n",
    "    return tf.py_function(loadData, [path],  (tf.float32, tf.int64))"
   ],
   "outputs": [],
   "execution_count": 251
  },
  {
   "cell_type": "code",
   "id": "a401cd6fa0067aed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T23:46:43.903859Z",
     "start_time": "2024-07-05T23:46:43.895860Z"
    }
   },
   "source": [
    "def getFrameCount(path) -> int: \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frameCount = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    cap.release()\n",
    "    return frameCount\n",
    "\n",
    "def getCharCount(path) -> int: \n",
    "    return len(loadText(path))"
   ],
   "outputs": [],
   "execution_count": 252
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T23:46:44.371952Z",
     "start_time": "2024-07-05T23:46:44.341636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "firstEntry  = errorPaths[0]\n",
    "\n",
    "for entry in errorPaths: \n",
    "    if entry != firstEntry: \n",
    "        print(entry)\n",
    "firstEntry"
   ],
   "id": "1e2c476f9e3a351a",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[253], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m firstEntry  \u001B[38;5;241m=\u001B[39m \u001B[43merrorPaths\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m entry \u001B[38;5;129;01min\u001B[39;00m errorPaths: \n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m entry \u001B[38;5;241m!=\u001B[39m firstEntry: \n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "execution_count": 253
  },
  {
   "cell_type": "code",
   "id": "9203a9532b428b04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T23:46:44.713802Z",
     "start_time": "2024-07-05T23:46:44.704687Z"
    }
   },
   "source": [
    "# numberPath = \"A:\\\\Lip Reading\\\\Potential Datasets\\\\BBC LRS2\\\\Numbers.txt\"\n",
    "# tensorPath = tf.convert_to_tensor(numberPath, dtype=tf.string)\n",
    "# path = bytes.decode(tensorPath.numpy())\n",
    "# fileName = path.split('\\\\')[-1].split('.')[0]\n",
    "# \n",
    "# # testing if the loadData, loadVideo, and loadText function all work\n",
    "# alignmentPath = os.path.join(rootDir2,f'{fileName}.txt')\n",
    "# loadText(alignmentPath)"
   ],
   "outputs": [],
   "execution_count": 254
  },
  {
   "cell_type": "code",
   "id": "1dc8265fa1dc4688",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T23:46:46.055084Z",
     "start_time": "2024-07-05T23:46:45.203741Z"
    }
   },
   "source": [
    "rawPath = \"A:\\\\Lip Reading\\\\Potential Datasets\\\\BBC LRS2\\\\allFiles\\\\5535415699068794046_00006.mp4\"\n",
    "\n",
    "tensorPath = tf.convert_to_tensor(rawPath, dtype=tf.string)\n",
    "path = bytes.decode(tensorPath.numpy())\n",
    "fileName = path.split('\\\\')[-1].split('.')[0]\n",
    "\n",
    "# testing if the loadData, loadVideo, and loadText function all work\n",
    "videoPath = os.path.join(rootDir,f'{fileName}.mp4')\n",
    "alignmentPath = os.path.join(rootDir,f'{fileName}.txt')\n",
    "\n",
    "loadVideo(videoPath)\n",
    "loadText(alignmentPath)\n",
    "\n",
    "frames, text = loadData(tensorPath)\n",
    "print(type(frames))\n",
    "print(frames)\n",
    "print(len(frames[0][0]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(\n",
      "[[[[ 0.9325923 ]\n",
      "   [ 0.97313976]\n",
      "   [ 1.0947822 ]\n",
      "   ...\n",
      "   [-1.8651845 ]\n",
      "   [-2.0273745 ]\n",
      "   [-2.1490169 ]]\n",
      "\n",
      "  [[ 0.8920448 ]\n",
      "   [ 0.97313976]\n",
      "   [ 1.0542347 ]\n",
      "   ...\n",
      "   [-1.8651845 ]\n",
      "   [-2.0273745 ]\n",
      "   [-2.1490169 ]]\n",
      "\n",
      "  [[ 0.8920448 ]\n",
      "   [ 0.9325923 ]\n",
      "   [ 0.97313976]\n",
      "   ...\n",
      "   [-1.905732  ]\n",
      "   [-2.0679219 ]\n",
      "   [-2.1490169 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.9325923 ]\n",
      "   [ 0.8109498 ]\n",
      "   [ 0.68930733]\n",
      "   ...\n",
      "   [-1.7029946 ]\n",
      "   [-1.7029946 ]\n",
      "   [-1.6624471 ]]\n",
      "\n",
      "  [[ 0.8514973 ]\n",
      "   [ 0.7704023 ]\n",
      "   [ 0.68930733]\n",
      "   ...\n",
      "   [-1.7029946 ]\n",
      "   [-1.6624471 ]\n",
      "   [-1.7029946 ]]\n",
      "\n",
      "  [[ 0.7298548 ]\n",
      "   [ 0.68930733]\n",
      "   [ 0.64875984]\n",
      "   ...\n",
      "   [-1.6218996 ]\n",
      "   [-1.6624471 ]\n",
      "   [-1.7029946 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.8514973 ]\n",
      "   [ 0.8920448 ]\n",
      "   [ 0.97313976]\n",
      "   ...\n",
      "   [-1.4191622 ]\n",
      "   [-1.6218996 ]\n",
      "   [-1.7435421 ]]\n",
      "\n",
      "  [[ 0.8514973 ]\n",
      "   [ 0.9325923 ]\n",
      "   [ 0.97313976]\n",
      "   ...\n",
      "   [-1.5002571 ]\n",
      "   [-1.6624471 ]\n",
      "   [-1.7840896 ]]\n",
      "\n",
      "  [[ 0.8920448 ]\n",
      "   [ 0.9325923 ]\n",
      "   [ 0.97313976]\n",
      "   ...\n",
      "   [-1.5408046 ]\n",
      "   [-1.7029946 ]\n",
      "   [-1.7840896 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.68930733]\n",
      "   [ 0.68930733]\n",
      "   [ 0.64875984]\n",
      "   ...\n",
      "   [-1.6624471 ]\n",
      "   [-1.6624471 ]\n",
      "   [-1.6624471 ]]\n",
      "\n",
      "  [[ 0.68930733]\n",
      "   [ 0.68930733]\n",
      "   [ 0.68930733]\n",
      "   ...\n",
      "   [-1.7029946 ]\n",
      "   [-1.7029946 ]\n",
      "   [-1.7029946 ]]\n",
      "\n",
      "  [[ 0.68930733]\n",
      "   [ 0.68930733]\n",
      "   [ 0.68930733]\n",
      "   ...\n",
      "   [-1.7029946 ]\n",
      "   [-1.7029946 ]\n",
      "   [-1.7435421 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.56766486]\n",
      "   [ 0.60821235]\n",
      "   [ 0.68930733]\n",
      "   ...\n",
      "   [-0.9325923 ]\n",
      "   [-1.1353297 ]\n",
      "   [-1.2569722 ]]\n",
      "\n",
      "  [[ 0.56766486]\n",
      "   [ 0.64875984]\n",
      "   [ 0.7298548 ]\n",
      "   ...\n",
      "   [-0.97313976]\n",
      "   [-1.2164247 ]\n",
      "   [-1.3380672 ]]\n",
      "\n",
      "  [[ 0.56766486]\n",
      "   [ 0.60821235]\n",
      "   [ 0.68930733]\n",
      "   ...\n",
      "   [-1.0947822 ]\n",
      "   [-1.2569722 ]\n",
      "   [-1.3786147 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.64875984]\n",
      "   [ 0.60821235]\n",
      "   [ 0.60821235]\n",
      "   ...\n",
      "   [-1.6624471 ]\n",
      "   [-1.6218996 ]\n",
      "   [-1.5813521 ]]\n",
      "\n",
      "  [[ 0.64875984]\n",
      "   [ 0.60821235]\n",
      "   [ 0.60821235]\n",
      "   ...\n",
      "   [-1.6218996 ]\n",
      "   [-1.6218996 ]\n",
      "   [-1.5813521 ]]\n",
      "\n",
      "  [[ 0.64875984]\n",
      "   [ 0.64875984]\n",
      "   [ 0.64875984]\n",
      "   ...\n",
      "   [-1.5408046 ]\n",
      "   [-1.5813521 ]\n",
      "   [-1.5813521 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-0.8920448 ]\n",
      "   [-0.8920448 ]\n",
      "   [-0.8514973 ]\n",
      "   ...\n",
      "   [-0.08109498]\n",
      "   [-0.12164247]\n",
      "   [-0.16218996]]\n",
      "\n",
      "  [[-0.8920448 ]\n",
      "   [-0.8514973 ]\n",
      "   [-0.8514973 ]\n",
      "   ...\n",
      "   [-0.08109498]\n",
      "   [-0.12164247]\n",
      "   [-0.16218996]]\n",
      "\n",
      "  [[-0.8109498 ]\n",
      "   [-0.8109498 ]\n",
      "   [-0.8109498 ]\n",
      "   ...\n",
      "   [-0.08109498]\n",
      "   [-0.12164247]\n",
      "   [-0.16218996]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.64875984]\n",
      "   [-0.64875984]\n",
      "   [-0.64875984]\n",
      "   ...\n",
      "   [-0.32437992]\n",
      "   [-0.32437992]\n",
      "   [-0.28383243]]\n",
      "\n",
      "  [[-0.68930733]\n",
      "   [-0.68930733]\n",
      "   [-0.68930733]\n",
      "   ...\n",
      "   [-0.32437992]\n",
      "   [-0.32437992]\n",
      "   [-0.32437992]]\n",
      "\n",
      "  [[-0.68930733]\n",
      "   [-0.68930733]\n",
      "   [-0.64875984]\n",
      "   ...\n",
      "   [-0.24328494]\n",
      "   [-0.28383243]\n",
      "   [-0.32437992]]]\n",
      "\n",
      "\n",
      " [[[-0.8514973 ]\n",
      "   [-0.8514973 ]\n",
      "   [-0.8109498 ]\n",
      "   ...\n",
      "   [ 0.04054749]\n",
      "   [-0.04054749]\n",
      "   [-0.08109498]]\n",
      "\n",
      "  [[-0.8920448 ]\n",
      "   [-0.8514973 ]\n",
      "   [-0.8109498 ]\n",
      "   ...\n",
      "   [ 0.04054749]\n",
      "   [-0.04054749]\n",
      "   [-0.08109498]]\n",
      "\n",
      "  [[-0.8514973 ]\n",
      "   [-0.8109498 ]\n",
      "   [-0.8109498 ]\n",
      "   ...\n",
      "   [ 0.04054749]\n",
      "   [-0.04054749]\n",
      "   [-0.04054749]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.68930733]\n",
      "   [-0.64875984]\n",
      "   [-0.60821235]\n",
      "   ...\n",
      "   [-0.3649274 ]\n",
      "   [-0.3649274 ]\n",
      "   [-0.3649274 ]]\n",
      "\n",
      "  [[-0.64875984]\n",
      "   [-0.64875984]\n",
      "   [-0.60821235]\n",
      "   ...\n",
      "   [-0.3649274 ]\n",
      "   [-0.3649274 ]\n",
      "   [-0.4054749 ]]\n",
      "\n",
      "  [[-0.60821235]\n",
      "   [-0.60821235]\n",
      "   [-0.56766486]\n",
      "   ...\n",
      "   [-0.3649274 ]\n",
      "   [-0.3649274 ]\n",
      "   [-0.3649274 ]]]\n",
      "\n",
      "\n",
      " [[[-0.97313976]\n",
      "   [-0.97313976]\n",
      "   [-0.9325923 ]\n",
      "   ...\n",
      "   [-0.04054749]\n",
      "   [-0.12164247]\n",
      "   [-0.16218996]]\n",
      "\n",
      "  [[-1.0136873 ]\n",
      "   [-0.97313976]\n",
      "   [-0.97313976]\n",
      "   ...\n",
      "   [-0.12164247]\n",
      "   [-0.16218996]\n",
      "   [-0.20273745]]\n",
      "\n",
      "  [[-0.9325923 ]\n",
      "   [-0.9325923 ]\n",
      "   [-0.9325923 ]\n",
      "   ...\n",
      "   [-0.20273745]\n",
      "   [-0.24328494]\n",
      "   [-0.24328494]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.7298548 ]\n",
      "   [-0.68930733]\n",
      "   [-0.64875984]\n",
      "   ...\n",
      "   [-0.3649274 ]\n",
      "   [-0.3649274 ]\n",
      "   [-0.4054749 ]]\n",
      "\n",
      "  [[-0.8109498 ]\n",
      "   [-0.7704023 ]\n",
      "   [-0.64875984]\n",
      "   ...\n",
      "   [-0.4054749 ]\n",
      "   [-0.4054749 ]\n",
      "   [-0.4054749 ]]\n",
      "\n",
      "  [[-0.8920448 ]\n",
      "   [-0.8109498 ]\n",
      "   [-0.64875984]\n",
      "   ...\n",
      "   [-0.4054749 ]\n",
      "   [-0.4054749 ]\n",
      "   [-0.4054749 ]]]], shape=(68, 40, 120, 1), dtype=float32)\n",
      "120\n"
     ]
    }
   ],
   "execution_count": 255
  },
  {
   "cell_type": "markdown",
   "id": "b323b3673a461c65",
   "metadata": {},
   "source": [
    "## reading data"
   ]
  },
  {
   "cell_type": "code",
   "id": "15d040463f02dc61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:13.564312Z",
     "start_time": "2024-07-04T05:58:13.457703Z"
    }
   },
   "source": [
    "# reading all files within the root directory\n",
    "# data = tf.data.Dataset.list_files('A:\\Lip Reading\\Potential Datasets\\BBC LRS2\\mvlrs_v1\\main\\*\\*.mp4')\n",
    "data = tf.data.Dataset.list_files('A:/Lip Reading/Potential Datasets/BBC LRS2/trainFiles1/*.mp4')\n",
    "# data = tf.data.Dataset.list_files('A:/Lip Reading/Potential Datasets/BBC LRS2/trainFiles6/*.mp4')\n",
    "\n",
    "global maxCharCt\n",
    "\n",
    "data = data.shuffle(500, reshuffle_each_iteration=False) # shuffling data\n",
    "data = data.map(processData) # \"processing\" the data to obtain frames and the respective text \n",
    "\n",
    "dim1 = newImageSize[0]\n",
    "dim2 = newImageSize[1]\n",
    "print(\"dataset size before padding:\", len(data))\n",
    "print(\"data shape of example frame:\", newImageSize)\n",
    "print(\"data shape of example video:\", frames.shape)\n",
    "print(\"dims: \",dim1, \"x\",dim2)\n",
    "\n",
    "# combining 8 videos as one \"input\"\n",
    "# ensuring all videos are padded to match the longest video, \n",
    "# ensuring the length of all the alignments is the size of the longest text characters, as some are lower. \n",
    "batchSize = 4\n",
    "data = data.padded_batch(batchSize, padded_shapes=([maxFrameCt,None, None,None], [maxCharCt])) \n",
    "print(\"autotune: \",tf.data.AUTOTUNE)\n",
    "data = data.prefetch(tf.data.AUTOTUNE)\n",
    "# data=data.prefetch(3)\n",
    "print(\"data length after padding:\", len(data))\n",
    "print(\"batch size:\", batchSize)\n",
    "\n",
    "train = data.take(int(len(data) * 0.6))\n",
    "test = data.skip(int(len(data) * 0.6))\n",
    "print(\"train data size:\", len(train))\n",
    "print(\"test data size:\",  len(test))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size before padding: 1139\n",
      "data shape of example frame: (40, 120)\n",
      "data shape of example video: (68, 40, 120, 1)\n",
      "dims:  40 x 120\n",
      "autotune:  -1\n",
      "data length after padding: 285\n",
      "batch size: 4\n",
      "train data size: 171\n",
      "test data size: 114\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "b98206929338ffa0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:14.097067Z",
     "start_time": "2024-07-04T05:58:14.077522Z"
    }
   },
   "source": [
    "data"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 290, None, None, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, 145), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:14.519011Z",
     "start_time": "2024-07-04T05:58:14.510399Z"
    }
   },
   "cell_type": "code",
   "source": "print(set(errorPaths))",
   "id": "83cd97bc3fe5774f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "771515f5cef4617f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:17.387235Z",
     "start_time": "2024-07-04T05:58:14.859061Z"
    }
   },
   "source": [
    "val = data.as_numpy_iterator().next()\n",
    "plt.imshow(val[0][0][2], cmap='gray_r')\n",
    "print(len(val[0][0]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAADUCAYAAAA87UGPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAv2klEQVR4nO2dfWxX1RnHn/LWF6CVF2mpFKiu+MZ0CoyIRHAbLOjcDMvidCpu/4iIg5EMRZbYGaTEPwhbMtk0BkgcwSyi08UR6lTUEKfyoggbztnJa1dRoIWWVtqzP0x/6f3ew+855977u/2VfT9J/zi/e+655zz33HtP7/O9z1NgjDFCCCGEEJIS/Xq7A4QQQgj5/4KLD0IIIYSkChcfhBBCCEkVLj4IIYQQkipcfBBCCCEkVbj4IIQQQkiqcPFBCCGEkFTh4oMQQgghqcLFByGEEEJShYsPQgghhKRKzhYfTzzxhFRXV0tRUZFMmjRJ3nzzzVwdihBCCCF9iAG5aPTZZ5+VxYsXyxNPPCHXX3+9/OEPf5A5c+bIvn37ZOzYsVn37erqkiNHjsjQoUOloKAgF90jhBBCSMIYY6SlpUUqKyulX7/s7zYKcpFYburUqXLttdfK2rVrM79dfvnlcuutt0pdXV3WfQ8dOiRVVVVJd4kQQgghKXDw4EEZM2ZM1jqJv/no6OiQHTt2yEMPPRT4ffbs2bJ9+/ZQ/fb2dmlvb8+Uu9dCL730kgwePDjwWzdffvll6JhIZ2dnoNzV1RUoY5tYxvqItr+IxH5zg/v379/f+5iDBg3KWsY233333UAZ3WX79+8PlIcOHRrqw5AhQwLl0tLSQPmCCy4IlEeOHJm1PGrUqEB5+PDhoWP2nEMiIkePHg2U//nPfwbK7733XqDc0NAQKJ86dSpQRrsWFhaG+lBUVBQoo60RbAPtUlNTEyhfcskloTbwTSLaDvuEaNcFzg/bnMZ98NrT6mvYrkXfNnyvRZfrG/uFcxDLZ8+ezdon/E/R1mes032P7AavPdyOc66kpCRr+3ivFQmPA+ucOXMmUG5ra8u6XZuDIuF7PM4xbQ7iPEZc7v/YplbWniEu404b2/lGstnqzJkzUldXZ30uIIkvPo4dOyadnZ1SXl4e+L28vFwaGxtD9evq6uTXv/516PfBgwdnLiQcLE7EgQMHhvb3XXzg9nxcfAwYEDxdtj7izcN38YEPK7Qttm+7qLGf2Ab2AW+I2Ifi4uJAGW+Ytn5oCwGXh2q27bb62sME0WyJdrMteDTb4HakNxYf2rXlUj8fFx9oKzy/uVh84PnGxQaW8brIxeJDswOWXR7CeE/R7u9cfLihXe8u+9jG6XK95UTzYTu4McbaoWXLlsmSJUsy5ebmZqmqqhJjTGaQvjcr2z6+EwNxuRkh2k1YQ5sILhMFwXHjAw3fKuB/0ngTcOmDr+21hzb+5yTy1aK3J/gm4/33389aX1vxY5/QDiLhxQLW0R4u+B/iJ598EiifOHEidMx///vfgXJFRUWgjOcPzy++lcL/nLFse5uDcyDu4kN702k7Rtw3nb7t237Df4rwIe17z7FdB9gGzhncjn3C841zVFuku6CdC+3e7HLfxDmB+7gs5HqC88Hl4em7qEJcFh++/xRraPPedr7RttkWzdq9uyeJLz5Gjhwp/fv3D73laGpqCr0NEfnq4Wf7j44QQggh5yeJf2o7aNAgmTRpktTX1wd+r6+vl2nTpiV9OEIIIYT0MXLidlmyZIncddddMnnyZLnuuuvkySeflAMHDsj8+fNzcThCCCGE9CFysvi47bbb5PPPP5dHH31Ujh49KhMnTpSXX35Zxo0b59xGV1eXs2YiCUGatn8aYiDfL3Bs49ZEqZpNUaCGX2AgqOgX0cWfmi2xz6jxQL2GSFjjsW/fvkD5yJEjgTJ+zYKgHTX9hg3fOYPnBvto0z6cPn06axl1IqgJufDCCwNltL0mWBYJn188/9hvX82HzQ+t+fy1ryN8NSMumg/EV4CMuNzXtHHbrs9soCbEJlhGbRP201fcq2llRPR7oe89BYlyrjRRq2YHF42I1obvtaRhG7dm+5599Dn3OROcLliwQBYsWJCr5gkhhBDSR2FuF0IIIYSkChcfhBBCCEmVnLldconLt865CCqUb9h8o76BrXCcGHRo2LBhgbIWm0Ik7AtFvQTqSrCNlpaWQFmLXioSjomBGg/UjWj+ei2+gW0O4vnQYg34+nNdjom2am1tDZSPHz8eKGtxW7RAWSJhW+Kn85odNN+3LaYKos1rTZfg658X8Z9DvnF/XOI+aH3SjqnFIrHZBa9fX42Xdv5tcXy0a0vTW/hqRlzOlTZvtYjULs8x33nti+91IBIeV88++MSF4ZsPQgghhKQKFx+EEEIISRUuPgghhBCSKlx8EEIIISRV+qTgVEvoI+IfsEsD67sEoUkiqJBvH3yD6aCwCsVkmJgMUyXbMhWj6BFFSHiML774IlDWAkTZgoxhGyha0+ZMXIGySPwkUFrQItv51oKAaeNEW2NgM+xTc3NzqA8YiErLpKqVkSjJzXAfF9FqNnKRSFJLCx9FTKjdc1DcHSX5JfYTzz/aHudklMBZmq18r1+tPRd8nwlREmomkQE6Gy5208S7URPL8c0HIYQQQlKFiw9CCCGEpAoXH4QQQghJlbzVfBQUFGR8TX0h4JcNXz+k5i9z8XNqvm1sAxN0ob8WE00NHz48UMZgXiJhzQf6fFFXgONGvzT2EZOliYQDk+E4tWBa2EffpGE2MDASJuTCNjS9Bu4vEh4H1sHzh3oMPCbaWkvAJxK27ZAhQwJlDFSHfcLAdtgn27iRuInDtIBQtqR+Gr6By6LoL3yDbWkJ9DTNj0h4XuP51TQgWnu2+yC2ETeAlxYgzOX6jvtccjn/mo7MN3ha3GSHNnoe00dzwjcfhBBCCEkVLj4IIYQQkipcfBBCCCEkVfJW85E0vvoLX9+Yb/tRiPJNtubbRLA++m/Ly8sD5f3794faQL+xljgO/bfoX8cy7i8SjuuB8Ss0nzGiJXSyEXeOIah1sPUZ9RGonygrKwuUMU4LHgPthrbH7Tawjpb8DvuIielscUB8EygieB1oWogkYjBoPn6Xe46mTfC9vnFe43Vk07rgbzgOPJ+oAdKuRZtuDedp0nGbouyjJZLT5qB2/m1tRNEF5St880EIIYSQVOHigxBCCCGpwsUHIYQQQlIlbzUfZ8+eDfmKu9H8szayxaO3tan5FKNoAuIS5Vt033gVmv+1srIyUEZ/rkg49wpqPlpbW7MeA3UmqCHA9kTCttHieiDox8a5p+UKsoF9iKsLso0B9RGo6UD/O2pCcBzatYV6DRFdo4PXim8cD5ut0ba+mizf+AguJK35ccE3joN2r3TRLeAcOHnyZKCMcwivX5yTiEucD9/8ML4xlGz3TW1OuLThSxRtStLk6tnGNx+EEEIISRUuPgghhBCSKlx8EEIIISRV8lbzkTRx/aua7zSJGPmI5qfOhc8YQf3FmDFjAmWb/xb98ZoPWMubgT5m1IzYjoG6Aixr+6OPOYquCHUjmj89io9Y0+hgv7FP2rnRYnSIhDU4WEZNB84pLR+RzfZarAgtj442713qa7qvuLox27hxH03jEVcD4gLOGZd8QD3B82/T+sXV5PjGdYlC3FgjSWgrcnF+cwXffBBCCCEkVbj4IIQQQkiqcPFBCCGEkFTpE5qPXPitfH1jWpwQG75+Zs0n7KLx8P3WHNvUtA+Y28Wm+cDYE+gD1jQf2CcXjYivrXC7pjvA+ueKQZOtTSyjDgXthmXbmNA2mPcGtQ/YJp5v1GtoeXrO9VtPcI5oMXVwu4uttevTN04EYquvabB89RZJaLjSyEml9RuvT5wfuD/m7rHFs9E0Gr56myhxexDf+7m2v8tzzjdfjBbfyAXf55grfPNBCCGEkFTh4oMQQgghqeK9+HjjjTfklltukcrKSikoKJAXXnghsN0YI7W1tVJZWSnFxcUyc+ZM2bt3b1L9JYQQQkgfx1vzcfr0abn66qvlpz/9qfzwhz8MbX/88cdl9erVsn79epkwYYKsWLFCZs2aJfv37w/lnchGV1dXxgcWxTeWDyQdE9/Fn+trG/QJan7s0tLSrGWRsA9Xy/2AsSOi6Cu0GBqarxS3a7lDbL5y1Fdo8S0wLw7qMdCONnDcaMvjx48HylpMBSyjpgTLIsnHuHFpT7snaLoEX42Qy7Wmxe1IIteHL1HG1RPb/UTTS2jjts2hnrjoFLRjou7E9xliO1faHPON6xLlOear6fHVnUStEwXvxcecOXNkzpw51m3GGFmzZo0sX75c5s6dKyIiGzZskPLyctm4caPce++98XpLCCGEkD5Pov+yNDQ0SGNjo8yePTvzW2FhocyYMUO2b99u3ae9vV2am5sDf4QQQgg5f0l08dHY2Cgi4c8xy8vLM9uQuro6KSsry/xVVVUl2SVCCCGE5Bk5+drF9l3wuXyPy5Ytk5MnT2b+Dh48mIsuEUIIISRPSDTIWEVFhYh89QZk9OjRmd+bmppCb0O6KSwsDAntRL5asHQLXXKRgEdDE2r1Rh+iCPs0wZEmgkLxFwbGGj58eKhNFBYfO3YsUEYxmBZUSgvOJeIfVEpLfqeN2ya0RQEpBtfSBKdasCVbcDW0lZakD8V+OG6tbLsutKRuJSUlgTJe73gutGBdNvB6xHHGTUTnIg7U6mjBmlzuKb73BE3kmoQIUrtn+AovXUSu2j1DC2QX5ZkSVzCsCedz8UzJRaK5bLbzGUOibz6qq6uloqJC6uvrM791dHTItm3bZNq0aUkeihBCCCF9FO83H6dOnZKPP/44U25oaJDdu3fL8OHDZezYsbJ48WJZuXKl1NTUSE1NjaxcuVJKSkrkjjvuSLTjhBBCCOmbeC8+3nvvPbnxxhsz5SVLloiIyLx582T9+vWydOlSaWtrkwULFsjx48dl6tSpsnXrVq8YH4QQQgg5f/FefMycOTOrX6egoEBqa2ultrY2Tr+ks7PT2cdm649vABhfchHoTPNTIrZgPHETLmlg/WHDhoXqoB5CO4+YeAr92qgZsAXfwn00Hz/WR58/+koHDx4cKF900UWhPnRrnrq54IILAmUtkRxud/Gfakm80M+M28+cORMoo1bCJbkd9hu1LaNGjQqU0S6a7W1J/zRftqYB8A0y5nIusE1NP4N9dtHXaNoULQmjFnwPbW27x2jj1O5BUYKxYfA87Zga2jFtfcA5FTeQYZQxxB1nlGR4PnoZH10Mc7sQQgghJFW4+CCEEEJIqnDxQQghhJBUSTTOR67Q/LEu2gckbjIsl9gDiO933Jpf2mUMvt+ma/XR1iNGjAjVQc0Hjru1tdXrGKjxsMWFQV0IllGHgH1AXznWHzduXKA8fvz4UB9sMU96gn5rPCb2Ce2AYxIJ2wZjh+CcOX36dKCMmg/UFKCew9YHFJNr8U6wzSj6LKyD49C0L9q1lAv/u6Z1sGlbfNESLGr18dy43Fs17QqC14FLIjktdgjiG9fDJdZIXLQ2Xea5hq+mz0Vv42MLn7p880EIIYSQVOHigxBCCCGpwsUHIYQQQlIlbzUfXV1dzv4jm59Ky3ERJa+CL7mOJYKagVwcQ7OTLccJxnFAXQL637GM49L0GCJhncGFF16YdTuCOhIcV3V1daCMsStEwnoInJeop9D82KdOnQqUbXMU5znqRrRYAjhu1G/guUT9hkjYtjhOPAbqELSYHC7XEdreN4cN4pIzR/OXa/cgxEXDpcWr0bQr2OcoOWx88wFpMVZcdCa+cVhcYqZk29/FDr66QS3ORxSSyFnTExfbZ2vTxyZ880EIIYSQVOHigxBCCCGpwsUHIYQQQlIlbzUf2XDRa+RCw9GTXHwH7ht33+Zfi5ujQhsXtm/TAKDeAutgTAZEO7+2cWt5UlCXUFlZGSiXl5cHyhizA8s23QnaDmNNoA7BN7+M7dygjxb7hRoOTU+DfcA4LjaNDx4T+4TnW8uRgWCfbPvg+cZcPL4+fU0z4rIPljG+haZ1cclZhbjEzMh2DJf7mqZV0trUND0u+WQQLU6HprfQzoWtjbh5sXLxDEFykbMoGz7zj28+CCGEEJIqXHwQQgghJFW4+CCEEEJIquSt5sMYk/FHRcn9kDRpHAOJkj8m6Ta1caNvXURk5MiRgfKwYcMC5RMnTgTKWrwS7DP690X0XB94DMyjgWXc/+OPPw6U0X9v+w01HydPngyUUadi05H0xOZ7xX5jG1oZzx/6bDHOB2pIRMKaDMwf8/nnnwfKWtwWrY8i4Tngm/dIu6e4aDw0bYumAcEyxgVBHYKtX5p+xjcWhYsuQdNo4Lji5mER8R+Hdj6j3M+1mChaH5PQIcZtI8r+Ps8Mn7p880EIIYSQVOHigxBCCCGpwsUHIYQQQlKFiw9CCCGEpEreCk57JpbTBEku4qG4wbV82xPxS8hjqx8FLXGUVl/bjnbChF4i4aBiFRUVgfLhw4cDZRSoaUHGbGJALXAZisEOHDgQKB86dChQbm5uDpSPHTum9gFtg2LAlpaWQBlFkyjm1MSgImFxJgpEMTkdin8x+Br2ySbuRdC2KDDF841CXJxD2EdbgjYMdqb1E22HIlnfa9XWJpaxT5qI1SX5nVZHC+iFaIGzbKJXPB94PlEErQVsc7G9Jsb1FZRq230Fri5tRiHucyvXwTbjwDcfhBBCCEkVLj4IIYQQkipcfBBCCCEkVfJW85EtyFgUNL+i5uNzCTqE9EZyOxxH3D5otrfZRUvitm/fvkAZ9RrYZ/T32vQd2A8tqduRI0cCZQwA9sUXX2Td3xb4CjUbqAHAPqFtP/vss0AZ9RzoSxfRE6phm6gJwXOFZUyoh9tFwnMOtS1Y1gK+oWYEk9uJhG2NuhG0XVFRUaCMAd5syes08J6iJYbD+jg/sI+2862haUK0+5zLtYbzGMeBwfZwHLYAfT2x3VO0gGxY9tW+IbkI8Ihoge6iELcN27h99C9edZ1rEkIIIYQkABcfhBBCCEkVLj4IIYQQkip5q/no7OzMfMutxX1wIenvoXPxTXfcJFAiudd4ILakcKhDQM0H+usxFoXmz0Wf87n60RP0XWMcj9bW1qzHRF+ozReOtkfdgRZTAfuAZVssC/Snoy2xn01NTYGyFmMD9ReolbD1QYvbovnTtTGIhLUnqJfQ4pX4lm0xVrRx4PnW4oJoY3BpQ0s0iPWxjzjvbeNGtPuzFpcpSnwTTeOhJX3zPXe2YyKarZJ4ZiT93PFNyJgkfPNBCCGEkFTh4oMQQgghqeK1+Kirq5MpU6bI0KFDZdSoUXLrrbfK/v37A3WMMVJbWyuVlZVSXFwsM2fOlL179ybaaUIIIYT0Xbw0H9u2bZP7779fpkyZImfPnpXly5fL7NmzZd++fZn4Ao8//risXr1a1q9fLxMmTJAVK1bIrFmzZP/+/SFffzZ65nZxqUu+QvN1atsRTUNi88+irxpjS2DcBtQVaJoBm75Di29y+vTprG1grgiM+4CxCWy6Ey3OA+oltFwgGB/DZmstNgT2G8ep2RrHadN8oK2wn5p+QtNbuMRc0HQEOE7f3B+2OCA4Dl9dWZT7VtzYIVpcF9zfJb4R9kHTEWj1bfccLZeLbw4b3+024j53tHuzSPKxonzPTS7xWnxs2bIlUF63bp2MGjVKduzYITfccIMYY2TNmjWyfPlymTt3roiIbNiwQcrLy2Xjxo1y7733JtdzQgghhPRJYmk+uqNCdkdBbGhokMbGRpk9e3amTmFhocyYMUO2b99ubaO9vV2am5sDf4QQQgg5f4m8+DDGyJIlS2T69OkyceJEERFpbGwUEZHy8vJA3fLy8sw2pK6uTsrKyjJ/VVVVUbtECCGEkD5A5DgfCxculA8++EDeeuut0DabD+9cvqRly5bJkiVLMuXm5ubQAsTFJ+hL3DZc/HUudXri8k19T6L45zQfH26P4kv11XygjgDjPGj+e9sxXfrZE5wP6GN20SGgLsD3/GAf0V9vQ/P5a3EftNgSOGfRLiL6tYTb8RilpaWBMuoQcLtIOIcNtonj1q4ttCOO2xZrBNFyEuG8xbKLvkK7fnEOoh1wO16bOD9sWhccl6bHQFtqdrDNMWxDi1eC9X3jWdi2+x7TFxfdifYs9H3GuNgl6RhZ3URafDzwwAPy4osvyhtvvCFjxozJ/F5RUSEiX70BGT16dOb3pqam0NuQbgoLC60iNkIIIYScn3i5XYwxsnDhQtm8ebO8+uqrUl1dHdheXV0tFRUVUl9fn/mto6NDtm3bJtOmTUumx4QQQgjp03i9+bj//vtl48aN8uc//1mGDh2a0XGUlZVJcXGxFBQUyOLFi2XlypVSU1MjNTU1snLlSikpKZE77rgjJwMghBBCSN/Ca/Gxdu1aERGZOXNm4Pd169bJPffcIyIiS5culba2NlmwYIEcP35cpk6dKlu3bvWK8ZELkv5eGnHx1/WGjzCuvy4JXQm61caPHx8oNzQ0BMonTpwIlF3OneYvx+02v3K2Y2o5NUTC/nUtfoXNn94TF3ekphPBMvr0NQ0Ito9jtP2GZRwHajrKysoCZbxXYH1bm3hM7VrTfOWabsFWB+eUpo3AGCxIFN0BHkPTBCHYJ5uWSrOlZhdfjYgL2jiTyFkSN2ZSEsR9ZqCd8LpJM2aW1+LD5SFQUFAgtbW1UltbG7VPhBBCCDmPYW4XQgghhKQKFx+EEEIISZXIcT76GmnGrHdF878m4X/z1br4HtOlPvqNMY7LyJEjA+UjR44Eyug7T8IuaHvNV47YtqPPV9N4oL4CdQwuegusk7QGBMdgiz2C/cY6aCs8Bsbx0PogYrdFT7TcH5pOwUWHoGk8NF2JpkuwaQh872PaODF+CbbvEtdFG6fv9lzr82xE0WvE1fClMU5tXL2ZF41vPgghhBCSKlx8EEIIISRVuPgghBBCSKpw8UEIIYSQVMlbwWlXV1dGDJNG8JZckOugYi7taQK1uKIn2/5asqvuHEDdXHjhhYFySUlJoHz69OlAOYn5oAXbiYIWiAztgEJNHDcKLzGZmkhY3KklEtNEsL5ByETC/daS/GnHdBFeIr7XliYwdRGcasfUAl9pQeZcRM1an3zFni7J7XyTmfni0l7S99Z8IIkxaIkHfff3xSc5at98qhNCCCGkz8LFByGEEEJShYsPQgghhKRK3mo++vXr5+x/yoVPOBf4+tN6Q+vie0ybXTXfNmoEUPNxwQUXBMqtra1efbIRN6Cb5isX8dcRoK3RTqjxGDFiROiYw4cPD5QxKZuW9A3togUhcwkypvmZcdzYB81utt/iagCSCEKo+duT0F/4arR8E8u55u/qiW8Sv1xoRrT7VlwthEjYdpqtkhhXruexi118dBzUfBBCCCEkb+HigxBCCCGpwsUHIYQQQlLlvNB8uPgpe0M/ofl8fYny/bvWRlxft83Hp/UBtQ2o+cDy4cOHvfulxWnQYklE8cfjPpiUC23V0dGRtewyX1DDgZqPIUOGBMoYgwP7hO2h7gT1HSJh2+E48BjanEO72WyNSdw0DYimM7ElUNPwvXa0Prrgoj3qia8+IxcxNrRjRLl/a+NC4ibkE9HvnfmYKNTXTmmSPz0hhBBCyP8FXHwQQgghJFW4+CCEEEJIquSt5uP/Ed/4CFFIw+en+Rlxe3l5eaCMuV9cvh1Hf6qWo8I3l4umjYjSJ9RGtLW1BcrNzc1Z9xcJax/a29sDZdSAaHE7UOPhoglADQ/2CfGJBXCu+pptUcMRV3dguzZ9/e++157LMTU75CJ3k3ZMbZ5jORf43oNcYo/4al208+2SRweJG8dD0z5FabMnPvdVvvkghBBCSKpw8UEIIYSQVOHigxBCCCGpcl5oPlz8YEnkbohL3D7kwxgQm//P17+K+UkqKysDZYxVcerUqdAxfeM0aDE4sIzxMWznAset+ZFRn4Hg/qgJsf2GtkGNB44DNR9oa8wng3l3bMdAvy8eQ7O1ix4DdSVYTiK2hIZvXAffnCYueguso+kMtLxLLjFZ8Jh4LaGmA88N7h/l/q1pF3rjXumrx3HRU8Wdp77HjKIBydZeNvjmgxBCCCGpwsUHIYQQQlKFiw9CCCGEpEreaj66uroy/qMo/rt81Ef4+jrzKQ5/N5qew1YHQR9wWVlZoIyaD4wDcubMmVCbWu6WKHlTehIlRwL6WzXti6ZjQP+8SHhcaAfUhGBuFtRj2GzbE5u2Rsv/0traGiijJiSKn1nzr/tuj3Itav5tHBceE7dr/nkbvv3WtBGabsnWT23eJpHTxhffHFdpkMYzKW4uH5vdfOaYz7nNv6cbIYQQQs5ruPgghBBCSKp4LT7Wrl0rV111lZSWlkppaalcd9118te//jWz3RgjtbW1UllZKcXFxTJz5kzZu3dv4p0mhBBCSN/FS/MxZswYWbVqlXzta18TEZENGzbID37wA9m1a5dceeWV8vjjj8vq1atl/fr1MmHCBFmxYoXMmjVL9u/fH8ox4UMaeRfywR+XBFqbcfvg4ivV6qB2AedGVVVVoHzppZcGykeOHAm1qcXM0HQFWuyJKGiaDi02CW7HeBoi4bgdeAzUV2B9RPMR2/K2oO1xH9Sl5CJGQ9J6Kk2PYUM7pu92l2tTO1+aXXz3F9FzufjGM4lyH8RxaNevdv5cckNp2pVcxJZJOpeL7/PBpY2e+/j01+us33LLLXLTTTfJhAkTZMKECfLYY4/JkCFD5O233xZjjKxZs0aWL18uc+fOlYkTJ8qGDRuktbVVNm7c6HMYQgghhJzHRP7Xu7OzUzZt2iSnT5+W6667ThoaGqSxsVFmz56dqVNYWCgzZsyQ7du3n7Od9vZ2aW5uDvwRQggh5PzFe/GxZ88eGTJkiBQWFsr8+fPl+eeflyuuuEIaGxtFJPxZZHl5eWabjbq6OikrK8v84St3QgghhJxfeC8+Lr30Utm9e7e8/fbbct9998m8efNk3759me22WAbZ/EDLli2TkydPZv4OHjzo2yVCCCGE9CG8g4wNGjQoIzidPHmyvPvuu/Kb3/xGHnzwQRERaWxslNGjR2fqNzU1hd6G9KSwsDAUlEjkK1FLkoJMTewTJdlRXFwCvGSrj2JCEV1Qpgm1fEVRNgEi9hMFppi8bNiwYYEyjmvKlCmB8s6dO0PHxIRqmsBME6hFEf9pQjvfwEY4Btv5xjoYJAz7rQlQtSBTNrtqwlmcIy6B6uKiBTKLK1AU8Z8jviJY23zBfvreM3wFpi7CS9/gaFp9l2sN7YDnG9vQ+oxz2DYG33Fq99IogmJEm4O+z9Ao12KvBRkzxkh7e7tUV1dLRUWF1NfXZ7Z1dHTItm3bZNq0aXEPQwghhJDzBK83Hw8//LDMmTNHqqqqpKWlRTZt2iSvv/66bNmyRQoKCmTx4sWycuVKqampkZqaGlm5cqWUlJTIHXfckav+E0IIIaSP4bX4+O9//yt33XWXHD16VMrKyuSqq66SLVu2yKxZs0REZOnSpdLW1iYLFiyQ48ePy9SpU2Xr1q2xYnwQQggh5PzCa/Hx9NNPZ91eUFAgtbW1UltbG6dP3rjoFHwD3yQRZAqJ69tOQnfgO64oya5Q44GJx1DzgWUMpnXFFVcEyrYvoo4fPx4oYzIzTeuShO5A85drZcRFd4C+akwUh+PEJH6YeA71GadPnw6UbfosPF/YB01ngvPF5VxoGi08pqYB8Q2+ZmtDu9aS0Lpo17fWpq8ewyXImG8SP8RFp+CrTYmbeLA3Es+5JHXTngHaHPMNrueLz/7M7UIIIYSQVOHigxBCCCGpwsUHIYQQQlLFO85HPhLFd5oLn39c4sYJcGnDV5eA9V18eqgBQE2HFlsCNQPjx48PlMeOHRs6Jgan0xLN+cYBSQIttgDaGrfbUg+gXkKLf4BxQFAbg8fAc4XnRiSsA0GNT2lpaaCM8wH318YkEr4WcB/02fsm8bMFS0Q0jUfcOeRyTBeNhk/9JJKh+cYe8d1uq+Orr9K0bFHGraHdv3Nhay2JI9Kn4nwQQgghhPjAxQchhBBCUoWLD0IIIYSkSt5qPrq6us7p+0vi+/h80HhoRMkvoqHlUdD8jlq8BBEJBZXT4nhovnLUDFxyySWhY3700UeBcrZMyi5EiQuCMTKwjlb2zT8kEvZd++YwQU2HpseJkvNCy5uh+aVtOW18x4lgH7RzZ+sDop2/uHlZbMeImy9I04DZ2tfmhG/OEzymy71Z02xpuV2ixPHwfWYkUd83V4vvfcvlmZILrYoI33wQQgghJGW4+CCEEEJIqnDxQQghhJBU6ROaD02X4OJb0/ztuSCuvy4JfL9n13yCGE8B9RsiIiUlJVnroK5Ay8OB5csvvzx0zPfffz9Q/sc//hEo++oOouRI8D1/6I/VzoWL/13TdOD50/KuaDE4bL9pc8T3/NuO6Xtt+eYG0eKG2H7TYk8kEVvIRYOTDW3cWjwUl2NqGgA8hu+5FPGPb+KrS0kiplIa+WG0fmr3rd7UPvLNByGEEEJShYsPQgghhKQKFx+EEEIISZW81XwYYzJ+PM13FuVbZd9vk6P4xnx9frnwIWq+TvRDo68b/fOYtwNjeojoPn5NI6DFaKiurg79hvlfysrKAuXPPvssa5tIEvkncI5psQe02BI2f7ymE9FiS2h9RP0OnkuXY2ixYbQ5aIuxETfmTRI+f7QdxgrBPmqxRBCX+CYaScxjxFdfoe2fhDYiSqwQX3znnO/9PIk4Tr7atd6Ebz4IIYQQkipcfBBCCCEkVbj4IIQQQkiqcPFBCCGEkFTJW8FptsRyiIt41DehTlyBqm0f3yBSSQhQfZNdocgNg0yhABGTxomIFBUVBcqaCFITLOI4KyoqQsccO3ZsoDxq1KhA+ejRo6F9eqKJO9vb2wNlm3ALRW8oMPRN2ucizPMNIuQbbEmbDyJhgagm/vNNsOYS0C1ukKko15qvLXMhnPdNoOZra5c5p4mWteBrLsktXQLuZWszH4WXuRCYpjGubPcln+ck33wQQgghJFW4+CCEEEJIqnDxQQghhJBUyVvNR2dnZ8g3eC6iaD60fdIIUuOrAdGSQtnqIFqQIvTfo34DA4jZEsvZEoH1JG5QIdsxKysrA2XUgOzevTtrm1pCLbS1y9zU6tgCdmXDdu6wjbh6Ck1T4BLwSwsapml+cH7Yzg32Q5tTqL/BMtoxSrIzrY5L0Lie2K5lTQfke21pyQ1t4DHi6uNc+uyrj/C9D7qcb1/bJhFEzFfTkYSOBNHmXM/t1HwQQgghJG/h4oMQQgghqcLFByGEEEJSJW81Hz0Ty2lE0RBo35onga8vVPO/uvjCtT5gWdN4aGWbDkGLV4FoPmRNIyAiUl5eHiij5gPjk3R0dATKaEvsE2oEXJK8aUn8XPQUPbFpRDDuBpY1/YXmQ8Yxucw5PCZea9gG2tZFt6IlafNNbqfpb1zuMb56myhxQdB22pyJG9/EBV+NR5SYSTiH0Na+sWQ0nZKNuLaKsr/vuLT7vYbLucl2n/N5FvPNByGEEEJShYsPQgghhKRK3rldul/ptLW1Oe+TxGexabhdtGNor/6ScLtor5t9P8209QHb1D4R9nWz2Ox06tSpQBnDoWuvn7VQ+Fo5iTa0V5a2ea6FrtbKmgsE3VMunyD6hrZGO2huGxu+YccRbXsu3C5oaxe0dAi+n95Gue9p145WH+dUFLR7pXYuXO4pSNxPiHvD7ZL0J8oi2edY93PbKfyFieKAyyGHDh2Sqqqq3u4GIYQQQiJw8OBBGTNmTNY6ebf46OrqkiNHjsjQoUOlpaVFqqqq5ODBg1JaWtrbXeuzNDc3044JQVsmB22ZDLRjctCW8TDGSEtLi1RWVupB91LqkzP9+vXLrJi6XyGVlpZyIiQA7ZgctGVy0JbJQDsmB20ZnbKyMqd6FJwSQgghJFW4+CCEEEJIquT14qOwsFAeeeSRUOAk4gftmBy0ZXLQlslAOyYHbZkeeSc4JYQQQsj5TV6/+SCEEELI+QcXH4QQQghJFS4+CCGEEJIqXHwQQgghJFXydvHxxBNPSHV1tRQVFcmkSZPkzTff7O0u5TV1dXUyZcoUGTp0qIwaNUpuvfVW2b9/f6COMUZqa2ulsrJSiouLZebMmbJ3795e6nHfoa6uTgoKCmTx4sWZ32hLdw4fPix33nmnjBgxQkpKSuQb3/iG7NixI7OdttQ5e/as/OpXv5Lq6mopLi6Wiy++WB599NFAXg3a0c4bb7wht9xyi1RWVkpBQYG88MILge0udmtvb5cHHnhARo4cKYMHD5bvf//7cujQoRRHcR5i8pBNmzaZgQMHmqeeesrs27fPLFq0yAwePNh8+umnvd21vOW73/2uWbdunfnwww/N7t27zc0332zGjh1rTp06lamzatUqM3ToUPPcc8+ZPXv2mNtuu82MHj3aNDc392LP85t33nnHjB8/3lx11VVm0aJFmd9pSze++OILM27cOHPPPfeYv//976ahocG88sor5uOPP87UoS11VqxYYUaMGGH+8pe/mIaGBvOnP/3JDBkyxKxZsyZTh3a08/LLL5vly5eb5557zoiIef755wPbXew2f/58c9FFF5n6+nqzc+dOc+ONN5qrr77anD17NuXRnD/k5eLjm9/8ppk/f37gt8suu8w89NBDvdSjvkdTU5MREbNt2zZjjDFdXV2moqLCrFq1KlPnzJkzpqyszPz+97/vrW7mNS0tLaampsbU19ebGTNmZBYftKU7Dz74oJk+ffo5t9OWbtx8883mZz/7WeC3uXPnmjvvvNMYQzu6gosPF7udOHHCDBw40GzatClT5/Dhw6Zfv35my5YtqfX9fCPv3C4dHR2yY8cOmT17duD32bNny/bt23upV32PkydPiojI8OHDRUSkoaFBGhsbA3YtLCyUGTNm0K7n4P7775ebb75ZvvOd7wR+py3defHFF2Xy5Mnyox/9SEaNGiXXXHONPPXUU5nttKUb06dPl7/97W/y0UcfiYjI+++/L2+99ZbcdNNNIkI7RsXFbjt27JAvv/wyUKeyslImTpxI28Yg7xLLHTt2TDo7O6W8vDzwe3l5uTQ2NvZSr/oWxhhZsmSJTJ8+XSZOnCgikrGdza6ffvpp6n3MdzZt2iQ7d+6Ud999N7SNtnTnk08+kbVr18qSJUvk4YcflnfeeUd+/vOfS2Fhodx99920pSMPPvignDx5Ui677DLp37+/dHZ2ymOPPSa33367iHBORsXFbo2NjTJo0CAZNmxYqA6fSdHJu8VHN90ZbbsxxoR+I3YWLlwoH3zwgbz11luhbbSrzsGDB2XRokWydetWKSoqOmc92lKnq6tLJk+eLCtXrhQRkWuuuUb27t0ra9eulbvvvjtTj7bMzrPPPivPPPOMbNy4Ua688krZvXu3LF68WCorK2XevHmZerRjNKLYjbaNR965XUaOHCn9+/cPrSibmppCq1MS5oEHHpAXX3xRXnvtNRkzZkzm94qKChER2tWBHTt2SFNTk0yaNEkGDBggAwYMkG3btslvf/tbGTBgQMZetKXO6NGj5Yorrgj8dvnll8uBAwdEhPPSlV/+8pfy0EMPyY9//GP5+te/LnfddZf84he/kLq6OhGhHaPiYreKigrp6OiQ48ePn7MO8SfvFh+DBg2SSZMmSX19feD3+vp6mTZtWi/1Kv8xxsjChQtl8+bN8uqrr0p1dXVge3V1tVRUVATs2tHRIdu2baNdgW9/+9uyZ88e2b17d+Zv8uTJ8pOf/ER2794tF198MW3pyPXXXx/65Pujjz6ScePGiQjnpSutra3Sr1/wdt2/f//Mp7a0YzRc7DZp0iQZOHBgoM7Ro0flww8/pG3j0GtS1yx0f2r79NNPm3379pnFixebwYMHm//85z+93bW85b777jNlZWXm9ddfN0ePHs38tba2ZuqsWrXKlJWVmc2bN5s9e/aY22+/nZ/iOdLzaxdjaEtX3nnnHTNgwADz2GOPmX/961/mj3/8oykpKTHPPPNMpg5tqTNv3jxz0UUXZT613bx5sxk5cqRZunRppg7taKelpcXs2rXL7Nq1y4iIWb16tdm1a1cmdIOL3ebPn2/GjBljXnnlFbNz507zrW99i5/axiQvFx/GGPO73/3OjBs3zgwaNMhce+21mU9GiR0Rsf6tW7cuU6erq8s88sgjpqKiwhQWFpobbrjB7Nmzp/c63YfAxQdt6c5LL71kJk6caAoLC81ll11mnnzyycB22lKnubnZLFq0yIwdO9YUFRWZiy++2Cxfvty0t7dn6tCOdl577TXrvXHevHnGGDe7tbW1mYULF5rhw4eb4uJi873vfc8cOHCgF0Zz/lBgjDG9886FEEIIIf+P5J3mgxBCCCHnN1x8EEIIISRVuPgghBBCSKpw8UEIIYSQVOHigxBCCCGpwsUHIYQQQlKFiw9CCCGEpAoXH4QQQghJFS4+CCGEEJIqXHwQQgghJFW4+CCEEEJIqnDxQQghhJBU+R91+BUOaD1NVAAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "e1b71a67fbe998bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T22:43:35.371870Z",
     "start_time": "2024-07-05T22:43:35.166642Z"
    }
   },
   "source": [
    "print(tf.strings.reduce_join([numToChar(word) for word in val[1][0]]))\n",
    "print(\"num of chars:\", len(([numToChar(word) for word in val[1][0]])))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'THEY MEET EACH OTHER OUTSIDE THE CHURCHTHEY WERE NEVER QUITE THE SAME WITHOUT HIM BECAUSE THE LEARINESS OF THE CARRY ON FILMSIVE BEEN VERY BUSY BABY SITTING MY NEW THREE WEEK OLD GRANDDAUGHTERTHESE GUYS HAVE MEMORIES OF THE DAY THEY BUILT AN EXTENSION SOMEWHERE IN GLOUCESTER', shape=(), dtype=string)\n",
      "num of chars: 145\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "cell_type": "markdown",
   "id": "7b9fe2e89759a25",
   "metadata": {},
   "source": [
    "## designing the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "44de38608ebec792",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:19.952783Z",
     "start_time": "2024-07-04T05:58:19.939730Z"
    }
   },
   "source": [
    "# imports for the model architecture \n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPooling3D, TimeDistributed, Flatten, GRU\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, Nadam, SGD\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "a4e35802d732d3c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:22.079998Z",
     "start_time": "2024-07-04T05:58:20.389893Z"
    }
   },
   "source": [
    "inputShape = data.as_numpy_iterator().next()[0][0].shape\n",
    "print(inputShape)\n",
    "print(charToNum.get_vocabulary())\n",
    "print(len(charToNum.get_vocabulary()))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290, 40, 120, 1)\n",
      "['', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ' ']\n",
      "28\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "84706072692f52d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:37.047892Z",
     "start_time": "2024-07-04T05:58:37.031835Z"
    }
   },
   "source": [
    "# model to be actually trained\n",
    "def createModel(x): \n",
    "    model = Sequential([\n",
    "    Conv3D(32, 3, input_shape=inputShape, padding='same', activation='relu', name=\"conv1\"),\n",
    "    MaxPooling3D((1,2,2), name=\"maxPool1\"),\n",
    "    \n",
    "    Conv3D(64, 3, padding='same', activation='relu', name=\"conv2\"),\n",
    "    MaxPooling3D((1,2,2), name=\"maxPool2\"),\n",
    "        \n",
    "    Conv3D(96, 3,  padding='same', activation='relu', name=\"conv3\"),\n",
    "    MaxPooling3D((1,2,2), name=\"maxPool3\"),\n",
    "    \n",
    "    TimeDistributed(Flatten()),\n",
    "    \n",
    "    # Bidirectional(LSTM(256, kernel_initializer='orthogonal', return_sequences=True)),\n",
    "    Bidirectional(GRU(x, kernel_initializer='orthogonal', return_sequences=True)),\n",
    "    Dropout(.5),\n",
    "        \n",
    "    # Bidirectional(LSTM(256, kernel_initializer='orthogonal' , return_sequences=True)),\n",
    "    Bidirectional(GRU(x, kernel_initializer='orthogonal' , return_sequences=True)),\n",
    "    Dropout(.5),\n",
    "    \n",
    "    Dense(charToNum.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "# model to be actually trained\n",
    "def createModel2(x): \n",
    "    model = Sequential([\n",
    "    Conv3D(32, 3, stride = (1,2,2),input_shape=inputShape, padding='same', activation='relu', name=\"conv1\"),\n",
    "    MaxPooling3D((1,2,2), name=\"maxPool1\"),\n",
    "    \n",
    "    Conv3D(64, 3, stride = (1,2,2), padding='same', activation='relu', name=\"conv2\"),\n",
    "    MaxPooling3D((1,2,2), name=\"maxPool2\"),\n",
    "        \n",
    "    Conv3D(96, 3,stride = (1,2,2),  padding='same', activation='relu', name=\"conv3\"),\n",
    "    MaxPooling3D((1,2,2), name=\"maxPool3\"),\n",
    "    \n",
    "    TimeDistributed(Flatten()),\n",
    "    \n",
    "    # Bidirectional(LSTM(256, kernel_initializer='orthogonal', return_sequences=True)),\n",
    "    Bidirectional(LSTM(x, kernel_initializer='orthogonal', return_sequences=True)),\n",
    "    Dropout(.5),\n",
    "        \n",
    "    # Bidirectional(LSTM(256, kernel_initializer='orthogonal' , return_sequences=True)),\n",
    "    Bidirectional(LSTM(x, kernel_initializer='orthogonal' , return_sequences=True)),\n",
    "    Dropout(.5),\n",
    "    \n",
    "    Dense(charToNum.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax')\n",
    "    ])\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "d728bc2771721d6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:40.859070Z",
     "start_time": "2024-07-04T05:58:37.467431Z"
    }
   },
   "source": [
    "model2 = createModel(256)\n",
    "model3 = createModel2\n",
    "print(\"final model input shape:\",  inputShape)\n",
    "model2.summary()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final model input shape: (290, 40, 120, 1)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1 (Conv3D)              (None, 290, 40, 120, 32)  896       \n",
      "                                                                 \n",
      " maxPool1 (MaxPooling3D)     (None, 290, 20, 60, 32)   0         \n",
      "                                                                 \n",
      " conv2 (Conv3D)              (None, 290, 20, 60, 64)   55360     \n",
      "                                                                 \n",
      " maxPool2 (MaxPooling3D)     (None, 290, 10, 30, 64)   0         \n",
      "                                                                 \n",
      " conv3 (Conv3D)              (None, 290, 10, 30, 96)   165984    \n",
      "                                                                 \n",
      " maxPool3 (MaxPooling3D)     (None, 290, 5, 15, 96)    0         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 290, 7200)        0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 290, 512)         11455488  \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 290, 512)          0         \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 290, 512)         1182720   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 290, 512)          0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 290, 29)           14877     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,875,325\n",
      "Trainable params: 12,875,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "9cd1b05996f23f8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T18:47:49.049211Z",
     "start_time": "2024-07-05T18:47:49.031170Z"
    }
   },
   "source": [
    "# custom functions \n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr        \n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "    \n",
    "def scheduler2(epoch, lr):\n",
    "    return lr * tf.math.exp(-0.1)\n",
    "# custom loss function \n",
    "def CTCLoss(yTrue, yPred):\n",
    "    # y true is the text alignment (None, 99) \n",
    "    # y pred is the end result of the model (154, 41) \n",
    "    batchLen = tf.cast(tf.shape(yTrue)[0], dtype=\"int64\")\n",
    "\n",
    "    inputLen = tf.cast(tf.shape(yPred)[1], dtype=\"int64\")\n",
    "    labelLen = tf.cast(tf.shape(yTrue)[1], dtype=\"int64\")\n",
    "    inputLen = inputLen * tf.ones(shape=(batchLen, 1), dtype=\"int64\")\n",
    "    labelLen = labelLen * tf.ones(shape=(batchLen, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = tf.keras.backend.ctc_batch_cost(yTrue, yPred, inputLen, labelLen)   \n",
    "    return loss \n",
    "\n",
    "class ProduceExample(tf.keras.callbacks.Callback): \n",
    "    def __init__(self, dataset) -> None: \n",
    "        self.dataset = dataset.as_numpy_iterator()\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None) -> None:\n",
    "        try: \n",
    "            data = self.dataset.next()\n",
    "            yhat = self.model.predict(data[0])\n",
    "       \n",
    "            decoded = tf.keras.backend.ctc_decode(yhat, [maxFrameCt, maxFrameCt, maxFrameCt, maxFrameCt], greedy=False)[0][0].numpy()\n",
    "            for x in range(len(yhat)):           \n",
    "                print('Original:', tf.strings.reduce_join(numToChar(data[1][x])).numpy().decode('utf-8'))\n",
    "                print('Prediction:', tf.strings.reduce_join(numToChar(decoded[x])).numpy().decode('utf-8'))\n",
    "                print(\"Word Error Rate: \", str(wer(tf.strings.reduce_join(numToChar(data[1][x])).numpy().decode('utf-8'), tf.strings.reduce_join(numToChar(decoded[x])).numpy().decode('utf-8') ) * 100) + \"%\")\n",
    "                print('~'*100)\n",
    "        except: \n",
    "            pass     \n",
    "      "
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "id": "d5afa6ac776aca30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T22:06:09.308473Z",
     "start_time": "2024-07-05T22:06:09.279702Z"
    }
   },
   "source": [
    "def makePrediction(model, valuePassed=None): \n",
    "    if valuePassed is None: \n",
    "        value = val\n",
    "    else: \n",
    "        value = valuePassed\n",
    "    yHat = model.predict(value[0])\n",
    "    \n",
    "    decoded = tf.keras.backend.ctc_decode(yHat, [maxFrameCt, maxFrameCt, maxFrameCt, maxFrameCt], greedy=False)[0][0].numpy()\n",
    "    originalArr = []\n",
    "    predArr = []\n",
    "    for x in range(len(yHat)):          \n",
    "        original = tf.strings.reduce_join(numToChar(val[1][x])).numpy().decode('utf-8')\n",
    "        prediction = tf.strings.reduce_join(numToChar(decoded[x])).numpy().decode('utf-8')\n",
    "        originalArr.append(original)\n",
    "        predArr.append(prediction )\n",
    "        \n",
    "        print('Original:', original)\n",
    "        print('Prediction:', prediction)\n",
    "        print(\"Word Error Rate on Prediction:\", str(wer(original,prediction) * 100) + \"%\")\n",
    "        print('~' * 40)\n",
    "    print(\"Avg Word Error Rate:\", str(wer(originalArr, predArr) * 100) + \"%\")\n",
    "    \n",
    "    return value, yHat, decoded"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:46.004372Z",
     "start_time": "2024-07-04T05:58:40.891571Z"
    }
   },
   "cell_type": "code",
   "source": "makePrediction(model2)",
   "id": "18278119fccacab6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n",
      "Original: THEY MEET EACH OTHER OUTSIDE THE CHURCH\n",
      "Prediction: GZGZGZGZGZGZGZYZGZGYLYE EJQJI EGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGHYN\n",
      "Word Error Rate on Prediction: 100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEY WERE NEVER QUITE THE SAME WITHOUT HIM BECAUSE THE LEARINESS OF THE CARRY ON FILMS\n",
      "Prediction: GRMRMGGMMMMFGRMMGMMRMRFMFRMRMRMRMMMLMYMYMYMQMOJAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAHZ\n",
      "Word Error Rate on Prediction: 100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IVE BEEN VERY BUSY BABY SITTING MY NEW THREE WEEK OLD GRANDDAUGHTER\n",
      "Prediction: GRMRFRFMVMVMRMMRMRMRMVMVMVMVMVRMRMVXVXMRMRMKMYMYMYMYMYMYKMUFEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEV\n",
      "Word Error Rate on Prediction: 100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THESE GUYS HAVE MEMORIES OF THE DAY THEY BUILT AN EXTENSION SOMEWHERE IN GLOUCESTER\n",
      "Prediction: AKYKRKRKYKRKYKYKYKYGYKGKGKGKRGRKRYRKRKRKRKRKYMYMYMYMLMCYJEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKX\n",
      "Word Error Rate on Prediction: 100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ['THEY MEET EACH OTHER OUTSIDE THE CHURCH', 'THEY WERE NEVER QUITE THE SAME WITHOUT HIM BECAUSE THE LEARINESS OF THE CARRY ON FILMS', 'IVE BEEN VERY BUSY BABY SITTING MY NEW THREE WEEK OLD GRANDDAUGHTER', 'THESE GUYS HAVE MEMORIES OF THE DAY THEY BUILT AN EXTENSION SOMEWHERE IN GLOUCESTER'] \n",
      "Predictions: ['GZGZGZGZGZGZGZYZGZGYLYE EJQJI EGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGEGHYN', 'GRMRMGGMMMMFGRMMGMMRMRFMFRMRMRMRMMMLMYMYMYMQMOJAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAHZ', 'GRMRFRFMVMVMRMMRMRMRMVMVMVMVMVRMRMVXVXMRMRMKMYMYMYMYMYMYKMUFEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEWEV', 'AKYKRKRKYKRKYKYKYKYGYKGKGKGKRGRKRYRKRKRKRKRKYMYMYMYMLMCYJEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKEKX']\n",
      "Avg Word Error Rate: 100.0%\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## compilign the model??",
   "id": "25b028a1d086a394"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T05:58:48.599941Z",
     "start_time": "2024-07-04T05:58:48.576945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model2.compile(optimizer=Adam(learning_rate=0.0002), loss=CTCLoss)\n",
    "# create all the callbacks \n",
    "checkpointCallback2 = ModelCheckpoint('newLipModelv11_m2.weights.h5', monitor='loss',save_weights_only=False, save_freq='epoch') # save checkpoints after each epoch\n",
    "exampleCallback2 = ProduceExample(test)"
   ],
   "id": "ec6634918fbbb5b3",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T16:03:55.491102Z",
     "start_time": "2024-07-04T08:15:50.887584Z"
    }
   },
   "cell_type": "code",
   "source": "model2.fit(train, validation_data=test, epochs=300, callbacks=[checkpointCallback2, exampleCallback2], use_multiprocessing=True)",
   "id": "8c3fe5f2bba6b6ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Original: AND THE LOWER HALF OF ALEXANDERS BODY WAS SHATTERED\n",
      "Prediction: I E E E E E E E E E E E E \n",
      "Word Error Rate:  144.44444444444443%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: JOE PASSED AWAY AND WITH ADAM AND HIS FAMILYS PERMISSION\n",
      "Prediction: I E E E E E E E E E E E E E E \n",
      "Word Error Rate:  150.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SO A FARM LIKE THIS\n",
      "Prediction: I E E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ONE OF US DECIDES THAT WERE GOING TO DO SOMETHING TOGETHER OF THEIR CHOICE\n",
      "Prediction: I E E E E E E E E E E E E E E E E E E \n",
      "Word Error Rate:  135.71428571428572%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 806s 5s/step - loss: 202.7820 - val_loss: 200.8653\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "Original: ALL RIGHT FOR THE ESTABLISHMENT TO TELL ME OPEN THE BORDERS\n",
      "Prediction: IH E T T T T E E E E E E E \n",
      "Word Error Rate:  118.18181818181819%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE GREAT BRITISH SHOWMAN\n",
      "Prediction: IH E T T T E E \n",
      "Word Error Rate:  175.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BORDER CONTROLS ON\n",
      "Prediction: I E E E E\n",
      "Word Error Rate:  166.66666666666669%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THAT MAN WAS JUDGE DREAD\n",
      "Prediction: IH E E T E E E E \n",
      "Word Error Rate:  160.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 600s 4s/step - loss: 200.1648 - val_loss: 199.3079\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "Original: IF YOU COME ACROSS A BOOK OF SUCH QUALITY\n",
      "Prediction: IH E E E E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE WONDERFUL THING IS ITS BEEN DOUBLE GLAZED\n",
      "Prediction: IH E E E E E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEYVE HAD POSITIVE THINGS TO SAY ABOUT ALL THE PROPERTIES\n",
      "Prediction: IH E E E E E E E E E  \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IS THAT THE TRUE REFLECTION\n",
      "Prediction: I E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 601s 4s/step - loss: 199.2603 - val_loss: 197.9945\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "Original: IM AFRAID THAT BECKY HAS SINGLED YOU OUT\n",
      "Prediction: T E E E E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHAT REALLY MAKES A CHIP A CHIP IS THE CRUNCH\n",
      "Prediction: T E E E E E E E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE WAY THINGS ARE LOOKING\n",
      "Prediction: TE E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I DONT WANT TO DO IT\n",
      "Prediction: TE E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 597s 4s/step - loss: 199.7089 - val_loss: 197.4216\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "Original: THE DIFFERENCE BETWEEN TWO VERY BIG NUMBERS\n",
      "Prediction: TE E E E E E E E E E \n",
      "Word Error Rate:  142.85714285714286%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE BIG QUESTION IS\n",
      "Prediction: AH E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IT WAS PRESENTED BY GEORGE III TO MY GREAT GREAT GREAT GREAT GREAT UNCLE\n",
      "Prediction: TH E E E E E E E E E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEY KEPT IT FOR THREE MONTHS\n",
      "Prediction: AH E E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 597s 4s/step - loss: 198.2024 - val_loss: 197.1380\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "Original: WHERE DOES THAT LEAVE US\n",
      "Prediction: IE E E  \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BECAUSE THEYRE VERY AMENABLE TO NEGOTIATION\n",
      "Prediction: IE E E E E E E E E E E \n",
      "Word Error Rate:  183.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS GOT EVERYTHING THAT THEYVE ASKED FOR\n",
      "Prediction: IE E E E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THIS PROGRAMME IS FOURTEEN MINUTES LONG AND WE LIKE TO TRY TO COVER AT LEAST ONE TOPIC FROM A VARIETY OF\n",
      "Prediction: IE E E E E E E E E E E E E E E E E E E E E E E E \n",
      "Word Error Rate:  114.28571428571428%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 596s 3s/step - loss: 198.7497 - val_loss: 197.8039\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "Original: WHAT IS NOT TO LIKE ABOUT THIS DUPLEX\n",
      "Prediction: IH E E E E E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND THEN ITS GOING TO COME DOWN TO A QUESTION OF COST\n",
      "Prediction: IH E E E E E E E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I THINK HIS LOVE WAS THE WORD\n",
      "Prediction: IH E E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I WROTE THIS BOOK\n",
      "Prediction: IH E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 598s 4s/step - loss: 198.4187 - val_loss: 195.0121\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "Original: BEARING THAT IN MIND\n",
      "Prediction: IH E E E E \n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHICH IS WHY WERE DOING IT\n",
      "Prediction: IH E E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THERE ARE ABOUT FOUR HUNDRED GRAND MASTERS\n",
      "Prediction: IH E E E E E E E E E E E E \n",
      "Word Error Rate:  185.71428571428572%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND ITS REALLY\n",
      "Prediction: IH E E E \n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 594s 3s/step - loss: 196.7961 - val_loss: 137.3825\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "Original: SHE WAS STRUGGLING\n",
      "Prediction: IH E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I WOULD SAY NINETY OF THAT WAS\n",
      "Prediction: IH E E T \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IT WILL BE LOVELY TO EAT\n",
      "Prediction: IE E E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE OWNERS INFORMED\n",
      "Prediction: IH E E E \n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 598s 4s/step - loss: 118.6882 - val_loss: 113.4193\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "Original: WIDE OPEN FIELDS\n",
      "Prediction: IH E E E\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: YOU ARE PART OF THAT PICTURE\n",
      "Prediction: IH E E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND OPING YOU WILL WIN\n",
      "Prediction: IH E E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND WHEN YOU SEE SOMEONE YOU LOVE\n",
      "Prediction: IH E E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 592s 3s/step - loss: 114.4030 - val_loss: 115.5458\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "Original: THERE ARE SOME CONVERTED BARNS\n",
      "Prediction: IH E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SHE HAD NO ENGLISH\n",
      "Prediction: IH E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IM A LITTLE BIT NERVOUS\n",
      "Prediction: IH E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS STILL VERY BUOYANT FOR RARE AND UNUSUAL ITEMS\n",
      "Prediction: IH E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 599s 4s/step - loss: 112.8335 - val_loss: 113.0488\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "Original: THERE HAVE BEEN SO MANY MOMENTS DURING THE WEEK WHICH REMIND US ALL OF THE COURAGE AND BRAVERY OF\n",
      "Prediction: IE E E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: YOU COME BACK YEAR AFTER YEAR\n",
      "Prediction: IH E E E E E E\n",
      "Word Error Rate:  116.66666666666667%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WITH A MARVELLOUS MUSICAL MEDLEY THAT INCLUDES A BURST OF ONE OF THE BEST LOVED\n",
      "Prediction: IE E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WE WERE GONE FOR A COUPLE OF DAYS AND CAME BACK\n",
      "Prediction: IH E E E E E E E E E E E\n",
      "Word Error Rate:  109.09090909090908%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 604s 4s/step - loss: 115.2198 - val_loss: 116.2201\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "Original: AND THE NEXT DAY\n",
      "Prediction: I E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SEEMS ALMOST JAW DROPPING\n",
      "Prediction: I E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE BIDS IN THE ROOM THEN\n",
      "Prediction: I T E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IVE JUST SPOTTED SOMETHING FANTASTIC\n",
      "Prediction: I E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 605s 4s/step - loss: 116.3331 - val_loss: 116.3827\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "Original: WE WOULD LOVE TO SELL IT\n",
      "Prediction: IH E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SEX CHANGING INVERTEBRATE MASQUERADING AS A ROCK\n",
      "Prediction: IH E E E E E E E\n",
      "Word Error Rate:  114.28571428571428%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I WOULD PUT HSA\n",
      "Prediction: IH E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEY LEARNED TO DANCES\n",
      "Prediction: IH E E E E E E E E E\n",
      "Word Error Rate:  250.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 599s 4s/step - loss: 113.9422 - val_loss: 112.1469\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "Original: AS DEMAND FOR THE WHITE STUFF GROWS EVER HIGHER\n",
      "Prediction: IOE E E E E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: MY BRAIN PICKS UP THE ELECTRICAL VIBRATIONS\n",
      "Prediction: IH E E E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: MY GUESS WOULD BE RIGA\n",
      "Prediction: IE E E E E E E\n",
      "Word Error Rate:  140.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: DIES OF RADIATION SICKNESS\n",
      "Prediction: IE E E E E E E E\n",
      "Word Error Rate:  200.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 598s 4s/step - loss: 113.6011 - val_loss: 113.5183\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "Original: DEALS ON WHEELS\n",
      "Prediction: IH E E E\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I FINISHED UP TEACHING\n",
      "Prediction: IH AE E E E E E E\n",
      "Word Error Rate:  200.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: FIVE CONTENDERS TONIGHT\n",
      "Prediction: IHE E E E E E E E\n",
      "Word Error Rate:  266.66666666666663%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WE ARE COMING BACK LATER ON IN THE SHOW\n",
      "Prediction: IHE T E E E E E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 600s 4s/step - loss: 111.3793 - val_loss: 109.7041\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "Original: SENSIBLE LITTLE CARS\n",
      "Prediction: IH E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: CLARISSA FROM THE TWO FAT LADIES ABSOLUTELY LOATHES IN THE WILD\n",
      "Prediction: IH E T T \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: NOW HAVING OVER A QUARTER OF A MILLION\n",
      "Prediction: IH E E T T\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: TURN OUT AND PLAY THE ODD GAME OF CRICKET\n",
      "Prediction: IH E E E T \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 602s 4s/step - loss: 111.1746 - val_loss: 111.0985\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "Original: I WENT WITH MY GUT FEELING ON THIS\n",
      "Prediction: IH E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I THINK HOPING TO MAKE A PROFIT ON IT\n",
      "Prediction: IH E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WATER LEVELS ROSE\n",
      "Prediction: TH E E E\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WE DONT WANT TO GET STUCK IN THE PAST\n",
      "Prediction: IH E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 602s 4s/step - loss: 112.2612 - val_loss: 111.6184\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "Original: BUT THEYRE REALLY EATING HIGH QUALITY FOOD\n",
      "Prediction: THE T T T T T T T T T\n",
      "Word Error Rate:  142.85714285714286%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHAT IS WORRYING YOU ABOUT HAVING BOUGHT THIS\n",
      "Prediction: IH A A T\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHERE WAS THE MONEY COMING FROM FOR THIS AND THAT\n",
      "Prediction: TE E E E E E E E E E E\n",
      "Word Error Rate:  110.00000000000001%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEY MEET EACH OTHER OUTSIDE THE CHURCH\n",
      "Prediction: TE T E E ET\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 602s 4s/step - loss: 111.3344 - val_loss: 111.1686\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "Original: THE SKYLINE CHANGED\n",
      "Prediction: THE E\n",
      "Word Error Rate:  66.66666666666666%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS NOT UPSTAIRS\n",
      "Prediction: IH \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WANDERING THROUGH SPACE AND TIME IN\n",
      "Prediction: THE \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: OF WHAT HAPPENED HERE THOSE MILLIONS OF YEARS AGO\n",
      "Prediction: T E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 601s 4s/step - loss: 111.4158 - val_loss: 110.6524\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "Original: IM AFRAID I MUST RESIGN\n",
      "Prediction: IH E E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: HE SET UP HIS STALL HERE AT THE MAPPIN PAVILION AWAY FROM THE CROWDS\n",
      "Prediction: THE T E E E \n",
      "Word Error Rate:  92.85714285714286%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND IT WAS LIKE\n",
      "Prediction: IH E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BECAUSE THEY HAVE NOT BEEN AT THE TOP\n",
      "Prediction: THE E \n",
      "Word Error Rate:  87.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 601s 4s/step - loss: 112.4454 - val_loss: 112.6412\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "Original: I LIKE TO SPEND THE MONEY IF IM GIVEN IT\n",
      "Prediction: IE E O\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THIS IS GOLD DUST\n",
      "Prediction: IH A \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND THEN WALK TO THE PLACE IM GOING\n",
      "Prediction: IH E T E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SO WEVE GOT SOME WHOPPING GREAT GAPS HERE\n",
      "Prediction: IH T T E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 596s 3s/step - loss: 110.2823 - val_loss: 114.1703\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "Original: WE SAW THIS IN A LOCAL AUCTION ABOUT FIVE YEARS AGO AND THOUGHT IT WAS JUST THE PIECE\n",
      "Prediction: IH I \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE MID TH CENTURY\n",
      "Prediction: IH E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: A WAGE THAT ALLOWS YOU TO BRING UP A FAMILY AND ALLOWS YOU TO LIVE A DECENT LIFE\n",
      "Prediction: IH E \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE VALUES OF THEM\n",
      "Prediction: IHE T E T OE\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 597s 4s/step - loss: 107.8107 - val_loss: 109.0104\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "Original: HOPEFULLY TOWARDS MY DADS\n",
      "Prediction: I A T O E\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THIS IS AMAZING\n",
      "Prediction: IE I I E\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IVE HAD SOME GOOD TIMES NO\n",
      "Prediction: IE A A A A A A O OE\n",
      "Word Error Rate:  150.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: HE WAS OBVIOUSLY VERY\n",
      "Prediction: IH I O R\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 601s 4s/step - loss: 109.5942 - val_loss: 106.7807\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "Original: OVER THE LAST FEW YEARS\n",
      "Prediction: I O E O H IT\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I DONT WANT TO BE THE MOUSE\n",
      "Prediction: I I A O O O\n",
      "Word Error Rate:  85.71428571428571%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IT WASNT JUST A TRAGEDY\n",
      "Prediction: I A A A A A O\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: FOR MANY PEOPLE\n",
      "Prediction: I O O O\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 602s 4s/step - loss: 107.6142 - val_loss: 102.6303\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "Original: FOR OUR ANCESTORS\n",
      "Prediction: I O OE O OE\n",
      "Word Error Rate:  166.66666666666669%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: TWENTY KILOMETRES ACROSS\n",
      "Prediction: I E E E E E\n",
      "Word Error Rate:  200.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE PASTEUR INSTITUTE HAS BEEN PRIMARILY INVOLVED IN RESEARCHING\n",
      "Prediction: I I I I E IE I I I E\n",
      "Word Error Rate:  111.11111111111111%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I HAD ONE MYSELF\n",
      "Prediction: I OE O OES\n",
      "Word Error Rate:  75.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 602s 4s/step - loss: 107.2316 - val_loss: 102.1314\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "Original: ITS WELL THUMBED\n",
      "Prediction: I W H \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BEFORE BUT IVE NEVER SEEN ONE WITH ROLLED PAPERWORK\n",
      "Prediction: IE H BE E E E E N H E E E OE\n",
      "Word Error Rate:  144.44444444444443%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BREATHLESS OF COURSE\n",
      "Prediction: I IN IE WU OE\n",
      "Word Error Rate:  166.66666666666669%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I WOULD IMAGINE A BUILDING LIKE THIS\n",
      "Prediction: I E E E E E T E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 602s 4s/step - loss: 106.2461 - val_loss: 103.6305\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "Original: I WOULD SAY IT WAS WORTH FOUR HUNDRED TWENTY FIVE PER CALENDAR MONTH\n",
      "Prediction: I WO WO WO WO OR WE TE TE E AE RER RNTHT\n",
      "Word Error Rate:  92.3076923076923%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IT WOULD BE FORTY PLUS YEARS AGO\n",
      "Prediction: I L O O T A E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHETHER ITS FROM A SHOP OR BEING SERVED TO US IN A RESTAURANT\n",
      "Prediction: I A A A A O A A O\n",
      "Word Error Rate:  84.61538461538461%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THROUGHOUT THE WHOLE SHOW\n",
      "Prediction: I O O O O\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 600s 4s/step - loss: 103.5953 - val_loss: 100.7992\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "Original: I WILL BE IN THE KITCHEN\n",
      "Prediction: I IE I IET\n",
      "Word Error Rate:  83.33333333333334%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHEN I RETURNED\n",
      "Prediction: IE E A IN\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: YOU NEVER WANT TO SEE DAMAGE\n",
      "Prediction: IE AE E E A AE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THAT TELLS US SOMETHING ABOUT THE SIZE OF THE PIPES\n",
      "Prediction: I A AE A A OE E E IE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 600s 4s/step - loss: 102.5922 - val_loss: 100.9517\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "Original: FOR MY FIRST LORD MAYORS SHOW\n",
      "Prediction: I OE OE O HE A A A A \n",
      "Word Error Rate:  150.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WE HAVE A ROOM DEDICATED IN THE PANDA FACILITY TO DO THAT\n",
      "Prediction: IE A AE AE AE ON T O O O O O O O\n",
      "Word Error Rate:  116.66666666666667%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: EIGHTY FOUR CHARING CROSS ROAD\n",
      "Prediction: IN H PU O\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WE ARE GOING TO HAVE A RACE AND ITS A VERY\n",
      "Prediction: IE OE AE I IN TIN IE A A AN N T T\n",
      "Word Error Rate:  109.09090909090908%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 596s 3s/step - loss: 102.7033 - val_loss: 98.6022\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "Original: SO ON THAT BASIS\n",
      "Prediction: I O O I I OIS IS\n",
      "Word Error Rate:  175.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHEN IM GOING ROUND\n",
      "Prediction: WO O ON O O\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: FAMOUS FOR ITS MINING IN THE PAST\n",
      "Prediction: I O O S O I A O IE\n",
      "Word Error Rate:  128.57142857142858%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND YOU HAVE TO LOOK VERY CLOSELY\n",
      "Prediction: IHE A H H O OS E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 604s 4s/step - loss: 103.6571 - val_loss: 100.1046\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "Original: WHO KNOWS WHERE TO START\n",
      "Prediction: TH O WS WHE HE \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: EAST AND WEST TO SIT AT YOUR TABLE\n",
      "Prediction: TE E E T A A A A \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: PLEASE MAKE YOUR WAY TO THE SAFE AREA\n",
      "Prediction: THE S AE AE OE O A AT\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: DECORATING COMES UNDER MAINTENANCE\n",
      "Prediction: THE ESE E A O H\n",
      "Word Error Rate:  150.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 598s 4s/step - loss: 99.0116 - val_loss: 99.6678\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "Original: THE DEER ARENT MANAGED SO WELL\n",
      "Prediction: I E E E A IG\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: HES BEEN UP ALL NIGHT\n",
      "Prediction: TH E A A A \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THAT IS SUCH A HARSH WORD\n",
      "Prediction: THE E H O H HA A\n",
      "Word Error Rate:  116.66666666666667%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE BAIT FISHING MAY STILL BE A LITTLE BIT OF A CHINK IN HIS ARMOUR\n",
      "Prediction: IE HAT AE AS A A O H T\n",
      "Word Error Rate:  86.66666666666667%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 600s 4s/step - loss: 100.5494 - val_loss: 97.7184\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "Original: IF YOU CARED ANYTHING ABOUT YOUR KID\n",
      "Prediction: IE E E E E O O OI\n",
      "Word Error Rate:  114.28571428571428%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IT WAS A BATTLE THAT CHANGED THE COURSE OF HISTORY\n",
      "Prediction: T E T A A A HE E R O R\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHAT COLLECTORS MIGHT BE LOOKING FOR\n",
      "Prediction: IE E OE HE O O\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IS GETTING IN A BIT OF NICHE COLLECTING\n",
      "Prediction: TE AS AN AN IN IN IN\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 595s 3s/step - loss: 96.3315 - val_loss: 92.6008\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "Original: YOU HOUSEWIVES AT HOME SAY TO ME\n",
      "Prediction: WOD OE O WA TO O A O ONE\n",
      "Word Error Rate:  128.57142857142858%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS A TOP SPOT\n",
      "Prediction: IT T TOT\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHICH MEANS YOURE STILL PLUS TWENTY\n",
      "Prediction: WU OE E E A WO O\n",
      "Word Error Rate:  116.66666666666667%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND THE OTHER ONE IS A HOUSEHOLD NAME\n",
      "Prediction: THD HES H OS OE O L HU HA \n",
      "Word Error Rate:  112.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 605s 4s/step - loss: 99.3613 - val_loss: 92.8189\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "Original: TO BE PERFECTLY FRANK\n",
      "Prediction: IE AE E E IE\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SO WONDERFUL TO SEE THAT\n",
      "Prediction: IO WONE FU O H\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ABOUT YOUR ITALIAN AND YOUR INFLUENZA AND EVERYTHING\n",
      "Prediction: TOT O AS A T TA OA AET TE THT\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I WOULDNT WEAR THAT\n",
      "Prediction: IE OE O IT\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 604s 4s/step - loss: 95.8526 - val_loss: 90.2021\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "Original: A LITTLE BIT OF PEACE WOULD BE LOVELY\n",
      "Prediction: IN T OE A O OD LELY\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: DURING THE NIGHT\n",
      "Prediction: BHE E E E\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND WITH STEALTH\n",
      "Prediction: AND WL TH T H\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I WANT TO BE CONSIDERED FOR ADVANCEMENT\n",
      "Prediction: IETIT TE TE E E E E E TI IE\n",
      "Word Error Rate:  142.85714285714286%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 605s 4s/step - loss: 95.4937 - val_loss: 91.1306\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "Original: LOVELY FAMILY HOME\n",
      "Prediction: IE AI IE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE DERBYSHIRE ANTIQUES ADMIRATION SOCIETY\n",
      "Prediction: I IE I I IUS U IE I O O O O O ORM OA\n",
      "Word Error Rate:  300.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND WHAT ARE THESE\n",
      "Prediction: I HE O OT\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND IN MARTINS CASE YOUR BRAIN\n",
      "Prediction: I I A A O O A O O\n",
      "Word Error Rate:  150.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 599s 4s/step - loss: 90.9302 - val_loss: 87.8357\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "Original: AND THE EVER PRESENT RISK OF ATTACK\n",
      "Prediction: AND HE ER PRERE ON O ATAC\n",
      "Word Error Rate:  85.71428571428571%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: TIME TO TALK TO A COUPLE WHO ARE OFFICIALLY THE UNDEFEATED CHAMPIONS OF THE DANCE OFF\n",
      "Prediction: TE AE AE OE HE TE OD O AN H OAD L IO TI O AE O O I OE\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WE WOULD NOT HAVE HAD THE JOY OF SEEING THE LABOUR HIGH COMMAND IN A GREGGS TRYING TO PRETEND\n",
      "Prediction: IE ED OE O AN A A A ORD AN AD H H O ON ON AL O PRE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE BEST IN THE WORLD\n",
      "Prediction: I L INL HOEDS\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 597s 4s/step - loss: 89.8260 - val_loss: 84.4533\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "Original: WE SHOULD PURSUE THIS STRATEGY\n",
      "Prediction: TE O OE US THES THES\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WAY BEFORE YOUR TIME\n",
      "Prediction: I BEFOR OR U\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WERE USING MORE COAL TO MAKE ELECTRICITY\n",
      "Prediction: THE ON NG HE AL O ON OR IEIN\n",
      "Word Error Rate:  128.57142857142858%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IT WILL ALLOW US TO LOOK UP AT OUR GALAXY AND DEDUCE THE PROPERTIES OF DARK MATTER FROM WHAT\n",
      "Prediction: TE WE E E E AE OE O BO O OE UE TE HIE HE E OE AE OE AN TRN N TH TE O O HON\n",
      "Word Error Rate:  142.10526315789474%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 602s 4s/step - loss: 87.9231 - val_loss: 86.9244\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "Original: AND ONE LAST THING\n",
      "Prediction: AD ON ALTHIN\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND TWO DAYS AFTER LANDING\n",
      "Prediction: AND WOAY FE AI\n",
      "Word Error Rate:  80.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHICH IS WHAT I DO\n",
      "Prediction: THE OS O ID\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: HE DESPISED IT WITH A PASSION\n",
      "Prediction: TS OU L E H R\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 599s 4s/step - loss: 84.3201 - val_loss: 82.3074\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "Original: THE GOVERNMENT HAS PROMISED THOSE COMMUNITIES DESTROYED BY THE RIOTS THAT THE BBC WILL MAKE A DRAMA\n",
      "Prediction: TE OE EN HS POE E TOE E O TIE A O O O TI TE THT THES SE HE A HE E A\n",
      "Word Error Rate:  135.29411764705884%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: PAULS A HOST AT ONE OF THE LOCAL HOTELS IN TORQUAY\n",
      "Prediction: WHE IS T HA AU A I T ON\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE GROUNDS ARE SO EXTENSIVE\n",
      "Prediction: THE OUN S RE OE HE E\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHAT ARE YOU DOING HERE\n",
      "Prediction: WH O OE HE ET\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 603s 4s/step - loss: 85.5497 - val_loss: 80.5749\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "Original: WHICH ROUGHLY TRANSLATES AS DYE SPOTS\n",
      "Prediction: IH H ROU A A AS OS\n",
      "Word Error Rate:  116.66666666666667%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND EXQUISITE DANCING\n",
      "Prediction: AND QISTIS ACIG\n",
      "Word Error Rate:  66.66666666666666%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: LETS FIND OUT WHAT THE BIDDERS THINK\n",
      "Prediction: IHI A OUT HOE O O AN \n",
      "Word Error Rate:  85.71428571428571%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: DONT OVER ANALYSE IT\n",
      "Prediction: I OVR AE A\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 598s 4s/step - loss: 83.7086 - val_loss: 75.1172\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "Original: AND THE FIRST THING SHE KNEW ABOUT IT WAS WHEN IT APPEARED IN THE TELEGRAPH\n",
      "Prediction: TH HE WE HE WE WHE WHE WE WE WE WE WE IE E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: EIGHT OCLOCK ON A MONDAY NIGHT\n",
      "Prediction: IH A E HE AE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IF I VERE IN CHARGE OF SECURITY\n",
      "Prediction: I I IE AN HARE O BO IT\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: FOUR CELEBRITIES WHO HAVE BOWED TO PRESSURE AND AGREED TO BE TESTED ON HOW MUCH THEY KNOW\n",
      "Prediction: WHE REIE IE TOE OE WOR HE THE RE HAN TE IE TAT THETE A E THE TI E E\n",
      "Word Error Rate:  117.64705882352942%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 607s 4s/step - loss: 80.2266 - val_loss: 78.4711\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "Original: SO MAYBE WE SHOULD SAY TO NICK\n",
      "Prediction: TE AE AS O O OI\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: MEMORIES AND OUR EMOTIONAL STATES\n",
      "Prediction: IMRIS AD OUR ME OI ATASTHSTH\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I LIKE TO KEEP FIGURES ROUND\n",
      "Prediction: I IK O I I IE\n",
      "Word Error Rate:  83.33333333333334%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SOMETIMES ONE HAS TO EMBARK ON AN UNKNOWN JOURNEY LIKE THIS\n",
      "Prediction: IH A OE HE E O I I IE I IE IN OT A\n",
      "Word Error Rate:  127.27272727272727%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 605s 4s/step - loss: 80.6453 - val_loss: 73.1334\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "Original: SO IT ACTS AS A VERY EFFECTIVE DECOY AND IT MIGHT KEEP THE PREDATOR OCCUPIED\n",
      "Prediction: T IS AS AY AE E ED OE AND I IG TE HE PAED O ORCIE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: FINDING THREE MONTH OLD CURRIES UNDER THE BED\n",
      "Prediction: TH HE L IY TOR TA AS TO A P TOT\n",
      "Word Error Rate:  137.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BRINGING WEATHER SYSTEM AFTER WEATHER SYSTEM\n",
      "Prediction: TRINS AT ES TO Y MAE R ATES THE HE\n",
      "Word Error Rate:  166.66666666666669%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IT WAS MY ANCESTORS WHO WERE HUNTING THEIR HEADS\n",
      "Prediction: THE HE HTE OE AE TAS OE LA A ES\n",
      "Word Error Rate:  111.11111111111111%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 602s 4s/step - loss: 75.9482 - val_loss: 69.5705\n",
      "Epoch 47/300\n",
      "171/171 [==============================] - ETA: 0s - loss: 74.5386"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  InvalidArgumentError: {{function_node __wrapped__Pack_N_67_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [40,120,1] != values[19].shape = [40,1,120] [Op:Pack] name: packed\nTraceback (most recent call last):\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\monis\\AppData\\Local\\Temp\\ipykernel_9104\\3629012439.py\", line 13, in loadData\n    frames = loadVideo(videoPath)\n\n  File \"C:\\Users\\monis\\AppData\\Local\\Temp\\ipykernel_9104\\3629012439.py\", line 52, in loadVideo\n    mean = tf.math.reduce_mean(processedFrames, keepdims=True)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 7209, in raise_from_not_ok_status\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Pack_N_67_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [40,120,1] != values[19].shape = [40,1,120] [Op:Pack] name: packed\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) UNKNOWN:  InvalidArgumentError: {{function_node __wrapped__Pack_N_67_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [40,120,1] != values[19].shape = [40,1,120] [Op:Pack] name: packed\nTraceback (most recent call last):\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\monis\\AppData\\Local\\Temp\\ipykernel_9104\\3629012439.py\", line 13, in loadData\n    frames = loadVideo(videoPath)\n\n  File \"C:\\Users\\monis\\AppData\\Local\\Temp\\ipykernel_9104\\3629012439.py\", line 52, in loadVideo\n    mean = tf.math.reduce_mean(processedFrames, keepdims=True)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 7209, in raise_from_not_ok_status\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Pack_N_67_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [40,120,1] != values[19].shape = [40,1,120] [Op:Pack] name: packed\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_test_function_698881]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnknownError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m300\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mcheckpointCallback2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexampleCallback2\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     55\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mUnknownError\u001B[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  InvalidArgumentError: {{function_node __wrapped__Pack_N_67_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [40,120,1] != values[19].shape = [40,1,120] [Op:Pack] name: packed\nTraceback (most recent call last):\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\monis\\AppData\\Local\\Temp\\ipykernel_9104\\3629012439.py\", line 13, in loadData\n    frames = loadVideo(videoPath)\n\n  File \"C:\\Users\\monis\\AppData\\Local\\Temp\\ipykernel_9104\\3629012439.py\", line 52, in loadVideo\n    mean = tf.math.reduce_mean(processedFrames, keepdims=True)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 7209, in raise_from_not_ok_status\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Pack_N_67_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [40,120,1] != values[19].shape = [40,1,120] [Op:Pack] name: packed\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) UNKNOWN:  InvalidArgumentError: {{function_node __wrapped__Pack_N_67_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [40,120,1] != values[19].shape = [40,1,120] [Op:Pack] name: packed\nTraceback (most recent call last):\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\monis\\AppData\\Local\\Temp\\ipykernel_9104\\3629012439.py\", line 13, in loadData\n    frames = loadVideo(videoPath)\n\n  File \"C:\\Users\\monis\\AppData\\Local\\Temp\\ipykernel_9104\\3629012439.py\", line 52, in loadVideo\n    mean = tf.math.reduce_mean(processedFrames, keepdims=True)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 7209, in raise_from_not_ok_status\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Pack_N_67_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [40,120,1] != values[19].shape = [40,1,120] [Op:Pack] name: packed\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_test_function_698881]"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T04:06:15.938630Z",
     "start_time": "2024-07-04T19:24:26.520087Z"
    }
   },
   "cell_type": "code",
   "source": "model2.fit(train, validation_data=test, epochs=300, callbacks=[checkpointCallback2, exampleCallback2], use_multiprocessing=True)",
   "id": "df68abce0cca2684",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "Original: WE WORK TOGETHER REALLY WELL SO WE SHOULD BE ALL RIGHT WITH EACH OTHER\n",
      "Prediction: T HE WE ALY WLS O WO WOUD BE L RIGT WH HAHE OTHE\n",
      "Word Error Rate:  92.85714285714286%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS A TREMENDOUS RESPONSIBILITY\n",
      "Prediction: IS E TE N HE RE I\n",
      "Word Error Rate:  175.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEY WERE RELATIVELY LOW PAID AND THATS WHAT THEY HAD\n",
      "Prediction: IALE OE WAVE LOW PAD AN THATAS WAT HY HD\n",
      "Word Error Rate:  90.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I EXPECT YOU FORGOT\n",
      "Prediction: I ELD IN TIE I A\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 414s 2s/step - loss: 73.8189 - val_loss: 69.0065\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "Original: YOU KNOW SOMETHING\n",
      "Prediction: TE TNTHT\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: EXCEPT THAT THE AMERICANS WERE THINKING\n",
      "Prediction: BEPT THAT THE MARANS WE THINING\n",
      "Word Error Rate:  66.66666666666666%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I MADE AN EFFORT NOT TO SEE THESE FILMS\n",
      "Prediction: I MAE INE E FART OE TOE TOE THE MOLS\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I HAD A FRIEND WHO LIVED UP THERE AND IVE BEEN INVITED UP\n",
      "Prediction: I HAE FAIR AG S AE O OL L E TEI\n",
      "Word Error Rate:  92.3076923076923%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 427s 3s/step - loss: 74.1957 - val_loss: 65.4654\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "Original: LIKE A PIECE OF SCULPTURE\n",
      "Prediction: THE I A AE HELS\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: YOU GREW UP AMONG THE RICH AND THE FAMOUS\n",
      "Prediction: THE AS T O O A IN\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: TIME TRAVEL OR PARALLEL UNIVERSES\n",
      "Prediction: THM ARE OR PAL O ARS\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SO WERE TWO MONTHS INTO THE FINANCIAL YEAR\n",
      "Prediction: TH WAE AE HE AE TOT TIE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 441s 3s/step - loss: 69.1104 - val_loss: 67.6246\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "Original: THE SORT OF SANCTIONS YOU COULD LOOK AT ARE FINANCIAL SANCTIONS\n",
      "Prediction: THE SOR O ASTION OU CULD LO O A ARE INANCIN ACIN\n",
      "Word Error Rate:  90.9090909090909%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND BECAUSE IVE GOT SO MANY DIFFERENT BREEDS AND SPECIES ON THE FARM\n",
      "Prediction: AND BCUSE IVE OSO AY IN FE IN RED AETECIE HE FR\n",
      "Word Error Rate:  84.61538461538461%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ORGANISING PLANNING STAGES\n",
      "Prediction: IE THE INE POE T IEAS\n",
      "Word Error Rate:  200.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS MORE IMPORTANT WHAT HAPPENS IN THE HILLS AND THE CATCHMENT OF THE RIVERS\n",
      "Prediction: TE N NRNT THTHT OAN AIE THE ATAT HE TAT THE ON THE HERS\n",
      "Word Error Rate:  85.71428571428571%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 427s 3s/step - loss: 68.9389 - val_loss: 63.9215\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "Original: IM NOT SURE IF I CAN REMEMBER ANY OF HER FILMS\n",
      "Prediction: I OS OR I AE MEMBR ANOY O THR FILS\n",
      "Word Error Rate:  90.9090909090909%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEY WERE NEVER QUITE THE SAME WITHOUT HIM BECAUSE THE LEARINESS OF THE CARRY ON FILMS\n",
      "Prediction: THE WE EVE HIS THE SE E TAR TE HE AE T AE EVE THIE OE E TE E I M\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND WHEN THEY HAD CRUCIFIED HIM\n",
      "Prediction: WON HE THINY ADCFTHING HI\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: YOURE BEING MORBID AGAIN\n",
      "Prediction: BURE MIND A\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 430s 3s/step - loss: 68.0590 - val_loss: 61.7289\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "Original: AS LONG AS YOUVE GOT A FOOD PROCESSOR\n",
      "Prediction: I O I IN O O ON I AND\n",
      "Word Error Rate:  112.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: TOMORROW YOU PUT OUT NORMAL FOOD\n",
      "Prediction: IOROW YOU PUT OUT OM MOU WOIN\n",
      "Word Error Rate:  66.66666666666666%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE COUPLE MARRIED LAST YEAR IN HIS HOME TOWN OF DUNBLANE\n",
      "Prediction: AND BOUE E E AE E EN N TA TAT HR OR MAND\n",
      "Word Error Rate:  118.18181818181819%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: TO PLAY THE GAME\n",
      "Prediction: TH WAT TAY GAE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 439s 3s/step - loss: 67.0291 - val_loss: 58.0618\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "Original: YOU NEED TO BUY A COUNTRYFILE CALENDAR\n",
      "Prediction: IO HE TO BUY A COUTR ILE CALDAR\n",
      "Word Error Rate:  71.42857142857143%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WOULD HAVE BEEN VERY NICE\n",
      "Prediction: WHUD HE BEVE ERY ICE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: INSTEAD OF STARING INTENTLY AT INDIVIDUAL OBJECTS\n",
      "Prediction: INSTED OF SAE INE AETE EGA TEND DOIEIN AN I\n",
      "Word Error Rate:  128.57142857142858%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I DONT THINK THEY ARE GOING TO USE THIS BED VERY OFTEN ANYWAY\n",
      "Prediction: IO WUT THIN THE TO OIG U TIE AS HE OIO O\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 438s 3s/step - loss: 65.2952 - val_loss: 59.6534\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "Original: BUT WE FEEL REALLY CONFIDENT THIS IS JUST THE BEGINNING AND\n",
      "Prediction: BUT WE FE RELY CONFIDET THIS IS JUT THE BINING AND\n",
      "Word Error Rate:  45.45454545454545%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: EVERY CHANCE YOU GET\n",
      "Prediction: I ATE S ANE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: OR THE CHANGES IN DATES\n",
      "Prediction: WOE HE TOE TR HIE AE\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND FOR THOSE DIED ON THE EXPEDITION\n",
      "Prediction: THE COE POREAL TOIT TI TI IR\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 432s 3s/step - loss: 67.6416 - val_loss: 59.7625\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "Original: THANK YOU SO MUCH FOR WATCHING\n",
      "Prediction: THNK YOU O MUNE FOR WATHING\n",
      "Word Error Rate:  66.66666666666666%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I THINK THERES STILL HUGE RESPECT FOR THE POPPY\n",
      "Prediction: I THIN THES TIL OTO O OE WO\n",
      "Word Error Rate:  88.88888888888889%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND THEY ARE REALLY ROUGH AND READY\n",
      "Prediction: WHE WAE WE WE E O O\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BECAUSE HES ONLY TWENTY FOUR\n",
      "Prediction: I AS ES TO ON FOF WIFU\n",
      "Word Error Rate:  140.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 430s 3s/step - loss: 63.9929 - val_loss: 55.9815\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "Original: HE MADE ANITA PRACTISE ALL THE ROMANTIC MOVES AGAIN AND AGAIN AND AGAIN\n",
      "Prediction: HE MADE ANT PRACTISE AL THE RMANTIN MOVES AGIN AND AGAIN AND AGAIN\n",
      "Word Error Rate:  30.76923076923077%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: HE DROVE DIGGER NUMBER THREE\n",
      "Prediction: I E I TOE TOTO OIN\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: DONT COMPROMISE ON QUALITY\n",
      "Prediction: THT HAE TOTAS AUAITI\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: EGYPT WAS BOUTROS BOUTROS GHALI\n",
      "Prediction: EY PIT WAS BUS SHA BAS A AL\n",
      "Word Error Rate:  140.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 408s 2s/step - loss: 61.1278 - val_loss: 57.2049\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "Original: THERE ARE OTHER THINGS LIKE THE MOON GOING IN FRONT OF PARTICULAR STAR\n",
      "Prediction: THE RE A THE THINS IK THE OE ONG IN FON OF TACRLS TAT\n",
      "Word Error Rate:  84.61538461538461%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WE ARE HERE TO CONTACT LONDON\n",
      "Prediction: WO AE OE ANE E TALN\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I REALLY DIDNT KNOW WHAT IT WAS\n",
      "Prediction: TE ALY WED WON WH T WAS\n",
      "Word Error Rate:  85.71428571428571%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IM A RETIRED SHOP MANAGER\n",
      "Prediction: IS E I IS O PE EN\n",
      "Word Error Rate:  140.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 401s 2s/step - loss: 61.5224 - val_loss: 54.4856\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "Original: THIS LOT ARE COMING UP LATER ON IN THE SHOW\n",
      "Prediction: THIS LOT AR COING U PARE ON IN THE HO\n",
      "Word Error Rate:  50.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: JUST LOOK AT THAT\n",
      "Prediction: JUS LOK AT THAT\n",
      "Word Error Rate:  50.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BUT TO BE HONEST\n",
      "Prediction: BUT TO BE ONEST\n",
      "Word Error Rate:  25.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THERE ARE VERY FEW PEOPLE THAT WILL ASK\n",
      "Prediction: ID WAE IE IEDOR WE TIE AE I AT\n",
      "Word Error Rate:  112.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 401s 2s/step - loss: 59.6702 - val_loss: 51.7562\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 1s 930ms/step\n",
      "Original: THIS ONE SOUNDS LIKE TROUBLE\n",
      "Prediction: THE ION SONSDUD IE TRBLE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SHE WAS CONVICTED OF TWENTY THREE OFFENCES\n",
      "Prediction: SHE WAS CONVCTED OF TWENTY THRE OFES\n",
      "Word Error Rate:  42.857142857142854%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I NEED TO PULL MY SOCKS UP\n",
      "Prediction: I E TOE OL LESOK \n",
      "Word Error Rate:  85.71428571428571%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ONE WAY OR ANOTHER\n",
      "Prediction: ON WAR ON AO\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 465s 3s/step - loss: 59.5873 - val_loss: 51.8762\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 1s 981ms/step\n",
      "Original: WHO WAS A BIT OF A BLACK SHEEP\n",
      "Prediction: S O A BE HE HE U\n",
      "Word Error Rate:  87.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: NOT ONLY WILL I COMPOSE A LETTER\n",
      "Prediction: IH E THE O O O E TAR\n",
      "Word Error Rate:  114.28571428571428%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS JUST FOR FUN\n",
      "Prediction: IS JUS FOR FOUH\n",
      "Word Error Rate:  75.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: NOW IF WE EXAMINE IT\n",
      "Prediction: AN LN OE TAE IE LI IT\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 998s 6s/step - loss: 59.8755 - val_loss: 50.1724\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 434ms/step\n",
      "Original: IT ALSO REPRESENTS A BRAND NEW WAY OF LIFE\n",
      "Prediction: IT ALSO REPRESENTS A BRAND NEW WAY OF LIF\n",
      "Word Error Rate:  11.11111111111111%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS TIME FOR THE FINAL ROUND WHICH\n",
      "Prediction: INS IME FOAE H IAL OU HICH\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: COS WE DONT DO NINETY\n",
      "Prediction: IH I E O E A\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: OR ASK A MEMBER OF STAFF\n",
      "Prediction: A ASA E THE TE FOTE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 758s 4s/step - loss: 56.8752 - val_loss: 51.1354\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "Original: ONE SET OF STALLS IS DESIGNATED THE KINGS\n",
      "Prediction: TE A AN AN AE INE ON\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SO WE KNEW IT WOULD HAVE TO BE TOTALLY\n",
      "Prediction: SOE ENE IT WOULD HAVE TO BE TOTALY\n",
      "Word Error Rate:  44.44444444444444%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BELIEVE IT OR NOT\n",
      "Prediction: TE OR O MANE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEY WONT MOVE VERY EASILY\n",
      "Prediction: THE WAD TOE ERY EAN SISY\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 511s 3s/step - loss: 56.7776 - val_loss: 50.8201\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "Original: BUT I WANT YOU TO TALK TO HIM\n",
      "Prediction: BUT I WANT YOU TO TALK TO HIM\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND A GREAT GUIDE PRICE\n",
      "Prediction: AND A GREAT GUID PRIE\n",
      "Word Error Rate:  40.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IT COULD HAPPEN TOMORROW\n",
      "Prediction: I AN HUE TON BR BIBES INS\n",
      "Word Error Rate:  175.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND WE REFORMULATED OUR PRODUCTS\n",
      "Prediction: AND OD WA IR FOML TAT N OU UT AUIT\n",
      "Word Error Rate:  180.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 422s 2s/step - loss: 58.0112 - val_loss: 47.2052\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "Original: BEING ABLE TO ACCEPT\n",
      "Prediction: BEING ALE TO ACET\n",
      "Word Error Rate:  50.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE MORE MONEY THEY EARN\n",
      "Prediction: TOE ETE THETHE EARN\n",
      "Word Error Rate:  80.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WE GET THIS FUSION TO HAPPEN\n",
      "Prediction: BE E THE TE BINE AS\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SHE HAS WANDERED OFF\n",
      "Prediction: WE O INOE OD\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 419s 2s/step - loss: 56.7296 - val_loss: 48.1450\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "Original: MY FAVOURITE ONE\n",
      "Prediction: MY FAVOUTIT ONE\n",
      "Word Error Rate:  33.33333333333333%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: VERY FINE INDEED\n",
      "Prediction: IE E E ED\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEN IT WONT HAPPEN TO YOU AGAIN\n",
      "Prediction: THE IN WOT HAP PEN TO YOU AIN\n",
      "Word Error Rate:  85.71428571428571%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BUTTERFLY IS ACTUALLY THE HARDEST STROKE\n",
      "Prediction: I IT I IT TOT THE HAND S TOKE\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 436s 3s/step - loss: 56.5441 - val_loss: 45.6214\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "Original: WHO WENT AROUND ON THEIR HANDS AND KNEES\n",
      "Prediction: WHO WANT AUND ON THER HANDS AND KNE\n",
      "Word Error Rate:  50.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IN THE SENSE THAT THEYRE IN PRISON\n",
      "Prediction: IN THE SESE THAT THEYRE IN PRISON\n",
      "Word Error Rate:  14.285714285714285%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND THE BIBLE DEFINITELY COMES DOWN HARD ON THAT\n",
      "Prediction: T I O O TH MT A AE A HINT\n",
      "Word Error Rate:  111.11111111111111%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WELL BE IN HAMPSHIRE WHERE MATT WILL BE TAKING A TRIP ALONG THE NEWLY ESTABLISHED SHIPWRIGHTS WAY\n",
      "Prediction: TI COND H SHI IE MIE IE WIT OIT IME I A TI LOG THE WELY SBLSHED SHIPRIGHTS WAY\n",
      "Word Error Rate:  94.11764705882352%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 426s 2s/step - loss: 54.3191 - val_loss: 48.6068\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "Original: NO MATTER WHERE YOU ARE IN THE BRITISH COUNTRYSIDE\n",
      "Prediction: I HANTHE HOR HE WAR IN O HENE U TU ID CI\n",
      "Word Error Rate:  122.22222222222223%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THAT DOMINATED THE LANDSCAPE\n",
      "Prediction: IE OEAS A A\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: YOU HAVE A BRAIN ANEURYSM\n",
      "Prediction: BUL ID HIERIN AE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IF YOU WANT TO MAKE PROFITS\n",
      "Prediction: WHE AE THOE END I\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 425s 2s/step - loss: 52.2383 - val_loss: 46.1892\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "Original: AND THAT WAS A MUCH GREATER DISTRACTION\n",
      "Prediction: A TAT WAS A UH GEATEDISRACTON\n",
      "Word Error Rate:  71.42857142857143%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: TURNS UP WHEN SHE SAYS SHE WILL\n",
      "Prediction: TE IE IS SHE S I\n",
      "Word Error Rate:  85.71428571428571%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IVE WALKED UP ON A FEW FROM TIME TO TIME\n",
      "Prediction: IE AS E O O N ENE AT MA\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I WOULD SAY IF YOU GOT HIM TO LIST HIS OWN PERSONAL QUALITIES\n",
      "Prediction: AN HERE SOT A YOU GORE THONS IUTE BAE AE AE U ANT\n",
      "Word Error Rate:  92.3076923076923%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 430s 3s/step - loss: 53.0754 - val_loss: 48.1330\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "Original: DOZENS HAVE BEEN HURT\n",
      "Prediction: DOZENS HE HEN HE HRT\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I DONT THINK SO AT ALL\n",
      "Prediction: ID WIE IN IN HIE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: HIS PARISH PRIEST ASKED HIM\n",
      "Prediction: HIS PARIST ARIE A I HEMI\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AS WE SAY LOCALLY\n",
      "Prediction: I O HE IE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 576s 3s/step - loss: 55.3507 - val_loss: 61.6301\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "Original: ITS THAT SIMPLE\n",
      "Prediction: IS THAT TIMPLE\n",
      "Word Error Rate:  66.66666666666666%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: LOCATION AND PRICE\n",
      "Prediction: IE IN \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I WAS ABLE TO GIVE THE PHOTOGRAPH OF THE PAINTING TO JUAN GARCIA\n",
      "Prediction: I WA TH ONS TOS ANE AT RED D ROINE\n",
      "Word Error Rate:  92.3076923076923%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: MY NAME IS RICHARD\n",
      "Prediction: IMY GE TIS THANGHE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 539s 3s/step - loss: 56.1330 - val_loss: 47.3022\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "Original: YOUR CHILD IS FOR YOUR CHILD TO HAVE A PROSPEROUS AND GOOD\n",
      "Prediction: YOUR HILD IS FOR YOUR CHILD TO HAVE A PROSPEROUS AND GOD\n",
      "Word Error Rate:  16.666666666666664%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS ANOTHER INSECT\n",
      "Prediction: ITS ANTHERE SOSES\n",
      "Word Error Rate:  66.66666666666666%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SOMETHING LIKE THIS\n",
      "Prediction: SOETHNG ILE THIS\n",
      "Word Error Rate:  66.66666666666666%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHETHER YOU LOVE OR LOATHE CICADAS\n",
      "Prediction: THE OR YOU LOVE TO WH THA WA\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 448s 3s/step - loss: 51.0956 - val_loss: 44.6411\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "Original: YOU KNOW THE SCORE WHEN IT COMES TO FRIDAY\n",
      "Prediction: YOUR RA E AD IS O O O\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: NOW THAT MONSTER IS GRADUATING FROM THE NURSERY\n",
      "Prediction: AE E A E ER RARATING FOM THE INURSEY\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WE HAVE TO PAY FOR THAT\n",
      "Prediction: IHE HAVE TOT PAY FOR THAT\n",
      "Word Error Rate:  33.33333333333333%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: COULD YOU ACCOMMODATE ME\n",
      "Prediction: COULD YOU ACOE\n",
      "Word Error Rate:  50.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 436s 3s/step - loss: 49.7003 - val_loss: 39.3508\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "Original: I GOT IT THE WRONG WAY ROUND\n",
      "Prediction: I E OR TA I\n",
      "Word Error Rate:  85.71428571428571%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THERES LOTS OF SMALLER\n",
      "Prediction: TH O O TO TOR\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: FEELING REALLY CRAZY RECENTLY\n",
      "Prediction: FELING REALY CAZY RECENTHEY INT\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: HES BAKING BREAD\n",
      "Prediction: THE BAIND BE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 440s 3s/step - loss: 50.2252 - val_loss: 41.9876\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "Original: WHEN I WAS ABOUT EIGHT OR NINE\n",
      "Prediction: WHEN I WAS ABOUT EIGHT OR NINE\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IT WAS NOT A HOTEL\n",
      "Prediction: WO WO AT HOTEL\n",
      "Word Error Rate:  80.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BUT IVE NEVER SEEN ONE THAT ACTUALLY GRAPHICALLY SHOWS AN INJURY\n",
      "Prediction: IEVS OE T FAT THE ARAV ANGURY\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IT WAS US AGAINST THE REST\n",
      "Prediction: I IS O O AI R\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 455s 3s/step - loss: 48.8946 - val_loss: 39.4741\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "Original: CALLED THE WILD WILD WEST\n",
      "Prediction: I WE WILD WILD WEST\n",
      "Word Error Rate:  40.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND THEN STEP BACK\n",
      "Prediction: TEA TN POP PANCK\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND THAT WAS MORE THAN TWENTY YEARS AGO\n",
      "Prediction: AE T IS O O THOY THONY BOR TIE\n",
      "Word Error Rate:  112.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IT MAKES A GREAT NOISE\n",
      "Prediction: THE AT N R A HAE\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 540s 3s/step - loss: 49.4445 - val_loss: 40.4464\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "Original: ITS GETTING TOO HOT IN THE MEDITERRANEAN AND THE WEATHERS BECOMING MORE SUITABLE OVER HERE\n",
      "Prediction: T IT TIT O O E THE AE AE AN INE THE THAT HES HEMEMING MOE TUSLE OE THE HE\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: GULPING FOR AIR\n",
      "Prediction: WHA A AN O IR\n",
      "Word Error Rate:  166.66666666666669%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THROUGHOUT EVAS LONG WIDOWHOOD\n",
      "Prediction: IH HA GOUGH ASASE ON THE HIN WAR WAHE\n",
      "Word Error Rate:  225.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IM HOPING TO CATCH A GLIMPSE OF THEM LATER THROUGH DAVES TELESCOPE\n",
      "Prediction: THM ANS SITIM TATRHY HAY WON H FOU HAN TAN HAS\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 645s 4s/step - loss: 48.5145 - val_loss: 43.4580\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "Original: LIFE IS NOT ABOUT WHERE YOU ARE\n",
      "Prediction: THE OS O WA AU WHERE YOU ARE\n",
      "Word Error Rate:  71.42857142857143%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND WE WORK WITH THE US MILITARY\n",
      "Prediction: AND WE WORK WITH THE U THA TO ORE\n",
      "Word Error Rate:  57.14285714285714%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: NOT ONLY DID THEY CONSTRUCT FINE TIMBER FRAMED BUILDINGS\n",
      "Prediction: WND OE I THE MOU CITI ITOTRAED BUILDINGS\n",
      "Word Error Rate:  88.88888888888889%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IN THE HAM DRAM\n",
      "Prediction: IHE E THATRAM\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 431s 3s/step - loss: 48.3959 - val_loss: 41.6570\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Original: ITS ABOUT THE LITTLE PEOPLE\n",
      "Prediction: IS BOUT THE LITLE PEPLE\n",
      "Word Error Rate:  80.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BUT IN MY OPINION\n",
      "Prediction: BE E BE BECHE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS GOT THE BASICS HERE\n",
      "Prediction: ITS GOT THE BASICS HERE\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THATS WHAT THE SALEROOMS ALL ABOUT ANYTHING CAN HAPPEN\n",
      "Prediction: THAS WHA THESE ON RANDOUS ONT HIN A\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 384s 2s/step - loss: 47.6308 - val_loss: 42.0322\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "Original: CHARLES WAS NOW CLUTCHING AT STRAWS\n",
      "Prediction: CHARLES WAS NOW CLUTCHING AT TRS\n",
      "Word Error Rate:  16.666666666666664%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: MINUS FIFTEEN ON THAT\n",
      "Prediction: IO O O O O TO\n",
      "Word Error Rate:  150.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: MY MOTHER ONCE WENT OUT WITH A\n",
      "Prediction: THO ASOE WOL RIG HU HICS\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THESE GUYS HAVE MEMORIES OF THE DAY THEY BUILT AN EXTENSION SOMEWHERE IN GLOUCESTER\n",
      "Prediction: THE HAE SAE MORIE TOL BOE THATE TORE ALINE HAR THISIE TN THES SOIN\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 390s 2s/step - loss: 47.3794 - val_loss: 39.3162\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "Original: I DONT THINK WE CAN USE THEM\n",
      "Prediction: IT THT WIT HE THE TE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE QUESTIONS ARE ALL GENERAL KNOWLEDGE\n",
      "Prediction: THE QUESTINS ARE AL GERAL KOLEDE\n",
      "Word Error Rate:  66.66666666666666%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: YOU THROW IT IN THE OVEN A COUPLE OF HOURS\n",
      "Prediction: WO THENE SIOIN IND OF CALE BOUAOAT\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND SO WE SAT DOWN HERE WITH JAMES ODONNELL TO TALK ABOUT MUSIC\n",
      "Prediction: NE ITH WAY THOR WO TH L TO AMS ON THEM TOURE TOI INS THOIN BHE\n",
      "Word Error Rate:  123.07692307692308%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 406s 2s/step - loss: 48.9632 - val_loss: 40.2590\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Original: RAYMOND SAYS ITS RELATIVELY SIMPLE AND HE STARTS THIS RECIPE BY CHOOSING THE PERFECT\n",
      "Prediction: RAYMOND SAY ITS RELATIVELY SIMPLE AND HE STARTS THIS RECIPE BY CHOSIN THE PERCT\n",
      "Word Error Rate:  21.428571428571427%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I DO BELIEVE ITS NOW THAT PART OF THE SHOW WHERE I WELCOME A TRIO OF HIGHLY ESTEEMED EXPERTS TO\n",
      "Prediction: IE O N O OND HERE TEINE O AR O I TBI A I RAL OD ON TO FOUCIE HA TES TE SE N\n",
      "Word Error Rate:  114.99999999999999%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I DONT HAVE TIME\n",
      "Prediction: I I TIN TOR AINTE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IF YOUVE GOT ANY UNLOVED TOYS YOU WANT TO SELL OR ANY OTHER ANTIQUES OR COLLECTABLES FOR THAT\n",
      "Prediction: WN DOUD A OR AY AN THOR OR ROS WANE BAS OE HE AN DOT O SON IOR O ENY HON T AETON\n",
      "Word Error Rate:  127.77777777777777%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 423s 2s/step - loss: 47.8285 - val_loss: 41.4681\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "Original: ALL REALLY NICE AND IN KEEPING\n",
      "Prediction: A L E AND AN KEPING\n",
      "Word Error Rate:  83.33333333333334%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ABOUT FIVE OCLOCK\n",
      "Prediction: BU TOT O JOURE THE\n",
      "Word Error Rate:  166.66666666666669%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE COUNTRY IS UNITED BEHIND SUPPORTING THE ARMED FORCES\n",
      "Prediction: THE COUNTRY IS UND TE AE HAE OU RETY THIE AOMED O RECE\n",
      "Word Error Rate:  111.11111111111111%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THANKS FOR WATCHING\n",
      "Prediction: INTH CECE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 457s 3s/step - loss: 48.4489 - val_loss: 44.0694\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "Original: FROM AN ENVIRONMENTAL STANDPOINT\n",
      "Prediction: FROM AN ENVROMENTAL STANDPOINT\n",
      "Word Error Rate:  25.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHICH WE WILL TALK ABOUT\n",
      "Prediction: WHICE WE WIL TAL ABOUT\n",
      "Word Error Rate:  60.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHEN I WAS WRITING THE BOOK\n",
      "Prediction: WHE I WAS WRITING THE BOK\n",
      "Word Error Rate:  33.33333333333333%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: HISTORY WAS THE ONE SUBJECT I FEARED AND LOATHED THE MOST\n",
      "Prediction: HES THE WOAR WETE E OE SBJET I FEARED AND THA THE THE MST\n",
      "Word Error Rate:  90.9090909090909%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 428s 3s/step - loss: 56.5531 - val_loss: 44.1670\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "Original: FOLLOWING THAT DAY\n",
      "Prediction: FOLOWING THAT DY\n",
      "Word Error Rate:  66.66666666666666%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IM YOUR SIMON COWELL\n",
      "Prediction: IM YOUR SIMON COWEL\n",
      "Word Error Rate:  25.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHEN YOU FELL OVER\n",
      "Prediction: WHEN YOU OF CIT\n",
      "Word Error Rate:  50.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IM FOREVER THE OPTIMIST AND MY GLASS IS USUALLY HALF FULL\n",
      "Prediction: HE HARE M FIRA AS SRSES FIS TIM I F\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 409s 2s/step - loss: 45.6469 - val_loss: 40.4625\n",
      "Epoch 39/300\n",
      "171/171 [==============================] - ETA: 0s - loss: 45.9973[' ', \"THEY'RE\", ' ', 'VERY', ' ', 'DEFINITE', ' ', 'ABOUT', ' ', 'WHAT', ' ', 'THEY', ' ', \"DON'T\", ' ', 'LIKE']\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "Original: IN A MOMENT OF CARELESS ABANDON\n",
      "Prediction: IE MOE OPAEALBEBAON\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SO ITS AGAINST ISLAMIC LAW\n",
      "Prediction: SO IS AGINS ISAMIC LAW\n",
      "Word Error Rate:  60.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: A LOT OF COLLECTIONS DO\n",
      "Prediction: IV O A FO ON FO TOS O ORE\n",
      "Word Error Rate:  160.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WED LOVE TO SEE YOU\n",
      "Prediction: I O A THAT O\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 428s 3s/step - loss: 45.9973 - val_loss: 37.5186\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "Original: IM SIXTY THREE AND IM A MASTERPOINT ADMINISTRATOR\n",
      "Prediction: IM SIXTY TRE AND M A MASTERPOINT ADMINISTRATOR\n",
      "Word Error Rate:  25.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THERE IS COMMISSION TO PAY\n",
      "Prediction: THERE IS MAME INT OE A\n",
      "Word Error Rate:  80.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THERE YOU GET NOT ALL OF THE HEAT OF IT\n",
      "Prediction: INS A IN OE HE AY HASE WOINT ONM\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND WAS QUITE ABLE\n",
      "Prediction: I HAS TON THAS OF FANS WA TOY \n",
      "Word Error Rate:  200.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 430s 3s/step - loss: 45.6333 - val_loss: 43.1461\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "Original: SO YOU KNOW WHO HE REALLY IS\n",
      "Prediction: SO YOU KNOW WHO HE RALY IS\n",
      "Word Error Rate:  14.285714285714285%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IM GOING TO SHOOT YOU WITH MY\n",
      "Prediction: I MOS OS SHO OU TITH\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BECAUSE I PROMISED I WOULDNT\n",
      "Prediction: THE IE O\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IS ACTUALLY NOT JUST TO DO WITH THE WHITE\n",
      "Prediction: TE AT BOT JAST TOR O WITH THE WHIE\n",
      "Word Error Rate:  77.77777777777779%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 445s 3s/step - loss: 43.7386 - val_loss: 38.1134\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "Original: THE BALL SHAPED ONE\n",
      "Prediction: THE BAL SHAPED ONE\n",
      "Word Error Rate:  25.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: TRADITIONAL THREE BEDROOM\n",
      "Prediction: TADITIONAL THRE BEDOM\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEN WE SHOULD BE A PRETTY FIT NATION\n",
      "Prediction: THEN WE SHOU AN HE EA TA I FIT CICEON\n",
      "Word Error Rate:  87.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: CRUNCHY LETTUCE BUT\n",
      "Prediction: COUT O HE HNM\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 424s 2s/step - loss: 44.1780 - val_loss: 37.0782\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "Original: THERES THINGS LIKE WATER PRESSURE\n",
      "Prediction: THTO HING LIKE ATER PRESURE\n",
      "Word Error Rate:  80.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: COURTESY OF JOHN AND JOSEPHINE BOWES\n",
      "Prediction: COURTESY OF JON AND JOSEPHINE BOWES\n",
      "Word Error Rate:  16.666666666666664%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SO MANY QUESTIONS\n",
      "Prediction: S MANY QUESTIT IN\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: INSTEAD OF A CHICKEN BURRITO\n",
      "Prediction: IE TED OF AY THINGURS\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 430s 3s/step - loss: 45.4828 - val_loss: 34.9888\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "Original: I THINK IT WAS THE CROP SPRAYER\n",
      "Prediction: I THINK IT WAS THE CROP PRAYEY\n",
      "Word Error Rate:  14.285714285714285%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IN A WORLD FIRST\n",
      "Prediction: IN A WORLD FIRST\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE COUPLE WHO LAY IN THEIR CRASHED CAR FOR THREE DAYS BEFORE POLICE CAME TO HELP JOHN YUILL DIED\n",
      "Prediction: THE OUPE WI TA BUY CIE BE BA SA E H BE BET TEY A O AN AD THE BIE IU OR IL FID\n",
      "Word Error Rate:  121.05263157894737%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IT AVERAGES MONEY OUT\n",
      "Prediction: TEN HUE TETRE TE TORTA\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 434s 3s/step - loss: 43.1274 - val_loss: 41.3066\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "Original: THE PERCEPTION THAT STRAIGHT RIVERS WAS A CONTROLLED ENVIRONMENT\n",
      "Prediction: THE PERETON THAT TRAIGHT RIVERS WAS A CONTROLED ENVIRONMENT\n",
      "Word Error Rate:  33.33333333333333%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: PARTICULARLY THE MALES\n",
      "Prediction: WOE TE THE E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ACCORDING TO STRONG\n",
      "Prediction: TH RAN R A TON\n",
      "Word Error Rate:  166.66666666666669%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: HERE ARE THE SCI FI FOOTBALL RESULTS\n",
      "Prediction: HERE TE TOSCIG I FOL EULTS\n",
      "Word Error Rate:  85.71428571428571%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 443s 3s/step - loss: 44.7056 - val_loss: 34.8340\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "Original: THATS WHERE QUEEN VICTORIA WOULD ARRIVE BY HORSE DRAWN CARRIAGE\n",
      "Prediction: THATS WHERE QUEN ICTORI WOULD ARIVE BY HORSE DRAWN CARIAGE\n",
      "Word Error Rate:  40.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THAT THEY WERE PREPARED TO DRIVE\n",
      "Prediction: THAT THEY WERE PREPARED O TO LIVE\n",
      "Word Error Rate:  33.33333333333333%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original:  SMOKERS GAVE UP THE HABIT WITHIN THE FIRST NINE MONTHS AFTER THE BAN\n",
      "Prediction: I IS ETETE OUPE TH HABT WIT THI THE FIRST NINE MONTHES FOFTER THE BIN\n",
      "Word Error Rate:  84.61538461538461%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THOUSANDS OF POUNDS\n",
      "Prediction: TE IT I T IND\n",
      "Word Error Rate:  166.66666666666669%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 397s 2s/step - loss: 45.0243 - val_loss: 33.5757\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "Original: CAMPERS HI DE HI\n",
      "Prediction: I I I\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND THE STREETS ARE FEATURED IN NUMEROUS FILMS\n",
      "Prediction: AND THE STRETS ARE FEATURED IN NUMEROUS FILMS\n",
      "Word Error Rate:  12.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SO WE JUST LIKE TO GO AND EXPERIENCE A LOT OF THE OLD MEDIEVAL HISTORY AND GO TO THE CASTLES WHEN\n",
      "Prediction: TO E T E TA BIMGE OANE OILE OME ORE SRERE RAME MAIE O IS OREME TER ONA TVE O CS\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BUT THEY DID HAVE A DREAM AND WHETHER THAT DREAM HAS BEEN REALISED AND THE GARDEN MADE\n",
      "Prediction: MITH I HEINE AL U WAEAN ONW THE HAT REAM HAS ENE N HOREANSISED AND HRED DENE MADE\n",
      "Word Error Rate:  88.23529411764706%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 380s 2s/step - loss: 42.6197 - val_loss: 37.9435\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "Original: WHAT PORSCHE DO IS\n",
      "Prediction: WHA O SOESOE ESI\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: HAVING PREVIOUSLY BORNE EIGHT CHILDREN TO HER FIRST HUSBAND\n",
      "Prediction: HAVING PREVIOUSLY BORNE EIGHT CHILDREN TO HER FIS TOT THIN IE\n",
      "Word Error Rate:  44.44444444444444%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THERE HAVE BEEN A FEW DISAGREEMENTS\n",
      "Prediction: THR RE HAVE BE FEW DOSMURETOWL\n",
      "Word Error Rate:  83.33333333333334%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SO MUCH OF IT WAS FORGOTTEN ABOUT\n",
      "Prediction: SO MURT POAT AT HO RANT OA WAT\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 390s 2s/step - loss: 42.8801 - val_loss: 39.2661\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "Original: LITERALLY MILLIONS OF BIKES BEING CHURNED OUT IN THE LOCAL INDUSTRIES HAD TO BE DECORATED\n",
      "Prediction: LITERALY MILIONS OF BIKES BEING CHURNED OUT HE TOF A A BF FOR TAI AE A SORATHED\n",
      "Word Error Rate:  80.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AS OF ABOUT THREE MONTHS AGO\n",
      "Prediction: AT O TOT THE THN SOS AGO\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: TOGETHER REALLY GREY\n",
      "Prediction: WIE HAE A HA E\n",
      "Word Error Rate:  166.66666666666669%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: MAYBE SOME PEOPLE SAY\n",
      "Prediction: TERE MOE MOS\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 435s 3s/step - loss: 42.8387 - val_loss: 37.0666\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "Original: IT LOOKS A LOT MORE\n",
      "Prediction: IT LOKS A LOT MORE\n",
      "Word Error Rate:  20.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IF THIS WAS PAINTED ON OAK\n",
      "Prediction: I WOS IS IN O TO THE AIN\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IT WAS A PROFITABLE NIGHT FOR DRAKE\n",
      "Prediction: IT WAS A POITAL IG SAR FORAKE\n",
      "Word Error Rate:  57.14285714285714%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ONE OR TWO IDEAS\n",
      "Prediction: TO O TE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 383s 2s/step - loss: 40.7751 - val_loss: 34.4482\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Original: THEY GET TWO MINUTES EACH FOR THE FIRST ROUND AND THEN TWO AND A HALF OF THE SECOND\n",
      "Prediction: THEY GET TWO MINTES ACH FOR THE FIRST ROND AND THEN TWO AND A HAL OF THES SECON\n",
      "Word Error Rate:  33.33333333333333%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHEN I SAW THEIR QUITE SIMPLE SHAPE AND THE VIBRANT COLOURS\n",
      "Prediction: WER IS AE OE LO ORSINE PORE AON E IT IA A LOUR TRTITI\n",
      "Word Error Rate:  127.27272727272727%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THIS COLLECTABLE IS MADE BY THE ALUM BAY GLASS COMPANY\n",
      "Prediction: THE ALECTABLE BIE SDUS TOIT AS TUL MA CA AIS SHUS SH PANY\n",
      "Word Error Rate:  130.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS ALWAYS GOING TO BE SLIGHTLY MORE EXPENSIVE THAN THE BIG BOYS\n",
      "Prediction: TIVISBORE WE WING ION AR TINS LORE AR WIVE ON THO HIGE OI\n",
      "Word Error Rate:  108.33333333333333%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 378s 2s/step - loss: 42.2421 - val_loss: 36.0438\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Original: THEY ALREADY HAVE THIS\n",
      "Prediction: THEY ALREADY HAVE THIS\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SO I WAS OFF FOR THREE WEEKS\n",
      "Prediction: SO I WAS OF FOR THRE WEKS\n",
      "Word Error Rate:  42.857142857142854%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SHOULD I UNPACK IT\n",
      "Prediction: SHOULD I UNT PINT TE A BE BTH\n",
      "Word Error Rate:  150.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IVE JUST BEEN JOINED BY MARION AND CHARLIE\n",
      "Prediction: HO WO MUS MAN MEMY BM MN MO BCANE\n",
      "Word Error Rate:  112.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 376s 2s/step - loss: 42.8588 - val_loss: 38.6728\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "Original: AND I THINK THIS IS ONE\n",
      "Prediction: AND I THINK THIS IS ONE\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: OF COURSE IT HAPPENS\n",
      "Prediction: OF COURSE IT HAPENS\n",
      "Word Error Rate:  25.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS NOT A STROKE\n",
      "Prediction: IN TOR\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SO IF A LITTLE BIT OF MONEY COMES IN THE BACK POCKET\n",
      "Prediction: IO LIVE IET OD DOMN O BOE THES TIT\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 380s 2s/step - loss: 40.2860 - val_loss: 34.2401\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "Original: HE STARTS TO SOB\n",
      "Prediction: THE E E O E\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: UNTIL YOU TAKE THE BOILER OFF\n",
      "Prediction: ANT TOU THAKETHE BOILER OF\n",
      "Word Error Rate:  83.33333333333334%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE FRENCH PEOPLE\n",
      "Prediction: THE E E E O\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THERE CERTAINLY WERE\n",
      "Prediction: I CE FIF THT\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 381s 2s/step - loss: 41.6180 - val_loss: 35.4706\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "Original: THEY USED TO HAVE THINGS CALLED TREPANNING SETS\n",
      "Prediction: THE HLE THE TOE THES S CALED TREPANING SETS\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WENT OFF TO WAR\n",
      "Prediction: WENT OF TO WA\n",
      "Word Error Rate:  50.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BUT IT ONLY UNDERLINES HOW MUCH MORE THERE IS TO KNOW ABOUT THIS COMPLEX SET OF DISEASES\n",
      "Prediction: WH R O AN ON O O E O O TO ON E E O TE E U INS OR E WINE I SETINE\n",
      "Word Error Rate:  135.29411764705884%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: GET BUYING AND HAVE SOME FUN WITH ANTIQUES\n",
      "Prediction: GE OUINGUDED YENS W WEN NS OI A BRS BUSE\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 378s 2s/step - loss: 39.5321 - val_loss: 37.6802\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Original: I WANT TO SEE THAT PROGRAMME\n",
      "Prediction: I WANT TO SE THAT PROGRAME\n",
      "Word Error Rate:  33.33333333333333%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: HE SHOULDNT HAVE BEEN AN OFFICER ACCORDING TO THE MANUAL OF MILITARY LAW\n",
      "Prediction: IHI I IN H HNG THE HU ANG HAIG I HI I\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND IT WAS AT THAT POINT THAT A YOUNG APPRENTICE DRAPER MOVED HERE FROM SURREY\n",
      "Prediction: AND IT WHAS AT THAT POINT THAT A YOUNG APRENTICE DRAPER MOVED HERE FOM SUREY\n",
      "Word Error Rate:  26.666666666666668%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND IF MEN CANT SEE THAT\n",
      "Prediction: I WOS S I MA\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 382s 2s/step - loss: 41.9447 - val_loss: 36.7577\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "Original: THIS AREA WAS SELECTED BECAUSE THERE WAS A HIGH DENSITY AT THAT TIME\n",
      "Prediction: THE AE AE AE CAUSE THER WAS A HIGH DENSIY AT THAT TIME\n",
      "Word Error Rate:  53.84615384615385%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BECAUSE IF WE DONT\n",
      "Prediction: AT ANAON\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: DRIVING MUM UP THE WALL\n",
      "Prediction: TE O E OAL\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE MYSTERY HOUSE WELL\n",
      "Prediction: TE E U LE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 377s 2s/step - loss: 40.1197 - val_loss: 31.7384\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "Original: WE WILL BE BACK TOMORROW AT A DIFFERENT TIME\n",
      "Prediction: WE WIL BE BACK TOMOROW AT A DIFERENT TIME\n",
      "Word Error Rate:  33.33333333333333%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IN THE BASEMENT\n",
      "Prediction: IN THE WIRE MENE\n",
      "Word Error Rate:  66.66666666666666%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WED LIKE TO AVOID LISTED BUILDINGS\n",
      "Prediction: WHE AS W WT A BL BO THERS\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: TO FIND OUT MORE\n",
      "Prediction: WO TO O\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 381s 2s/step - loss: 41.5688 - val_loss: 34.6823\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Original: VERY CLOSE TO THE MOTORWAY\n",
      "Prediction: WE ISE TO THE MORWAY\n",
      "Word Error Rate:  60.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ALAN TITCHMARSH MIGHT SAY SO\n",
      "Prediction: I AT THA AN O HAS SAS SO\n",
      "Word Error Rate:  140.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I CAN SPEND HOURS BROWSING IN AN AUCTION ROOM\n",
      "Prediction: I ANS HN ON TRORIN N AN ANINO\n",
      "Word Error Rate:  77.77777777777779%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WAS THIS DELIGHTFUL LITTLE TABLE\n",
      "Prediction: WE HE E THI TIT TITE EIL\n",
      "Word Error Rate:  140.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 379s 2s/step - loss: 40.4738 - val_loss: 34.7041\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "Original: WERE HAVING AN EARLY NIGHT\n",
      "Prediction: WHER HAING AN EARLY NIGHT\n",
      "Word Error Rate:  40.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: FOR A LONG TIME\n",
      "Prediction: FOR A LONG TIME\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHETHER ITS BEFORE OR AFTER\n",
      "Prediction: THE HE IS R A\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: YOU AND EVERYBODY ELSE WAS PAYING ME TO DO IT\n",
      "Prediction: BU AE A A A A A A I E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 381s 2s/step - loss: 43.0564 - val_loss: 33.5920\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "Original: MY WASHING MACHINES ON THE BLINK\n",
      "Prediction: FE WOND TORE WOE POULDIN ON\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS THERE TO BE WORN\n",
      "Prediction: IE IS E E A BE FON\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: NOW BEFORE WE HAND OVER THAT LEFTOVER LOLLY TO DAVID BARBY\n",
      "Prediction: WHE HVN AE ONE OTE E E ER TA IAD F\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE LOCAL PEOPLE WILL BE BETTER OFF BECAUSE THEYVE GOT MORE MONEY TO SPEND AND EVERYBODY IS HAPPY\n",
      "Prediction: BUS HRE ONE OP BL IPERE WE HOR TO RTONS O MA AS OBO BA\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 378s 2s/step - loss: 41.4368 - val_loss: 37.1639\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "Original: YOU LOOK AT THE REALITY IN THE COUNTRY\n",
      "Prediction: BH TATE E BABO O\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BECAUSE OF ALL OF THE DEMAND THAT HAS DEVELOPED\n",
      "Prediction: THE I I O TOE HE HE HE I\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IT DOESNT HAVE A GREAT FINANCIAL VALUE\n",
      "Prediction: CINT A ENTHAVE RIME AE MO T HR\n",
      "Word Error Rate:  114.28571428571428%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS VERY CLEAN\n",
      "Prediction: WH E THR N\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 382s 2s/step - loss: 40.2677 - val_loss: 34.3210\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "Original: IM FEELING RATHER CHILLY\n",
      "Prediction: IM FELING RATHER CHILY\n",
      "Word Error Rate:  50.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND THIS IS HOW THEY WERE TREATED\n",
      "Prediction: AND THIS IS HOW THEY WERE TREATED\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IM IN THE PROCESS OF DOING THAT\n",
      "Prediction: IM IN THE PROCES O TA ET\n",
      "Word Error Rate:  57.14285714285714%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEYRE VERY DEFINITE ABOUT WHAT THEY DONT LIKE\n",
      "Prediction: THER HA A TEY M L WORY WART AMLE O LINE\n",
      "Word Error Rate:  137.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 384s 2s/step - loss: 39.1131 - val_loss: 32.3845\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "Original: WANTED ME TO CHANGE THE DRESS\n",
      "Prediction: WANTED ME TO CHANGE THE DRES\n",
      "Word Error Rate:  16.666666666666664%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: NEW CAMPERS HELLO\n",
      "Prediction: SE CAPRS HELO\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: FOUR MORE CONTENDERS ARE ALL SET TO TAKE TO THE STAGE TONIGHT\n",
      "Prediction: FOURE TEO AE PTITS AME IT PTIRE TOT TA E TO TE TAG TONGIHT\n",
      "Word Error Rate:  108.33333333333333%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE ONE HE USED TO DISCOVER URANUS\n",
      "Prediction: THE ONE HE ESES TO DOST O WHE OR\n",
      "Word Error Rate:  71.42857142857143%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 386s 2s/step - loss: 40.6633 - val_loss: 35.7139\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "Original: FOR MOST OF THE AFTERNOON\n",
      "Prediction: I E O O ON\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I DONT THINK THAT IS THE CASE\n",
      "Prediction: I DONT THINK THAT IS THE CASE\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THIS IS OUT OF MY LEAGUE\n",
      "Prediction: I IM WON O FM EAY UE\n",
      "Word Error Rate:  116.66666666666667%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND HE WAS VERY DEVOTED TO HIS CHILDREN\n",
      "Prediction: AE AS TASHAS THERE O THISODE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 550s 3s/step - loss: 38.5595 - val_loss: 33.0496\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "Original: OUR ANIMALS ARE MOSTLY RARE BREED BECAUSE THEYRE SLOW GROWING\n",
      "Prediction: AE AE OR ORER R RE TE O ON\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND I REMEMBER THAT VERY VIVIDLY AS A CHILD\n",
      "Prediction: AND I REMEMBER TAT TORE O CAEDHGHAG CHA A OS\n",
      "Word Error Rate:  66.66666666666666%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS ONE OF THOSE THINGS\n",
      "Prediction: SHU D COUE AME TE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND A BEAUTIFUL MATURE GARDEN\n",
      "Prediction: AE AE TATER RAT ARER TREN\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 998s 6s/step - loss: 40.8730 - val_loss: 33.9806\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "Original: WHILE I WAIT TO ENJOY THE FRUITS OF MY LABOURS\n",
      "Prediction: WHILE I WAIT TO ENJOY THE FRUITS OF MY LABOURS\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: TRASHING THE PLACE\n",
      "Prediction: THASHING THE PLACE\n",
      "Word Error Rate:  33.33333333333333%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS JUST BEEN THROUGH AN OPEN MARKET AUCTION\n",
      "Prediction: IS JES TEN POEGE TOND OE NON NERERI\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: YOUR TIME HAS COME TO ENTER THE ST CENTURY IN A BIG WAY\n",
      "Prediction: IE THE ME TO I EIS BOS SU CENTURUT AY BEY\n",
      "Word Error Rate:  92.3076923076923%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 913s 5s/step - loss: 40.3670 - val_loss: 32.5551\n",
      "Epoch 68/300\n",
      "125/171 [====================>.........] - ETA: 4:23 - loss: 41.4991"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[33], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m300\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mcheckpointCallback2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexampleCallback2\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1570\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1568\u001B[0m logs \u001B[38;5;241m=\u001B[39m tmp_logs\n\u001B[0;32m   1569\u001B[0m end_step \u001B[38;5;241m=\u001B[39m step \u001B[38;5;241m+\u001B[39m data_handler\u001B[38;5;241m.\u001B[39mstep_increment\n\u001B[1;32m-> 1570\u001B[0m \u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_train_batch_end\u001B[49m\u001B[43m(\u001B[49m\u001B[43mend_step\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1571\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_training:\n\u001B[0;32m   1572\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:470\u001B[0m, in \u001B[0;36mCallbackList.on_train_batch_end\u001B[1;34m(self, batch, logs)\u001B[0m\n\u001B[0;32m    463\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001B[39;00m\n\u001B[0;32m    464\u001B[0m \n\u001B[0;32m    465\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m    466\u001B[0m \u001B[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001B[39;00m\n\u001B[0;32m    467\u001B[0m \u001B[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001B[39;00m\n\u001B[0;32m    468\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    469\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_call_train_batch_hooks:\n\u001B[1;32m--> 470\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_batch_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mModeKeys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTRAIN\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mend\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:317\u001B[0m, in \u001B[0;36mCallbackList._call_batch_hook\u001B[1;34m(self, mode, hook, batch, logs)\u001B[0m\n\u001B[0;32m    315\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_batch_begin_hook(mode, batch, logs)\n\u001B[0;32m    316\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m hook \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 317\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_batch_end_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    319\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    320\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized hook: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    321\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExpected values are [\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbegin\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    322\u001B[0m     )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:340\u001B[0m, in \u001B[0;36mCallbackList._call_batch_end_hook\u001B[1;34m(self, mode, batch, logs)\u001B[0m\n\u001B[0;32m    337\u001B[0m     batch_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_start_time\n\u001B[0;32m    338\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_times\u001B[38;5;241m.\u001B[39mappend(batch_time)\n\u001B[1;32m--> 340\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_batch_hook_helper\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhook_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    342\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_times) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_batches_for_timing_check:\n\u001B[0;32m    343\u001B[0m     end_hook_name \u001B[38;5;241m=\u001B[39m hook_name\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:388\u001B[0m, in \u001B[0;36mCallbackList._call_batch_hook_helper\u001B[1;34m(self, hook_name, batch, logs)\u001B[0m\n\u001B[0;32m    386\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m callback \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks:\n\u001B[0;32m    387\u001B[0m     hook \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(callback, hook_name)\n\u001B[1;32m--> 388\u001B[0m     \u001B[43mhook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    390\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_timing:\n\u001B[0;32m    391\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m hook_name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_hook_times:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:1081\u001B[0m, in \u001B[0;36mProgbarLogger.on_train_batch_end\u001B[1;34m(self, batch, logs)\u001B[0m\n\u001B[0;32m   1080\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mon_train_batch_end\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch, logs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m-> 1081\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_batch_update_progbar\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:1158\u001B[0m, in \u001B[0;36mProgbarLogger._batch_update_progbar\u001B[1;34m(self, batch, logs)\u001B[0m\n\u001B[0;32m   1155\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1156\u001B[0m     \u001B[38;5;66;03m# Only block async when verbose = 1.\u001B[39;00m\n\u001B[0;32m   1157\u001B[0m     logs \u001B[38;5;241m=\u001B[39m tf_utils\u001B[38;5;241m.\u001B[39msync_to_numpy_or_python_type(logs)\n\u001B[1;32m-> 1158\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprogbar\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mseen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mlogs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfinalize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\generic_utils.py:1051\u001B[0m, in \u001B[0;36mProgbar.update\u001B[1;34m(self, current, values, finalize)\u001B[0m\n\u001B[0;32m   1048\u001B[0m         info \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1050\u001B[0m     message \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m info\n\u001B[1;32m-> 1051\u001B[0m     \u001B[43mio_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprint_msg\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mline_break\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m   1052\u001B[0m     message \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1054\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\io_utils.py:79\u001B[0m, in \u001B[0;36mprint_msg\u001B[1;34m(message, line_break)\u001B[0m\n\u001B[0;32m     77\u001B[0m         sys\u001B[38;5;241m.\u001B[39mstdout\u001B[38;5;241m.\u001B[39mwrite(message \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 79\u001B[0m         \u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstdout\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     80\u001B[0m     sys\u001B[38;5;241m.\u001B[39mstdout\u001B[38;5;241m.\u001B[39mflush()\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\iostream.py:662\u001B[0m, in \u001B[0;36mOutStream.write\u001B[1;34m(self, string)\u001B[0m\n\u001B[0;32m    660\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpub_thread\u001B[38;5;241m.\u001B[39mschedule(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flush)\n\u001B[0;32m    661\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 662\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_schedule_flush\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    664\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(string)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\iostream.py:559\u001B[0m, in \u001B[0;36mOutStream._schedule_flush\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    556\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_schedule_in_thread\u001B[39m():\n\u001B[0;32m    557\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_io_loop\u001B[38;5;241m.\u001B[39mcall_later(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mflush_interval, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flush)\n\u001B[1;32m--> 559\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpub_thread\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mschedule\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_schedule_in_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\iostream.py:266\u001B[0m, in \u001B[0;36mIOPubThread.schedule\u001B[1;34m(self, f)\u001B[0m\n\u001B[0;32m    264\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_events\u001B[38;5;241m.\u001B[39mappend(f)\n\u001B[0;32m    265\u001B[0m     \u001B[38;5;66;03m# wake event thread (message content is ignored)\u001B[39;00m\n\u001B[1;32m--> 266\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_event_pipe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    267\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    268\u001B[0m     f()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\zmq\\sugar\\socket.py:696\u001B[0m, in \u001B[0;36mSocket.send\u001B[1;34m(self, data, flags, copy, track, routing_id, group)\u001B[0m\n\u001B[0;32m    689\u001B[0m         data \u001B[38;5;241m=\u001B[39m zmq\u001B[38;5;241m.\u001B[39mFrame(\n\u001B[0;32m    690\u001B[0m             data,\n\u001B[0;32m    691\u001B[0m             track\u001B[38;5;241m=\u001B[39mtrack,\n\u001B[0;32m    692\u001B[0m             copy\u001B[38;5;241m=\u001B[39mcopy \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    693\u001B[0m             copy_threshold\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcopy_threshold,\n\u001B[0;32m    694\u001B[0m         )\n\u001B[0;32m    695\u001B[0m     data\u001B[38;5;241m.\u001B[39mgroup \u001B[38;5;241m=\u001B[39m group\n\u001B[1;32m--> 696\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mflags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrack\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrack\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mzmq\\\\backend\\\\cython\\\\socket.pyx:742\u001B[0m, in \u001B[0;36mzmq.backend.cython.socket.Socket.send\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mzmq\\\\backend\\\\cython\\\\socket.pyx:789\u001B[0m, in \u001B[0;36mzmq.backend.cython.socket.Socket.send\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mzmq\\\\backend\\\\cython\\\\socket.pyx:250\u001B[0m, in \u001B[0;36mzmq.backend.cython.socket._send_copy\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd:13\u001B[0m, in \u001B[0;36mzmq.backend.cython.checkrc._check_rc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T07:39:13.768450Z",
     "start_time": "2024-07-05T04:08:20.409843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model2.compile(optimizer=Adam(learning_rate=0.00006), loss=CTCLoss)\n",
    "# create all the callbacks \n",
    "checkpointCallback2 = ModelCheckpoint('newLipModelv12_m2.weights.h5', monitor='loss',save_weights_only=False, save_freq='epoch') # save checkpoints after each epoch\n",
    "exampleCallback2 = ProduceExample(test)\n",
    "\n",
    "model2.fit(train, validation_data=test, epochs=300, callbacks=[checkpointCallback2, exampleCallback2], use_multiprocessing=True)\n",
    "\n",
    "# finished with loss ~ 35"
   ],
   "id": "3b9c695e7fa6123e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Original: IVE WALKED UP ON A FEW FROM TIME TO TIME\n",
      "Prediction: WD A A A E E M O TO\n",
      "Word Error Rate:  90.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: MADE A MIRACULOUS DIVERSION\n",
      "Prediction: MADE A MIRACULOUS DIVERSION\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: TO FIND OUT MORE\n",
      "Prediction: THOE O FO\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND NOT DOING VERY WELL\n",
      "Prediction: IE OE ON E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 991s 6s/step - loss: 38.3257 - val_loss: 32.7727\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "Original: ITS ONE OF THOSE THINGS\n",
      "Prediction: ITS ONE OF THOSE THINGS\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND I FIRST WENT THERE FORTY YEARS AGO\n",
      "Prediction: AND I FIRST WENT THERE FORTY YEAS AGO\n",
      "Word Error Rate:  12.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SHE HAD NO ENGLISH\n",
      "Prediction: TE A OGNGHISH\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: FOR MORE INFORMATION HEAD OVER TO THE STRICTLY WEBSITE\n",
      "Prediction: TOE MORE O O OND HOD VOR TO THE SRICLY WEBSITE\n",
      "Word Error Rate:  77.77777777777779%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 799s 5s/step - loss: 36.6437 - val_loss: 30.9106\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "Original: AND COS I LIVE IN LONDON\n",
      "Prediction: I OE O OE E O O I\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SHORT AND SWEET\n",
      "Prediction: SHORT HAD SWET\n",
      "Word Error Rate:  66.66666666666666%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE DECISION OF THE WIFE OF THE EDITOR IS FINAL\n",
      "Prediction: T OE OT O ON ON TO FRARD END TOANS\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND I THINK THIS IS ONE\n",
      "Prediction: IN E TO PINT O NE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 730s 4s/step - loss: 37.1697 - val_loss: 32.3786\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Original: THESE ARE RADIO PHENOMENA\n",
      "Prediction: THESE ARE RADIO PHENOMENA\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I THINK YOURE RIGHT\n",
      "Prediction: I H HOR RIRGHT\n",
      "Word Error Rate:  75.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: TRADITIONAL THREE BEDROOM\n",
      "Prediction: TRADTIN WO THRE TE EON\n",
      "Word Error Rate:  166.66666666666669%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND THE LOWER HALF OF ALEXANDERS BODY WAS SHATTERED\n",
      "Prediction: AND THE LOR ALF ME WOREADE TIS BODY WAS SHATER RHAD\n",
      "Word Error Rate:  77.77777777777779%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 2447s 14s/step - loss: 37.9438 - val_loss: 32.4932\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "Original: THE HOSPITALS WERE ALREADY BUSY DEALING WITH WAR CASUALTIES AND THERE WASNT ENOUGH ROOM TO DEAL\n",
      "Prediction: THE HOPITALS WERE ALREADY BUSY DEALING WITH WAR CASUALTIES AND THERE WASNT ENOUGS TO O TOEDEA\n",
      "Word Error Rate:  31.25%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BUT YOU PROMISED US\n",
      "Prediction: IUR OU THORORED DARTE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THERE HAVE BEEN A FEW DISAGREEMENTS\n",
      "Prediction: THE THE AVE BE SIS SHE SESE TE\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHICH IS LITERALLY JUST UP THE ROAD\n",
      "Prediction: WHE IS IT AS HS ERS SHUY PERIN\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 862s 5s/step - loss: 38.0269 - val_loss: 30.3688\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "Original: THERE IS COMMISSION TO PAY\n",
      "Prediction: THERE IS COMISION TO PAY\n",
      "Word Error Rate:  20.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: CHILD OF THE MILLENNIUM\n",
      "Prediction: CHILD OF THE MILENIUM\n",
      "Word Error Rate:  25.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IVE HAD A CHANCE TO THINK\n",
      "Prediction: IE A A A ON\n",
      "Word Error Rate:  83.33333333333334%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WE HAVE A DRIFT TIME\n",
      "Prediction: A HA ARINE\n",
      "Word Error Rate:  80.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 608s 4s/step - loss: 35.9517 - val_loss: 28.6019\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "Original: THAT DOMINATED THE LANDSCAPE\n",
      "Prediction: THE A E E E A A\n",
      "Word Error Rate:  175.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THAT TELLS US SOMETHING ABOUT THE SIZE OF THE PIPES\n",
      "Prediction: THE AS TO U O O E O I TO OR ES\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS JUST BEEN THROUGH AN OPEN MARKET AUCTION\n",
      "Prediction: AT WIN LI POY AN NIN AT THETME\n",
      "Word Error Rate:  87.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I GAVE YOU THAT\n",
      "Prediction: AE GOE TO SOT O\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 596s 3s/step - loss: 33.7887 - val_loss: 29.8698\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "Original: SO EVERYTHING WAS CARBON FIBRE\n",
      "Prediction: SO EVERYTHING WAS CARBON FIBRE\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND IF MEN CANT SEE THAT\n",
      "Prediction: IND I MO TIN TAT\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IM AFRAID I MUST RESIGN\n",
      "Prediction: IT TIS AS TR RATH\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THATS WHAT WERE WORKING TOWARDS\n",
      "Prediction: BHAT WAT WERE WOKING TOWARDS\n",
      "Word Error Rate:  60.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 943s 6s/step - loss: 36.3638 - val_loss: 31.4665\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "Original: ITS ABOUT THE LITTLE PEOPLE\n",
      "Prediction: ITS ABOUT THE LITLE PEOPLE\n",
      "Word Error Rate:  20.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND HE WAS VERY DEVOTED TO HIS CHILDREN\n",
      "Prediction: THE HE WAE EY DEVOTED TO HIS CHILDREN\n",
      "Word Error Rate:  37.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I EXPECT YOU FORGOT\n",
      "Prediction: IE CECO\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IM HERE ON THE BATTLEMENTS\n",
      "Prediction: IND HER GHITE HIR LOL\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 886s 5s/step - loss: 35.6581 - val_loss: 32.7598\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "Original: ITS NOT A STROKE\n",
      "Prediction: I O O O\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE MEMORY OF THE PLEASANT DALES\n",
      "Prediction: THE MEMORY OF THE PLEASANT DALES\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEY WOULD SUFFER THE SEVEN SULPHURS OF HELL TO PROTECT THAT WHICH THEY\n",
      "Prediction: THEY WOULD SUFE THET TATE HA HIN HEL ON TO ECTHTH THEK\n",
      "Word Error Rate:  84.61538461538461%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: NO TIME TO REST AS WE PUSH STRAIGHT ON WITH OUR THIRD GAME\n",
      "Prediction: AN WOSAT WOVE HT HAT THAT TOS GIGTHT ON WITH HO TRIRS GAME\n",
      "Word Error Rate:  76.92307692307693%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 819s 5s/step - loss: 34.4357 - val_loss: 30.8987\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "Original: YOURE GOING WITH THE BELT\n",
      "Prediction: TH HI OE E E\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THERE WERE SEVERAL OTHER ESCAPE ATTEMPTS\n",
      "Prediction: THE ERE RERE A THERE SCAPE ATEMPTS\n",
      "Word Error Rate:  116.66666666666667%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: CONGRATULATIONS TO HIM\n",
      "Prediction: CON RA TUR EISH OF TOE TIARM\n",
      "Word Error Rate:  233.33333333333334%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I DONT THINK THEY ARE GOING TO USE THIS BED VERY OFTEN ANYWAY\n",
      "Prediction: I OUT HINT HE THE BO BOS BOE O TOE E ONY ONOY\n",
      "Word Error Rate:  92.3076923076923%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 802s 5s/step - loss: 37.2041 - val_loss: 28.5727\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "Original: WITH ME JOHN HUMPHRYS\n",
      "Prediction: WITH ME JOHN HUMPHRYS\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS GETTING TOO HOT IN THE MEDITERRANEAN AND THE WEATHERS BECOMING MORE SUITABLE OVER HERE\n",
      "Prediction: IT IT IS T TO ON THE TE THE TEN AN AN HE WANT TEL BO ON TI BEML BE ME\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WE TAKE AWAY ALL THE GOODNESS\n",
      "Prediction: WHE EVE E OE TE IN TER\n",
      "Word Error Rate:  116.66666666666667%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND I DONT KNOW WHETHER THATS IN MY FAVOUR\n",
      "Prediction: I YOMETN IN WATHER THA THS IN MY FAVOUR FROT TINT\n",
      "Word Error Rate:  88.88888888888889%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 730s 4s/step - loss: 34.6735 - val_loss: 29.9191\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "Original: HE BROKE THE WORLD RECORD ON LAND\n",
      "Prediction: HE BROKE THE WORLD RECORD ON LAND\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WEVE STILL HAVE GOT OUR VINYL COLLECTION\n",
      "Prediction: WU AG GIS THE LAS AE BEOL\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IT WAS STILL LEGAL TO PAY WOMEN MUCH LESS THAN MEN FOR DOING THE SAME JOB\n",
      "Prediction: IME TE O LERE AS FA LE AL O TINE A A M MEN OR MOING THE SA ME LOE\n",
      "Word Error Rate:  112.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IN A WORLD WHERE PEOPLE\n",
      "Prediction: I A WORED WHERE PELE\n",
      "Word Error Rate:  60.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 599s 3s/step - loss: 35.0360 - val_loss: 28.6606\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "Original: FORTUNATELY FOR ME\n",
      "Prediction: IOTEY FOR ME\n",
      "Word Error Rate:  33.33333333333333%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHILE SOBERLY SURVEYING OUR GREAT PAST AND OUR PROMISING FUTURE\n",
      "Prediction: WHILE SOBERLY SURVEYING OUR GREAT PAST AD O FORISHO RY TOS SE\n",
      "Word Error Rate:  60.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHY NOBODY ELSE SAW IT IT WOULD HAVE BEEN VISIBLE ONLY FROM THAT PART OF THE GLOBE AND ALSO\n",
      "Prediction: WHAY THEBOULE A WOLE AL TI WALT EAE O HEBLEY TOITS AL IF TOR SAT TAS TOTS A ES TIM GOUTI\n",
      "Word Error Rate:  110.5263157894737%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND IF IM SUCCESSFUL AND WIN\n",
      "Prediction: IN I EAY HABEBIBEBIS BIND\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 618s 4s/step - loss: 34.8488 - val_loss: 31.9697\n",
      "Epoch 15/300\n",
      " 98/171 [================>.............] - ETA: 2:41 - loss: 35.3060"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[34], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m checkpointCallback2 \u001B[38;5;241m=\u001B[39m ModelCheckpoint(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnewLipModelv12_m2.weights.h5\u001B[39m\u001B[38;5;124m'\u001B[39m, monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m,save_weights_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, save_freq\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mepoch\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;66;03m# save checkpoints after each epoch\u001B[39;00m\n\u001B[0;32m      4\u001B[0m exampleCallback2 \u001B[38;5;241m=\u001B[39m ProduceExample(test)\n\u001B[1;32m----> 6\u001B[0m \u001B[43mmodel2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m300\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mcheckpointCallback2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexampleCallback2\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1570\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1568\u001B[0m logs \u001B[38;5;241m=\u001B[39m tmp_logs\n\u001B[0;32m   1569\u001B[0m end_step \u001B[38;5;241m=\u001B[39m step \u001B[38;5;241m+\u001B[39m data_handler\u001B[38;5;241m.\u001B[39mstep_increment\n\u001B[1;32m-> 1570\u001B[0m \u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_train_batch_end\u001B[49m\u001B[43m(\u001B[49m\u001B[43mend_step\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1571\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_training:\n\u001B[0;32m   1572\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:470\u001B[0m, in \u001B[0;36mCallbackList.on_train_batch_end\u001B[1;34m(self, batch, logs)\u001B[0m\n\u001B[0;32m    463\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001B[39;00m\n\u001B[0;32m    464\u001B[0m \n\u001B[0;32m    465\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m    466\u001B[0m \u001B[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001B[39;00m\n\u001B[0;32m    467\u001B[0m \u001B[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001B[39;00m\n\u001B[0;32m    468\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    469\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_call_train_batch_hooks:\n\u001B[1;32m--> 470\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_batch_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mModeKeys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTRAIN\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mend\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:317\u001B[0m, in \u001B[0;36mCallbackList._call_batch_hook\u001B[1;34m(self, mode, hook, batch, logs)\u001B[0m\n\u001B[0;32m    315\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_batch_begin_hook(mode, batch, logs)\n\u001B[0;32m    316\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m hook \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 317\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_batch_end_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    319\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    320\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized hook: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    321\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExpected values are [\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbegin\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    322\u001B[0m     )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:340\u001B[0m, in \u001B[0;36mCallbackList._call_batch_end_hook\u001B[1;34m(self, mode, batch, logs)\u001B[0m\n\u001B[0;32m    337\u001B[0m     batch_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_start_time\n\u001B[0;32m    338\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_times\u001B[38;5;241m.\u001B[39mappend(batch_time)\n\u001B[1;32m--> 340\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_batch_hook_helper\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhook_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    342\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_times) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_batches_for_timing_check:\n\u001B[0;32m    343\u001B[0m     end_hook_name \u001B[38;5;241m=\u001B[39m hook_name\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:388\u001B[0m, in \u001B[0;36mCallbackList._call_batch_hook_helper\u001B[1;34m(self, hook_name, batch, logs)\u001B[0m\n\u001B[0;32m    386\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m callback \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks:\n\u001B[0;32m    387\u001B[0m     hook \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(callback, hook_name)\n\u001B[1;32m--> 388\u001B[0m     \u001B[43mhook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    390\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_timing:\n\u001B[0;32m    391\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m hook_name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_hook_times:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:1081\u001B[0m, in \u001B[0;36mProgbarLogger.on_train_batch_end\u001B[1;34m(self, batch, logs)\u001B[0m\n\u001B[0;32m   1080\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mon_train_batch_end\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch, logs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m-> 1081\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_batch_update_progbar\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:1157\u001B[0m, in \u001B[0;36mProgbarLogger._batch_update_progbar\u001B[1;34m(self, batch, logs)\u001B[0m\n\u001B[0;32m   1153\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseen \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m add_seen\n\u001B[0;32m   1155\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1156\u001B[0m     \u001B[38;5;66;03m# Only block async when verbose = 1.\u001B[39;00m\n\u001B[1;32m-> 1157\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[43mtf_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msync_to_numpy_or_python_type\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1158\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprogbar\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseen, \u001B[38;5;28mlist\u001B[39m(logs\u001B[38;5;241m.\u001B[39mitems()), finalize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001B[0m, in \u001B[0;36msync_to_numpy_or_python_type\u001B[1;34m(tensors)\u001B[0m\n\u001B[0;32m    632\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\n\u001B[0;32m    633\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39mndim(t) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m t\n\u001B[1;32m--> 635\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_structure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_to_single_numpy_or_python_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001B[0m, in \u001B[0;36mmap_structure\u001B[1;34m(func, *structure, **kwargs)\u001B[0m\n\u001B[0;32m    913\u001B[0m flat_structure \u001B[38;5;241m=\u001B[39m (flatten(s, expand_composites) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m structure)\n\u001B[0;32m    914\u001B[0m entries \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mflat_structure)\n\u001B[0;32m    916\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pack_sequence_as(\n\u001B[1;32m--> 917\u001B[0m     structure[\u001B[38;5;241m0\u001B[39m], [func(\u001B[38;5;241m*\u001B[39mx) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m entries],\n\u001B[0;32m    918\u001B[0m     expand_composites\u001B[38;5;241m=\u001B[39mexpand_composites)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    913\u001B[0m flat_structure \u001B[38;5;241m=\u001B[39m (flatten(s, expand_composites) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m structure)\n\u001B[0;32m    914\u001B[0m entries \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mflat_structure)\n\u001B[0;32m    916\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pack_sequence_as(\n\u001B[1;32m--> 917\u001B[0m     structure[\u001B[38;5;241m0\u001B[39m], [\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m entries],\n\u001B[0;32m    918\u001B[0m     expand_composites\u001B[38;5;241m=\u001B[39mexpand_composites)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001B[0m, in \u001B[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m    625\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_to_single_numpy_or_python_type\u001B[39m(t):\n\u001B[0;32m    626\u001B[0m     \u001B[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001B[39;00m\n\u001B[0;32m    627\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, tf\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[1;32m--> 628\u001B[0m         t \u001B[38;5;241m=\u001B[39m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001B[39;00m\n\u001B[0;32m    630\u001B[0m     \u001B[38;5;66;03m# as-is.\u001B[39;00m\n\u001B[0;32m    631\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, (np\u001B[38;5;241m.\u001B[39mndarray, np\u001B[38;5;241m.\u001B[39mgeneric)):\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001B[0m, in \u001B[0;36m_EagerTensorBase.numpy\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1134\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001B[39;00m\n\u001B[0;32m   1135\u001B[0m \n\u001B[0;32m   1136\u001B[0m \u001B[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1154\u001B[0m \u001B[38;5;124;03m    NumPy dtype.\u001B[39;00m\n\u001B[0;32m   1155\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1156\u001B[0m \u001B[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001B[39;00m\n\u001B[1;32m-> 1157\u001B[0m maybe_arr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m   1158\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m maybe_arr\u001B[38;5;241m.\u001B[39mcopy() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(maybe_arr, np\u001B[38;5;241m.\u001B[39mndarray) \u001B[38;5;28;01melse\u001B[39;00m maybe_arr\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001B[0m, in \u001B[0;36m_EagerTensorBase._numpy\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1121\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_numpy\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m   1122\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1123\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_numpy_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1124\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m   1125\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T12:01:22.997356Z",
     "start_time": "2024-07-05T07:53:34.681705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model2.compile(optimizer=Adam(learning_rate=0.00002), loss=CTCLoss)\n",
    "# create all the callbacks \n",
    "checkpointCallback2 = ModelCheckpoint('newLipModelv13_m2.weights.h5', monitor='loss',save_weights_only=False, save_freq='epoch') # save checkpoints after each epoch\n",
    "exampleCallback2 = ProduceExample(test)\n",
    "scheduleCallback2 = LearningRateScheduler(scheduler)\n",
    "\n",
    "model2.fit(train, validation_data=test, epochs=300, callbacks=[checkpointCallback2, exampleCallback2, scheduleCallback2], use_multiprocessing=True)"
   ],
   "id": "9ed847ccbbdefe0d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "  6/171 [>.............................] - ETA: 5:56 - loss: 29.2406WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7764s vs `on_train_batch_end` time: 1.3023s). Check your callbacks.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Original: HES BEEN UP ALL NIGHT\n",
      "Prediction: TH A O ON A O\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: MAYBE SOME PEOPLE SAY\n",
      "Prediction: TE BOUE POPE SO\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: HE TALKS ABOUT HOW\n",
      "Prediction: THE I O H\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IM AFRAID THAT BECKY HAS SINGLED YOU OUT\n",
      "Prediction: I MI THAT TA BAS H SINGED DOU UT\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 869s 5s/step - loss: 33.9611 - val_loss: 28.2947 - lr: 2.0000e-05\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "Original: THOUSANDS OF POUNDS\n",
      "Prediction: THOR ANDS O FOUND\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEN IT WONT HAPPEN TO YOU AGAIN\n",
      "Prediction: THEN IT WONT HAPEN TO YOU AGAIN\n",
      "Word Error Rate:  14.285714285714285%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WERE NOT ENTIRELY SURE WHEN ALL THIS HAPPENED\n",
      "Prediction: WERE NOT TENTIRELY SURE WHEN AL THIS HAPENED\n",
      "Word Error Rate:  37.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: FOR YOUR MUSIC STARTER\n",
      "Prediction: FOR YOUR MUSIC STARTER\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 755s 4s/step - loss: 35.5460 - val_loss: 31.4068 - lr: 2.0000e-05\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "Original: AND IT LOOKS LIKE A REALLY GOOD BUY\n",
      "Prediction: AND IT LOKS LIKE A REALY GOE IT E OR O\n",
      "Word Error Rate:  87.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: AND I FIRST WENT THERE FORTY YEARS AGO\n",
      "Prediction: AND AN RIR MANE CEVE RTONT TE HAS AG\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: HE WENT BACK AND BACK\n",
      "Prediction: HE AT AN AN AK\n",
      "Word Error Rate:  80.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: PEOPLE LIKE MY PASTA\n",
      "Prediction: FO LOLE LIKE MYAR\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 746s 4s/step - loss: 33.7086 - val_loss: 29.8888 - lr: 2.0000e-05\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "Original: LOOK AFTER YOURSELF\n",
      "Prediction: WHE TO TO\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THAT DOMINATED THE LANDSCAPE\n",
      "Prediction: THE OE E OE ON E LE\n",
      "Word Error Rate:  175.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BEFORE BUT IVE NEVER SEEN ONE WITH ROLLED PAPERWORK\n",
      "Prediction: BEFORE BUT IVEREIVE N NE WT RO TEDEWET\n",
      "Word Error Rate:  77.77777777777779%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THIS WAS THE SORT OF THING THAT GAINSBOROUGH DID\n",
      "Prediction: THIS WAS TONY THO PUEIN THA TH TI O\n",
      "Word Error Rate:  77.77777777777779%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 732s 4s/step - loss: 34.0282 - val_loss: 29.9871 - lr: 2.0000e-05\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "Original: ITS FIVE YEARS OF ANAL GLANDS\n",
      "Prediction: IS FIVS FES OF AN AND ANDS\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: TOGETHER REALLY GREY\n",
      "Prediction: TOGETHER REALY GREY\n",
      "Word Error Rate:  33.33333333333333%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEN WE SHOULD BE A PRETTY FIT NATION\n",
      "Prediction: THEN WE SHOUT BE AS TE FIT ONTICHIG\n",
      "Word Error Rate:  50.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WE SHOULD PURSUE THIS STRATEGY\n",
      "Prediction: IE THEVE WASTR SHE THIRS TATES\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 746s 4s/step - loss: 34.3943 - val_loss: 28.1265 - lr: 2.0000e-05\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "Original: IT IS GOING TO TAKE US SOME TIME ON THE BIGGEST TELESCOPES IN THE WORLD\n",
      "Prediction: IT IS GOING TO TAKE US SOME TIME ON THE BIGEST TELESCOPES IN THER WOREMS\n",
      "Word Error Rate:  20.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: REALLY VERY GOOD\n",
      "Prediction: I IS O CEORE\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS JUST FOR FUN\n",
      "Prediction: ITS JUS BER FUIN\n",
      "Word Error Rate:  75.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THERE HAVE BEEN A FEW DISAGREEMENTS\n",
      "Prediction: THE RE HIE HERE HIT O WO ECO\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 791s 5s/step - loss: 33.3000 - val_loss: 29.0505 - lr: 2.0000e-05\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "Original: SO MUCH OF IT WAS FORGOTTEN ABOUT\n",
      "Prediction: SO MUCH OF IT WAS FORGOTEN ABOUT\n",
      "Word Error Rate:  14.285714285714285%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BUT I DONT REMEMBER HIM\n",
      "Prediction: IN I ER MEM\n",
      "Word Error Rate:  80.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IVE GOT TO GET BACK HOME\n",
      "Prediction: IVE GOT T GET BAN CHES\n",
      "Word Error Rate:  50.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE THING TO DO IS TO TRY AND ATTRACT THE ATTENTION OF OTHER PEOPLE\n",
      "Prediction: HE E E AN THA ABD RAN TE IE HE O BIE IE EONSTIE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 770s 5s/step - loss: 33.3488 - val_loss: 29.7785 - lr: 2.0000e-05\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "Original: WHO KNOWS WHERE TO START\n",
      "Prediction: WHO KNOWS WHERE TO START\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I HAD LOTS OF PEOPLE SAY TO ME\n",
      "Prediction: AND I O O O O TO\n",
      "Word Error Rate:  87.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I THINK YOURE RIGHT\n",
      "Prediction: IHIT HEYTO THY YOU\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SO A FARM LIKE THIS\n",
      "Prediction: SO A HAE LALKE THIS\n",
      "Word Error Rate:  40.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 761s 4s/step - loss: 34.5045 - val_loss: 29.1226 - lr: 2.0000e-05\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "Original: THEY FORGET THAT HE WAS A MAN OF HIS TIME\n",
      "Prediction: TE O E HA THAT A A AT HE CIM\n",
      "Word Error Rate:  90.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THE HOSPITALS WERE ALREADY BUSY DEALING WITH WAR CASUALTIES AND THERE WASNT ENOUGH ROOM TO DEAL\n",
      "Prediction: THE HOSPITALS WERE ALEAY BUT AL TOTRE RER T EA I TIN TEAN I AR UNUGUE TOM TO DEAL\n",
      "Word Error Rate:  87.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ID BE MORE THAN HAPPY WITH THE SAME AGAIN\n",
      "Prediction: I ETET THINE AS O HAN HE FORDA\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I REALLY DIDNT KNOW WHAT IT WAS\n",
      "Prediction: THE TOR A O A IE RECE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 949s 6s/step - loss: 33.7308 - val_loss: 31.0638 - lr: 2.0000e-05\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "Original: IF YOU CARED ANYTHING ABOUT YOUR KID\n",
      "Prediction: IE WE AND AN HING HABOUT YOUR KID\n",
      "Word Error Rate:  85.71428571428571%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SOUNDS LIKE THE CLICHE\n",
      "Prediction: WHE IT A ALTHTH\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IM JUST GOING OUT TO BUY SOME WINE\n",
      "Prediction: I ON SOTI TE BUTETISMIN\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WE WERE GONE FOR A COUPLE OF DAYS AND CAME BACK\n",
      "Prediction: WHE E E OR E E ES SA MAN MA\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 967s 6s/step - loss: 32.2154 - val_loss: 26.8659 - lr: 2.0000e-05\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "Original: HAS ALWAYS BEEN INCREDIBLY IMPORTANT TO ME\n",
      "Prediction: THE E E O IN AN AT ANTHI\n",
      "Word Error Rate:  114.28571428571428%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEY ALSO HAVE A VERY HIGH LEVEL OF FLEXIBILITY\n",
      "Prediction: TH I I H O HE I OY FL LINAT\n",
      "Word Error Rate:  111.11111111111111%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BUT IN MY OPINION\n",
      "Prediction: BUT IN M OININ\n",
      "Word Error Rate:  50.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SHALL WE FIND OUT\n",
      "Prediction: T L I TO OI\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 979s 6s/step - loss: 35.8436 - val_loss: 32.5196 - lr: 1.8097e-05\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "Original: IM HAVING TO DEAL WITH PHILS MESS\n",
      "Prediction: IM HAVING TO DEAL WITH PHILS MES\n",
      "Word Error Rate:  14.285714285714285%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IN A WORLD FIRST\n",
      "Prediction: IN A WORLD FIRST\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THIS IS SPORT IN ENGLAND\n",
      "Prediction: T T ESE THAR AL LIE E I\n",
      "Word Error Rate:  160.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: JUST TWO YEARS BEFORE SHE WAS FORCED FROM POWER\n",
      "Prediction: JUS FIRS BEFORE SHE WAS FORCELD OR MORE\n",
      "Word Error Rate:  66.66666666666666%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 995s 6s/step - loss: 35.2826 - val_loss: 30.1194 - lr: 1.6375e-05\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "Original: AND THEN STEP BACK\n",
      "Prediction: AND HE TE BACK\n",
      "Word Error Rate:  50.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THERES TO BE NO SUNDAY TRADING\n",
      "Prediction: THERES BO BE OU UD RAING\n",
      "Word Error Rate:  66.66666666666666%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WE ARE HERE TO CONTACT LONDON\n",
      "Prediction: TE AE HE TO COE COCON\n",
      "Word Error Rate:  83.33333333333334%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS ALL RIGHT FOR YOU\n",
      "Prediction: TOE ROT TORO\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 777s 5s/step - loss: 32.4583 - val_loss: 32.3987 - lr: 1.4816e-05\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "Original: NO MONEY BEING HANDED OUT\n",
      "Prediction: TOME ON HE E E DO\n",
      "Word Error Rate:  120.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WERE ALL DESTINED FOR THE SCRAP HEAP OF HISTORY\n",
      "Prediction: WE AL DESTINED FOR THE SCRAP HEAP OF HISTORY\n",
      "Word Error Rate:  22.22222222222222%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I WOULD PUT HSA\n",
      "Prediction: I WOL PUT HS\n",
      "Word Error Rate:  50.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: LYING JUST SIXTY MILES AWAY\n",
      "Prediction: I IOL IS EIT MES E WIM\n",
      "Word Error Rate:  140.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 772s 5s/step - loss: 33.5624 - val_loss: 29.5936 - lr: 1.3406e-05\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "Original: DIES OF RADIATION SICKNESS\n",
      "Prediction: DIES OF RADIATION SICKNES\n",
      "Word Error Rate:  25.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: OUR FIRST POLICE FORCE\n",
      "Prediction: SOR FIRST POLICE FORCE\n",
      "Word Error Rate:  25.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ITS NOT WORTH IT\n",
      "Prediction: ITS DON WORTHA T\n",
      "Word Error Rate:  75.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THERE ARE RISKS\n",
      "Prediction: THES RER \n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 756s 4s/step - loss: 34.7014 - val_loss: 29.3823 - lr: 1.2131e-05\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "Original: PLEASE TELL ME THIS IS A JOKE\n",
      "Prediction: PLEASE TEL ME THIS IS A JOKE\n",
      "Word Error Rate:  14.285714285714285%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: QUICK QUESTION HOW MANY BRUSSELS SPROUTS DO YOU WANT\n",
      "Prediction: BUE OE TO H WAY BOUES SOUS YO YOU WAN\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IT WAS A THREE WAY MARGINAL\n",
      "Prediction: I WAT TAE WA MAIGI\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEYD CALL IT RECYCLING THESE DAYS\n",
      "Prediction: THEY A CL RE OR IG SHAS TAST\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 784s 5s/step - loss: 33.7612 - val_loss: 29.0088 - lr: 1.0976e-05\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "Original: THESE ARE RADIO PHENOMENA\n",
      "Prediction: THESE ARE RADIO PHENOMENA\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I DONT HAVE THE BUDGET TO BUY THE MATERIALS\n",
      "Prediction: TH IT HE THE NEANG THE BUY THE MAEAIS\n",
      "Word Error Rate:  66.66666666666666%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: HED LIVED HIS PASSION\n",
      "Prediction: IEIS T TYOTR\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THROUGHOUT EVAS LONG WIDOWHOOD\n",
      "Prediction: THO GOU HE AS ONILI WHE HOD\n",
      "Word Error Rate:  175.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 962s 6s/step - loss: 31.6458 - val_loss: 30.0965 - lr: 9.9317e-06\n",
      "Epoch 18/300\n",
      "171/171 [==============================] - ETA: 0s - loss: 33.1866[' ', 'WHEN', ' ', 'I', ' ', 'WAS', ' ', 'ABOUT', ' ', 'EIGHT', ' ', 'OR', ' ', 'NINE']\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} sizes input must be 1-D, not [31,1] [Op:Reshape]\nTraceback (most recent call last):\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\monis\\AppData\\Local\\Temp\\ipykernel_9104\\3629012439.py\", line 13, in loadData\n    frames = loadVideo(videoPath)\n\n  File \"C:\\Users\\monis\\AppData\\Local\\Temp\\ipykernel_9104\\3629012439.py\", line 44, in loadVideo\n    grayFrame = tf.image.rgb_to_grayscale(frame)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 54, in quick_execute\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} sizes input must be 1-D, not [31,1] [Op:Reshape]\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) UNKNOWN:  InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} sizes input must be 1-D, not [31,1] [Op:Reshape]\nTraceback (most recent call last):\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\monis\\AppData\\Local\\Temp\\ipykernel_9104\\3629012439.py\", line 13, in loadData\n    frames = loadVideo(videoPath)\n\n  File \"C:\\Users\\monis\\AppData\\Local\\Temp\\ipykernel_9104\\3629012439.py\", line 44, in loadVideo\n    grayFrame = tf.image.rgb_to_grayscale(frame)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 54, in quick_execute\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} sizes input must be 1-D, not [31,1] [Op:Reshape]\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_test_function_240841334]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnknownError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[38], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m exampleCallback2 \u001B[38;5;241m=\u001B[39m ProduceExample(test)\n\u001B[0;32m      5\u001B[0m scheduleCallback2 \u001B[38;5;241m=\u001B[39m LearningRateScheduler(scheduler)\n\u001B[1;32m----> 7\u001B[0m \u001B[43mmodel2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m300\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mcheckpointCallback2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexampleCallback2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduleCallback2\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     55\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mUnknownError\u001B[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} sizes input must be 1-D, not [31,1] [Op:Reshape]\nTraceback (most recent call last):\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\monis\\AppData\\Local\\Temp\\ipykernel_9104\\3629012439.py\", line 13, in loadData\n    frames = loadVideo(videoPath)\n\n  File \"C:\\Users\\monis\\AppData\\Local\\Temp\\ipykernel_9104\\3629012439.py\", line 44, in loadVideo\n    grayFrame = tf.image.rgb_to_grayscale(frame)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 54, in quick_execute\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} sizes input must be 1-D, not [31,1] [Op:Reshape]\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) UNKNOWN:  InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} sizes input must be 1-D, not [31,1] [Op:Reshape]\nTraceback (most recent call last):\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\monis\\AppData\\Local\\Temp\\ipykernel_9104\\3629012439.py\", line 13, in loadData\n    frames = loadVideo(videoPath)\n\n  File \"C:\\Users\\monis\\AppData\\Local\\Temp\\ipykernel_9104\\3629012439.py\", line 44, in loadVideo\n    grayFrame = tf.image.rgb_to_grayscale(frame)\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"C:\\Users\\monis\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 54, in quick_execute\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} sizes input must be 1-D, not [31,1] [Op:Reshape]\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_test_function_240841334]"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T21:47:46.389830Z",
     "start_time": "2024-07-05T18:48:12.691986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model2.compile(optimizer=Adam(learning_rate=0.000007), loss=CTCLoss)\n",
    "# create all the callbacks \n",
    "checkpointCallback2 = ModelCheckpoint('newLipModelv14_m2.weights.h5', monitor='loss',save_weights_only=False, save_freq='epoch') # save checkpoints after each epoch\n",
    "exampleCallback2 = ProduceExample(test)\n",
    "scheduleCallback3 = LearningRateScheduler(scheduler2)\n",
    "\n",
    "model2.fit(train, validation_data=test, epochs=300, callbacks=[checkpointCallback2, exampleCallback2, scheduleCallback3], use_multiprocessing=True)"
   ],
   "id": "f11b486a3e527ff3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Original: AND THEY ARE REALLY ROUGH AND READY\n",
      "Prediction: AND THE RE RAL YORY OUD ADADAD\n",
      "Word Error Rate:  85.71428571428571%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BUT BEFORE WE GO\n",
      "Prediction: BUT BEFORE WE GO\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THERES A WORLD IN WHICH THAT WILL WORK\n",
      "Prediction: THERES A WOALD IN WHICH THAT WIL WORK\n",
      "Word Error Rate:  25.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHICH THEY DO TODAY\n",
      "Prediction: THE HO OR DO DANY\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 1532s 9s/step - loss: 33.3434 - val_loss: 29.6526 - lr: 6.3339e-06\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "Original: I THINK THERES STILL HUGE RESPECT FOR THE POPPY\n",
      "Prediction: I HIK THERES STIL HUGE RESPECT FOR THE POPY\n",
      "Word Error Rate:  33.33333333333333%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHETHER YOU LOVE OR LOATHE CICADAS\n",
      "Prediction: WHETHER YOU LOVE OR LOATHE CICADAS\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: STILL GOING TO NEED TO TRAIN OFFICERS\n",
      "Prediction: WHE L TON TON TO ON O OFR\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I DONT THINK THAT IS THE CASE\n",
      "Prediction: I DONT THINK THAT IS THE CASE\n",
      "Word Error Rate:  0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 1287s 8s/step - loss: 34.0232 - val_loss: 28.3325 - lr: 5.7311e-06\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "Original: I KEEP MY BREAD IN THE FRIDGE\n",
      "Prediction: TI LE PEMW WHIN THE RIDGE\n",
      "Word Error Rate:  85.71428571428571%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BUT I WANT YOU TO TALK TO HIM\n",
      "Prediction: BUT IR MAN IT UT TO TALK O WONT HION\n",
      "Word Error Rate:  87.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ALAN TITCHMARSH MIGHT SAY SO\n",
      "Prediction: BATAT HAS AON SAY TOS\n",
      "Word Error Rate:  80.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEY HAVE TO THINK ABOUT THAT\n",
      "Prediction: THE AE A TITN T\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 1288s 8s/step - loss: 33.7566 - val_loss: 29.8729 - lr: 5.1857e-06\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "Original: THERE CERTAINLY WERE\n",
      "Prediction: THE CRCINS HE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SO IF A LITTLE BIT OF MONEY COMES IN THE BACK POCKET\n",
      "Prediction: SO IF ALITLE BIT OF MONEY COMES IN THE BACK POCKET\n",
      "Word Error Rate:  16.666666666666664%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: DECORATING COMES UNDER MAINTENANCE\n",
      "Prediction: YECERATING COMES UNDER MAINTENANCE\n",
      "Word Error Rate:  25.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: WHERE DID YOU GET THESE SCALES FROM\n",
      "Prediction: I T TO TI I ATO\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 1296s 8s/step - loss: 32.9847 - val_loss: 28.3889 - lr: 4.6922e-06\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "Original: WANDERING THROUGH SPACE AND TIME IN\n",
      "Prediction: WE I I I IN IN IN I HEI\n",
      "Word Error Rate:  133.33333333333331%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: I GET A LOT OF THAT ON A FRIDAY NIGHT IN THE BALLROOM WITH THE GENTLEMANS EXCUSE ME\n",
      "Prediction: IT AT OF THAT ON A FRIDAY NIGHT IN THE BALROM WITH THE GENTLEMANS EXCUSE ME\n",
      "Word Error Rate:  27.77777777777778%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: SO BOTH THOSE CLUBS WILL BE LOOKING TO ACTUALLY FINISH OFF THE SEASON AND GET PROMOTION\n",
      "Prediction: TOT CIT BELITE HIL I TO O THAT ATI INS HIS AES A A\n",
      "Word Error Rate:  93.75%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: NICK THINKS ITS SCOTTISH\n",
      "Prediction: ICK HIN H TAM POTILSH\n",
      "Word Error Rate:  125.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 1236s 7s/step - loss: 32.7182 - val_loss: 32.3807 - lr: 4.2457e-06\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 1s 753ms/step\n",
      "Original: I AM HIS TWIN BROTHER\n",
      "Prediction: I AM HI HIS BRTR\n",
      "Word Error Rate:  60.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: BUT THEN THEY DIDNT GET THIS GREEN WITHOUT A BIT OF RAIN\n",
      "Prediction: BUT THEN THEY DIDNT GET THIS GREN WITHOUT A BIT OF RAIN\n",
      "Word Error Rate:  8.333333333333332%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: LIFE IS NOT ABOUT WHERE YOU ARE\n",
      "Prediction: THERE BY TAL IVERY FOUTEY FRAE\n",
      "Word Error Rate:  100.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: ON OUR FURTHEST TRIP OUT EAST\n",
      "Prediction: IN HE F FRTHES TR POUT DEADSIT\n",
      "Word Error Rate:  116.66666666666667%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "171/171 [==============================] - 3038s 18s/step - loss: 31.4726 - val_loss: 27.6801 - lr: 3.8417e-06\n",
      "Epoch 7/300\n",
      " 78/171 [============>.................] - ETA: 21:46 - loss: 31.5015"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[40], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m exampleCallback2 \u001B[38;5;241m=\u001B[39m ProduceExample(test)\n\u001B[0;32m      5\u001B[0m scheduleCallback3 \u001B[38;5;241m=\u001B[39m LearningRateScheduler(scheduler2)\n\u001B[1;32m----> 7\u001B[0m \u001B[43mmodel2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m300\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mcheckpointCallback2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexampleCallback2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduleCallback3\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1570\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1568\u001B[0m logs \u001B[38;5;241m=\u001B[39m tmp_logs\n\u001B[0;32m   1569\u001B[0m end_step \u001B[38;5;241m=\u001B[39m step \u001B[38;5;241m+\u001B[39m data_handler\u001B[38;5;241m.\u001B[39mstep_increment\n\u001B[1;32m-> 1570\u001B[0m \u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_train_batch_end\u001B[49m\u001B[43m(\u001B[49m\u001B[43mend_step\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1571\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_training:\n\u001B[0;32m   1572\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:470\u001B[0m, in \u001B[0;36mCallbackList.on_train_batch_end\u001B[1;34m(self, batch, logs)\u001B[0m\n\u001B[0;32m    463\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001B[39;00m\n\u001B[0;32m    464\u001B[0m \n\u001B[0;32m    465\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m    466\u001B[0m \u001B[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001B[39;00m\n\u001B[0;32m    467\u001B[0m \u001B[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001B[39;00m\n\u001B[0;32m    468\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    469\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_call_train_batch_hooks:\n\u001B[1;32m--> 470\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_batch_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mModeKeys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTRAIN\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mend\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:317\u001B[0m, in \u001B[0;36mCallbackList._call_batch_hook\u001B[1;34m(self, mode, hook, batch, logs)\u001B[0m\n\u001B[0;32m    315\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_batch_begin_hook(mode, batch, logs)\n\u001B[0;32m    316\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m hook \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 317\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_batch_end_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    319\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    320\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized hook: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    321\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExpected values are [\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbegin\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    322\u001B[0m     )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:340\u001B[0m, in \u001B[0;36mCallbackList._call_batch_end_hook\u001B[1;34m(self, mode, batch, logs)\u001B[0m\n\u001B[0;32m    337\u001B[0m     batch_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_start_time\n\u001B[0;32m    338\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_times\u001B[38;5;241m.\u001B[39mappend(batch_time)\n\u001B[1;32m--> 340\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_batch_hook_helper\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhook_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    342\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_times) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_batches_for_timing_check:\n\u001B[0;32m    343\u001B[0m     end_hook_name \u001B[38;5;241m=\u001B[39m hook_name\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:388\u001B[0m, in \u001B[0;36mCallbackList._call_batch_hook_helper\u001B[1;34m(self, hook_name, batch, logs)\u001B[0m\n\u001B[0;32m    386\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m callback \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks:\n\u001B[0;32m    387\u001B[0m     hook \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(callback, hook_name)\n\u001B[1;32m--> 388\u001B[0m     \u001B[43mhook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    390\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_timing:\n\u001B[0;32m    391\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m hook_name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_hook_times:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:1081\u001B[0m, in \u001B[0;36mProgbarLogger.on_train_batch_end\u001B[1;34m(self, batch, logs)\u001B[0m\n\u001B[0;32m   1080\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mon_train_batch_end\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch, logs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m-> 1081\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_batch_update_progbar\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:1158\u001B[0m, in \u001B[0;36mProgbarLogger._batch_update_progbar\u001B[1;34m(self, batch, logs)\u001B[0m\n\u001B[0;32m   1155\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1156\u001B[0m     \u001B[38;5;66;03m# Only block async when verbose = 1.\u001B[39;00m\n\u001B[0;32m   1157\u001B[0m     logs \u001B[38;5;241m=\u001B[39m tf_utils\u001B[38;5;241m.\u001B[39msync_to_numpy_or_python_type(logs)\n\u001B[1;32m-> 1158\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprogbar\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mseen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mlogs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfinalize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\generic_utils.py:1051\u001B[0m, in \u001B[0;36mProgbar.update\u001B[1;34m(self, current, values, finalize)\u001B[0m\n\u001B[0;32m   1048\u001B[0m         info \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1050\u001B[0m     message \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m info\n\u001B[1;32m-> 1051\u001B[0m     \u001B[43mio_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprint_msg\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mline_break\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m   1052\u001B[0m     message \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1054\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\io_utils.py:80\u001B[0m, in \u001B[0;36mprint_msg\u001B[1;34m(message, line_break)\u001B[0m\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     79\u001B[0m         sys\u001B[38;5;241m.\u001B[39mstdout\u001B[38;5;241m.\u001B[39mwrite(message)\n\u001B[1;32m---> 80\u001B[0m     \u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstdout\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflush\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     82\u001B[0m     logging\u001B[38;5;241m.\u001B[39minfo(message)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\iostream.py:573\u001B[0m, in \u001B[0;36mOutStream.flush\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    562\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"trigger actual zmq send\u001B[39;00m\n\u001B[0;32m    563\u001B[0m \n\u001B[0;32m    564\u001B[0m \u001B[38;5;124;03msend will happen in the background thread\u001B[39;00m\n\u001B[0;32m    565\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    566\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    567\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpub_thread\n\u001B[0;32m    568\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpub_thread\u001B[38;5;241m.\u001B[39mthread \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    571\u001B[0m ):\n\u001B[0;32m    572\u001B[0m     \u001B[38;5;66;03m# request flush on the background thread\u001B[39;00m\n\u001B[1;32m--> 573\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpub_thread\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mschedule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flush\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    574\u001B[0m     \u001B[38;5;66;03m# wait for flush to actually get through, if we can.\u001B[39;00m\n\u001B[0;32m    575\u001B[0m     evt \u001B[38;5;241m=\u001B[39m threading\u001B[38;5;241m.\u001B[39mEvent()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\iostream.py:266\u001B[0m, in \u001B[0;36mIOPubThread.schedule\u001B[1;34m(self, f)\u001B[0m\n\u001B[0;32m    264\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_events\u001B[38;5;241m.\u001B[39mappend(f)\n\u001B[0;32m    265\u001B[0m     \u001B[38;5;66;03m# wake event thread (message content is ignored)\u001B[39;00m\n\u001B[1;32m--> 266\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_event_pipe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    267\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    268\u001B[0m     f()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\zmq\\sugar\\socket.py:696\u001B[0m, in \u001B[0;36mSocket.send\u001B[1;34m(self, data, flags, copy, track, routing_id, group)\u001B[0m\n\u001B[0;32m    689\u001B[0m         data \u001B[38;5;241m=\u001B[39m zmq\u001B[38;5;241m.\u001B[39mFrame(\n\u001B[0;32m    690\u001B[0m             data,\n\u001B[0;32m    691\u001B[0m             track\u001B[38;5;241m=\u001B[39mtrack,\n\u001B[0;32m    692\u001B[0m             copy\u001B[38;5;241m=\u001B[39mcopy \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    693\u001B[0m             copy_threshold\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcopy_threshold,\n\u001B[0;32m    694\u001B[0m         )\n\u001B[0;32m    695\u001B[0m     data\u001B[38;5;241m.\u001B[39mgroup \u001B[38;5;241m=\u001B[39m group\n\u001B[1;32m--> 696\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mflags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrack\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrack\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mzmq\\\\backend\\\\cython\\\\socket.pyx:742\u001B[0m, in \u001B[0;36mzmq.backend.cython.socket.Socket.send\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mzmq\\\\backend\\\\cython\\\\socket.pyx:789\u001B[0m, in \u001B[0;36mzmq.backend.cython.socket.Socket.send\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mzmq\\\\backend\\\\cython\\\\socket.pyx:250\u001B[0m, in \u001B[0;36mzmq.backend.cython.socket._send_copy\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd:13\u001B[0m, in \u001B[0;36mzmq.backend.cython.checkrc._check_rc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T21:48:51.127521Z",
     "start_time": "2024-07-05T21:48:51.032726Z"
    }
   },
   "cell_type": "code",
   "source": "model2.save_weights('FINAL_LIPMODEL.weights.h5')",
   "id": "f2cfe82f23b35d7a",
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "id": "6eff0658378dde17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T21:47:58.606201Z",
     "start_time": "2024-07-05T21:47:58.348584Z"
    }
   },
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = model2.history.history['loss']\n",
    "test_loss = model2.history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T22:07:03.170480Z",
     "start_time": "2024-07-05T22:07:00.367989Z"
    }
   },
   "cell_type": "code",
   "source": "value, yHat, decoded = makePrediction(model2)",
   "id": "2a4447c34db46abd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 404ms/step\n",
      "Original: THEY MEET EACH OTHER OUTSIDE THE CHURCH\n",
      "Prediction: THEY MET EACH OTHER OUTSIDE THE CHURCH\n",
      "Word Error Rate on Prediction: 14.285714285714285%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THEY WERE NEVER QUITE THE SAME WITHOUT HIM BECAUSE THE LEARINESS OF THE CARRY ON FILMS\n",
      "Prediction: THEY WERE NEVER QUITE THE SAME WITHOUT HIM BECAUSE THE LEARINES OF THE CARY ON FILMS\n",
      "Word Error Rate on Prediction: 12.5%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: IVE BEEN VERY BUSY BABY SITTING MY NEW THREE WEEK OLD GRANDDAUGHTER\n",
      "Prediction: IVE BEN VERY BUSY BABY SITING MY NEW THRE WEK OLD GRANDAUGHTER\n",
      "Word Error Rate on Prediction: 41.66666666666667%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Original: THESE GUYS HAVE MEMORIES OF THE DAY THEY BUILT AN EXTENSION SOMEWHERE IN GLOUCESTER\n",
      "Prediction: THESE GUYS HAVE MEMORIES OF THE DAY THEY BUILT AN EXTENSION SOMEWHERE IN GLOUCESTER\n",
      "Word Error Rate on Prediction: 0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Avg Word Error Rate: 16.3265306122449%\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T22:11:03.160926Z",
     "start_time": "2024-07-05T22:11:03.146900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(value))\n",
    "# print(value.shape)\n",
    "print(len(yHat))\n",
    "print(yHat.shape)\n",
    "print(len(decoded))\n",
    "print(decoded.shape)"
   ],
   "id": "36165a18e6604940",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "(4, 290, 29)\n",
      "4\n",
      "(4, 290)\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T22:46:39.302388Z",
     "start_time": "2024-07-05T22:46:39.288273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "len(val)\n",
    "len(val[0][0])"
   ],
   "id": "3ba349dd53e62719",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T22:48:26.884050Z",
     "start_time": "2024-07-05T22:48:26.867363Z"
    }
   },
   "cell_type": "code",
   "source": "val[0][0].shape",
   "id": "949ed77bc9baf9e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290, 40, 120, 1)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T23:24:53.059945Z",
     "start_time": "2024-07-05T23:24:53.055433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def padTensor(tensor, target_shape, padding_value=0):\n",
    "  \"\"\"Pads a tensor to the specified target shape with a given padding value.\n",
    "\n",
    "  Args:\n",
    "      tensor: The tensor to be padded.\n",
    "      target_shape: The desired padded shape.\n",
    "      padding_value: The value to use for padding (default: 0).\n",
    "\n",
    "  Returns:\n",
    "      The padded tensor.\n",
    "  \"\"\"\n",
    "\n",
    "  paddings = [[0, target_shape[0] - tensor.shape[0]],  # Pad leading and trailing dimensions 0\n",
    "             [0, target_shape[1] - tensor.shape[1]],  # for the first 3 dimensions\n",
    "             [0, target_shape[2] - tensor.shape[2]],\n",
    "             [0, target_shape[3] - tensor.shape[3]]]  # Pad only for dimension 3\n",
    "  return tf.pad(tensor, paddings, constant_values=padding_value)\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "def fixPath(path): \n",
    "    return path.replace('\\\\', '\\\\\\\\')\n",
    "  "
   ],
   "id": "4192a78f190f1ea5",
   "outputs": [],
   "execution_count": 198
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T23:35:20.759129Z",
     "start_time": "2024-07-05T23:35:20.744128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def loadData2(fileName): \n",
    "    # tf has the paths as bytes so decode that\n",
    " \n",
    "    # generate the respective paths of the data\n",
    "    vidName = fileName + (\".mp4\")\n",
    "    txtName = fileName + (\".txt\")\n",
    "    print(vidName)\n",
    "    videoPath = os.path.join(rootDir2, \"customVids\", vidName)\n",
    "    alignmentPath = os.path.join(rootDir2, \"customVids\", txtName)\n",
    "    \n",
    "    # return the frames and alignments\n",
    "    frames = loadVideo(videoPath) \n",
    "    alignments = loadText(alignmentPath)\n",
    "    return frames, alignments\n",
    "\n",
    "def loadVideo2(path, ): \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    global lastKnownCrop, frameSizeOld, frameSize, newFrameSize, grayFrame\n",
    "    global errorNums, maxFrameCt\n",
    "    processedFrames = []\n",
    "    isFirstFrame = True\n",
    "    frameShape = None\n",
    "    frameCount = 0\n",
    "    \n",
    "    # for each frame \n",
    "    for n in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))): \n",
    "        if frameCount != maxFrameCt:\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            # in case a frame is missing, just continue\n",
    "            if frame is None or frame.shape[0] == 0: \n",
    "                continue\n",
    "            \n",
    "            if isFirstFrame: \n",
    "                frameShape  = frame.shape\n",
    "                isFirstFrame = False\n",
    "            \n",
    "            if frame.shape != frameShape: \n",
    "                continue\n",
    "            # crop only the mouth like we'll do on the RPI \n",
    "            frameSizeOld = frame.shape\n",
    "            frame = cropForMouth(frame)\n",
    "            frameSize = frame.shape\n",
    "            frame = cv2.resize(frame, (newImageSize[1], newImageSize[0]))\n",
    "            newFrameSize = frame.shape\n",
    "            try: \n",
    "                grayFrame = tf.image.rgb_to_grayscale(frame)\n",
    "            except: \n",
    "                continue\n",
    "            processedFrames.append(grayFrame)\n",
    "            # processedFrames = [*processedFrames, grayFrame]\n",
    "            lastFrame = grayFrame\n",
    "            frameCount += 1\n",
    "\n",
    "    while len(processedFrames) < maxFrameCt: \n",
    "        processedFrames.append(lastFrame)\n",
    "    cap.release()    \n",
    "\n",
    "    # generate the normalized frames (deviation from the average)\n",
    "    mean = tf.math.reduce_mean(processedFrames, keepdims=True)\n",
    "    try: \n",
    "        std = tf.math.reduce_std(tf.cast(processedFrames, tf.float32),  keepdims=True)\n",
    "    except: \n",
    "        \n",
    "        errorPaths.append(path)\n",
    "        errorInfo.append(\"SECOND STATEMENT\")\n",
    "        errorInfo.append(len(processedFrames))\n",
    "        errorInfo.append(frameSizeOld)\n",
    "        errorInfo.append(frameSize)\n",
    "        errorInfo.append(newFrameSize)\n",
    "        errorInfo.append(grayFrame)\n",
    "    std = tf.math.reduce_std(tf.cast(processedFrames, tf.float32), keepdims=True)\n",
    "    frames = tf.cast(processedFrames, tf.float32)\n",
    "    normalizedFrames = (tf.cast(frames, tf.float32) - tf.cast(mean, tf.float32)) / tf.cast(std, tf.float32)\n",
    "    return normalizedFrames\n",
    "\n",
    "def makePredictionOnVid(path, model):\n",
    "    sample = loadData(tf.convert_to_tensor(path))\n",
    "    print('~'*60)\n",
    "    original = tf.strings.reduce_join(numToChar(sample[1])).numpy().decode('utf-8')\n",
    "    paddedVid =  padTensor(sample[0], (290, 40, 120, 1))\n",
    "    yhat = model.predict(tf.expand_dims(paddedVid, axis=0))\n",
    "    \n",
    "    decoded = tf.keras.backend.ctc_decode(yhat, input_length=[maxFrameCt], greedy=True)[0][0].numpy()\n",
    "    prediction = tf.strings.reduce_join(numToChar(decoded[0])).numpy().decode('utf-8')\n",
    "    print('Original:', original)\n",
    "    print('Prediction:', prediction)\n",
    "    print(\"Word Error Rate on Prediction:\", str(wer(original,prediction) * 100) + \"%\")\n",
    "\n",
    "\n",
    "def makePredictionCustomVid(path, model): \n",
    "    sample = loadData2((path))\n",
    "    original = tf.strings.reduce_join(numToChar(sample[1])).numpy().decode('utf-8')\n",
    "    paddedVid =  padTensor(sample[0], (290, 40, 120, 1))\n",
    "    yhat = model.predict(tf.expand_dims(paddedVid, axis=0))\n",
    "    \n",
    "    decoded = tf.keras.backend.ctc_decode(yhat, input_length=[maxFrameCt], greedy=True)[0][0].numpy()\n",
    "    prediction = tf.strings.reduce_join(numToChar(decoded[0])).numpy().decode('utf-8')\n",
    "    print('Original:', original)\n",
    "    print('Prediction:', prediction)\n",
    "    print(\"Word Error Rate on Prediction:\", str(wer(original,prediction) * 100) + \"%\")\n"
   ],
   "id": "9b8c8a3c40b391a8",
   "outputs": [],
   "execution_count": 241
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T23:39:00.452939Z",
     "start_time": "2024-07-05T23:38:58.526473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "makePredictionCustomVid(\"5570920046221178499_00015\", model2)\n",
    "\n",
    "path = \"A:\\Lip Reading\\Potential Datasets\\BBC LRS2\\\\allFiles\\\\5570920046221178499_00015.mp4\"\n",
    "makePredictionOnVid(path, model2)"
   ],
   "id": "d3e17401309985fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5570920046221178499_00015.mp4\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "Original: WHICH OF OUR CONTESTANTS TODAY IS GOING TO MAKE A THUMPING GREAT PROFIT\n",
      "Prediction: WHICH OF OUR CONTESTANTS TODAY IS GOING TO MAKE A THUMPING GREAT PROFIT\n",
      "Word Error Rate on Prediction: 0.0%\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "Original: WHICH OF OUR CONTESTANTS TODAY IS GOING TO MAKE A THUMPING GREAT PROFIT\n",
      "Prediction: WHICH OF OUR CONTESTANTS TODAY IS GOING TO MAKE A THUMPING GREAT PROFIT\n",
      "Word Error Rate on Prediction: 0.0%\n"
     ]
    }
   ],
   "execution_count": 248
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "cb4ee05381ede6ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a54706f60d61aa2c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
